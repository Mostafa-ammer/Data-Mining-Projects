{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Define the problem ?**"
      ],
      "metadata": {
        "id": "xeZFdsitIusX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**it is a classification problem that depend on multi-modality because there are two features have different data types such as text and image ,and also depend on multi-task because we predict two labels the price of real estate and it's type of real estate**"
      ],
      "metadata": {
        "id": "1ork0X-lIusY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **What is the input?**"
      ],
      "metadata": {
        "id": "_EC8WKHrIusZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**we have two input features , the image of real estate and summary of real estate**"
      ],
      "metadata": {
        "id": "rMX4GO0sIusZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **What is the output?**"
      ],
      "metadata": {
        "id": "IvGVZr28IusZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**we have two output , the price of real estate and it's type.**"
      ],
      "metadata": {
        "id": "CDOKF5zjIusZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **What data mining function is required?**"
      ],
      "metadata": {
        "id": "O4-pBtA7IusZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**the function is prediction and classification**"
      ],
      "metadata": {
        "id": "1V1ClXkxIusZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **What could be the challenges?**"
      ],
      "metadata": {
        "id": "ZvcIOZ-KIusa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. we have two features and predict two labels**\n",
        "\n",
        "**2. the summary feature have a different language**\n",
        "\n",
        "**3. imbalance labels**\n",
        "\n",
        "**4. when drop Null and Duplication from train and test data , the data become very small**\n",
        "\n",
        "**5. make preprocessing on different type of data**"
      ],
      "metadata": {
        "id": "PamNlN02Iusa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **What is the impact?**"
      ],
      "metadata": {
        "id": "hZt1H12fIusa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**the model will help the hosts to determine the suitable price for their real estate and the hosts will be able to sell their real estate easily**"
      ],
      "metadata": {
        "id": "D6fNGhAFIusa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **What is an ideal solution?**"
      ],
      "metadata": {
        "id": "OhpD1gq2Iusa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**the ideal solution for me is is building neural network with dropout technique, \n",
        "the accuracy on validation data is 0.6951**"
      ],
      "metadata": {
        "id": "PuI_NApmIusa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **What is the experimental protocol used and how was it carried out?**\n",
        "**1-  import the required libraries**\n",
        "\n",
        "**2- read the train and test data** \n",
        "\n",
        "**3- make some visualization on data** \n",
        "\n",
        "**4- make preprocessing on data**\n",
        "\n",
        "\n",
        "  * remove null values and remove duplication\n",
        "     \n",
        "  * translate the text into English\n",
        "     \n",
        "  * apply lemmatization process on text\n",
        "     \n",
        "  * tokenize the text of summary feature\n",
        "     \n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "**5- building set of models** \n",
        "  \n",
        " **6- train each model**\n",
        "  \n",
        " **7- make prediction**\n",
        "  \n",
        " **8- building the submittion file**"
      ],
      "metadata": {
        "id": "wCAMJDe_Iusb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **How did we tune hyper-parameters in the template? What is the search space and what is the criteria to determine good/bad hyper-parameters?**\n"
      ],
      "metadata": {
        "id": "bT6jYlhkIusb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Tuning the hyperparameters is an important aspect of building a machine learning model, as they can have a significant impact on the model's performance.**\n",
        "* **we used a technique called grid search, which involves specifying a range of values for each hyperparameter and then systematically trying all possible combinations of these values**\n",
        "* **To determine good/bad hyperparameters, we typically use a metric that measures the performance of the model on a validation set. For example, we might use the accuracy or F1 score for a classification task, or the mean squared error or R-squared for a regression task.**"
      ],
      "metadata": {
        "id": "eE0pU4bmIusb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Is fully-connected model a good one for sequential data? Why? How about for image data? Is it good? Why?**"
      ],
      "metadata": {
        "id": "ib0CN-q_Iusb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**- it is not good for sequential data because the sequential data is dependant,and the neural network deal with data as non-sequential data** \n",
        "\n",
        "**- it is not good for image because it is not good to deal with feature extraction , so that there are many parameters which may lead to overfitting**"
      ],
      "metadata": {
        "id": "_VX9WBbtIusb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **What is gradient vanishing and gradient explosion, and how GRU/LSTM tries to mitigate this problem?**"
      ],
      "metadata": {
        "id": "b-k60cCvIusb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Gradient vanishing occurs when the gradients of the loss function with respect to the parameters of the network become very small as they are backpropagated through the network, making it difficult for the network to update the parameters and learn**\n",
        "* **Gradient explosion occurs when the gradients become very large during backpropagation, causing the weights to update too much and leading to instability and divergence**\n",
        "*  **In both GRU and LSTM, there are gates that control the flow of information through the network, allowing it to selectively remember or forget information from previous time steps. These gates are learned during training and help to mitigate the problems of vanishing and exploding gradients by allowing the network to selectively propagate or block gradients through time.**"
      ],
      "metadata": {
        "id": "5dxVGdSLIusc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **What is multi-objective/multi-task learning? What is multi-modality learning? How do you use them in this assignment?**"
      ],
      "metadata": {
        "id": "UGkvRyh2Iusc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **multi-objective/multi-task learning mean that make prediction on multiple lable , not one label , in the assignment we make prediction of price of real estate and it's type .**\n",
        "* **multi-modality learning mean the features have different datatypes ,in the assignment ,there are two different features , they are the summary that represent in form of text and image of real estate**"
      ],
      "metadata": {
        "id": "gPa19Nh-Iusc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **What is the difference among xgboost, lightgbm and catboost ?**"
      ],
      "metadata": {
        "id": "IEjToY4YIusc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **XGBoost is designed to be highly scalable and efficient, using a variety of optimization techniques such as parallelization, cache awareness, and regularization to improve performance. XGBoost uses a tree-based model, where each tree is built using a greedy algorithm that selects the best split at each node based on the gradient of the loss function.**\n",
        "\n",
        "* **A framework for gradient boosting called LightGBM (Light Gradient Boosting Machine). Gradient-based One-Side Sampling (GOSS), a Gradient-edge method, is utilised to reduce the number of data points required to train each tree, making it even more effective than XGBoost. Although LightGBM similarly use a tree-based model, it implements split finding differently from XGBoost, relying instead on a histogram-based strategy that may be more effective for sparse data sets.**\n",
        "* **A weighted sample variation of stochastic gradient boosting, known as minimal variance sampling (MVS), is provided by Catboost.**"
      ],
      "metadata": {
        "id": "uPfDZuXiIusc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        pass\n",
        "        #print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-04-13T12:23:53.434146Z",
          "iopub.execute_input": "2023-04-13T12:23:53.434857Z",
          "iopub.status.idle": "2023-04-13T12:24:01.540048Z",
          "shell.execute_reply.started": "2023-04-13T12:23:53.434817Z",
          "shell.execute_reply": "2023-04-13T12:24:01.538993Z"
        },
        "trusted": true,
        "id": "cXFLX1y8Iusc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the required libraries\n",
        "# the basic libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os \n",
        "import pathlib\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "from time import time\n",
        "import tensorflow as tf\n",
        "# libraries for dealing with deep learning \n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, LSTM, Dropout, Bidirectional, GRU\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pprint import pprint\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# for dealing with nlp \n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "# for text translation \n",
        "!pip install googletrans\n",
        "!pip install googletrans==3.1.0a0 --user\n",
        "from googletrans import Translator\n",
        "import cv2\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:23:34.030837Z",
          "iopub.execute_input": "2023-04-13T11:23:34.032843Z",
          "iopub.status.idle": "2023-04-13T11:23:55.809148Z",
          "shell.execute_reply.started": "2023-04-13T11:23:34.032799Z",
          "shell.execute_reply": "2023-04-13T11:23:55.807528Z"
        },
        "trusted": true,
        "id": "7AuY3MPfIusd",
        "outputId": "fe715bf8-7d4b-49b4-b58f-3686ad038e7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\nRequirement already satisfied: googletrans in /root/.local/lib/python3.7/site-packages (3.1.0a0)\nRequirement already satisfied: httpx==0.13.3 in /opt/conda/lib/python3.7/site-packages (from googletrans) (0.13.3)\nRequirement already satisfied: rfc3986<2,>=1.3 in /opt/conda/lib/python3.7/site-packages (from httpx==0.13.3->googletrans) (1.5.0)\nRequirement already satisfied: httpcore==0.9.* in /opt/conda/lib/python3.7/site-packages (from httpx==0.13.3->googletrans) (0.9.1)\nRequirement already satisfied: hstspreload in /opt/conda/lib/python3.7/site-packages (from httpx==0.13.3->googletrans) (2023.1.1)\nRequirement already satisfied: chardet==3.* in /opt/conda/lib/python3.7/site-packages (from httpx==0.13.3->googletrans) (3.0.4)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from httpx==0.13.3->googletrans) (2022.12.7)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.7/site-packages (from httpx==0.13.3->googletrans) (1.3.0)\nRequirement already satisfied: idna==2.* in /opt/conda/lib/python3.7/site-packages (from httpx==0.13.3->googletrans) (2.10)\nRequirement already satisfied: h11<0.10,>=0.8 in /opt/conda/lib/python3.7/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (0.9.0)\nRequirement already satisfied: h2==3.* in /opt/conda/lib/python3.7/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (3.2.0)\nRequirement already satisfied: hyperframe<6,>=5.2.0 in /opt/conda/lib/python3.7/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (5.2.0)\nRequirement already satisfied: hpack<4,>=3.0 in /opt/conda/lib/python3.7/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (3.0.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: googletrans==3.1.0a0 in /root/.local/lib/python3.7/site-packages (3.1.0a0)\nRequirement already satisfied: httpx==0.13.3 in /opt/conda/lib/python3.7/site-packages (from googletrans==3.1.0a0) (0.13.3)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.7/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.3.0)\nRequirement already satisfied: hstspreload in /opt/conda/lib/python3.7/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2023.1.1)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2022.12.7)\nRequirement already satisfied: rfc3986<2,>=1.3 in /opt/conda/lib/python3.7/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.5.0)\nRequirement already satisfied: chardet==3.* in /opt/conda/lib/python3.7/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\nRequirement already satisfied: httpcore==0.9.* in /opt/conda/lib/python3.7/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (0.9.1)\nRequirement already satisfied: idna==2.* in /opt/conda/lib/python3.7/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\nRequirement already satisfied: h2==3.* in /opt/conda/lib/python3.7/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.2.0)\nRequirement already satisfied: h11<0.10,>=0.8 in /opt/conda/lib/python3.7/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (0.9.0)\nRequirement already satisfied: hyperframe<6,>=5.2.0 in /opt/conda/lib/python3.7/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (5.2.0)\nRequirement already satisfied: hpack<4,>=3.0 in /opt/conda/lib/python3.7/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.0.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read the data (train,test)\n",
        "train=pd.read_csv(\"/kaggle/input/copy-of-cisc-873-dm-w23-a4/a4/train_xy.csv\")\n",
        "test=pd.read_csv(\"/kaggle/input/copy-of-cisc-873-dm-w23-a4/a4/test_x.csv\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:23:55.814568Z",
          "iopub.execute_input": "2023-04-13T11:23:55.817556Z",
          "iopub.status.idle": "2023-04-13T11:23:55.925215Z",
          "shell.execute_reply.started": "2023-04-13T11:23:55.817505Z",
          "shell.execute_reply": "2023-04-13T11:23:55.924151Z"
        },
        "trusted": true,
        "id": "xAin_bZ7Iuse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show the train data\n",
        "train"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:23:55.931190Z",
          "iopub.execute_input": "2023-04-13T11:23:55.933747Z",
          "iopub.status.idle": "2023-04-13T11:23:55.953270Z",
          "shell.execute_reply.started": "2023-04-13T11:23:55.933706Z",
          "shell.execute_reply": "2023-04-13T11:23:55.952313Z"
        },
        "trusted": true,
        "id": "CNZnjTjDIuse",
        "outputId": "7e7f5ee2-7701-44bc-f1b4-191a25051903"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 29,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                summary               image  \\\n0     Spacious, sunny and cozy modern apartment in t...     img_train/0.jpg   \n1     Located in one of the most vibrant and accessi...     img_train/1.jpg   \n2     Logement coquet et douillet à 10 minutes du ce...     img_train/2.jpg   \n3     Beautiful and spacious (1076 sc ft, / 100 mc) ...     img_train/3.jpg   \n4     Très grand appartement ''rustique'' et très ag...     img_train/4.jpg   \n...                                                 ...                 ...   \n7622  Un grand logement 4 et 1/2, tout inclut, bien ...  img_train/7626.jpg   \n7623  Magnificent condo directly on the river. You w...  img_train/7627.jpg   \n7624  This apartment is perfect for anyone visiting ...  img_train/7628.jpg   \n7625  It is a cozy ,clean ,and comfortable apartment...  img_train/7629.jpg   \n7626  Modern country style (newly-renovated); open c...  img_train/7630.jpg   \n\n           type  price  \n0     Apartment      1  \n1     Apartment      0  \n2     Apartment      1  \n3     Apartment      1  \n4     Apartment      0  \n...         ...    ...  \n7622  Apartment      0  \n7623  Apartment      2  \n7624  Apartment      1  \n7625  Apartment      0  \n7626      House      1  \n\n[7627 rows x 4 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>summary</th>\n      <th>image</th>\n      <th>type</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Spacious, sunny and cozy modern apartment in t...</td>\n      <td>img_train/0.jpg</td>\n      <td>Apartment</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Located in one of the most vibrant and accessi...</td>\n      <td>img_train/1.jpg</td>\n      <td>Apartment</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Logement coquet et douillet à 10 minutes du ce...</td>\n      <td>img_train/2.jpg</td>\n      <td>Apartment</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Beautiful and spacious (1076 sc ft, / 100 mc) ...</td>\n      <td>img_train/3.jpg</td>\n      <td>Apartment</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Très grand appartement ''rustique'' et très ag...</td>\n      <td>img_train/4.jpg</td>\n      <td>Apartment</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7622</th>\n      <td>Un grand logement 4 et 1/2, tout inclut, bien ...</td>\n      <td>img_train/7626.jpg</td>\n      <td>Apartment</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7623</th>\n      <td>Magnificent condo directly on the river. You w...</td>\n      <td>img_train/7627.jpg</td>\n      <td>Apartment</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7624</th>\n      <td>This apartment is perfect for anyone visiting ...</td>\n      <td>img_train/7628.jpg</td>\n      <td>Apartment</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7625</th>\n      <td>It is a cozy ,clean ,and comfortable apartment...</td>\n      <td>img_train/7629.jpg</td>\n      <td>Apartment</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7626</th>\n      <td>Modern country style (newly-renovated); open c...</td>\n      <td>img_train/7630.jpg</td>\n      <td>House</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7627 rows × 4 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* there are 7627 samples in train data \n",
        "* there are features such as summary, image path\n",
        "* the labels are type and the price "
      ],
      "metadata": {
        "id": "tfauy0d6Iuse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# show the test data\n",
        "test "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:23:55.957388Z",
          "iopub.execute_input": "2023-04-13T11:23:55.959543Z",
          "iopub.status.idle": "2023-04-13T11:23:55.976505Z",
          "shell.execute_reply.started": "2023-04-13T11:23:55.959504Z",
          "shell.execute_reply": "2023-04-13T11:23:55.975646Z"
        },
        "trusted": true,
        "id": "buUDvg2aIuse",
        "outputId": "55c2b67f-f13c-413e-9b35-551c998ba5ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 30,
          "output_type": "execute_result",
          "data": {
            "text/plain": "        id                                            summary  \\\n0        0  Charming warm house is ready to host you here ...   \n1        1  La chambre est spacieuse et lumineuse, dans un...   \n2        2  Grande chambre confortable située au sous-sol ...   \n3        3  Près d’un Métro, ligne orange. 10 minutes à pi...   \n4        4  Very bright appartment and very cosy. 2 separa...   \n...    ...                                                ...   \n7355  7626  Large, fully-furnished flat with brick walls a...   \n7356  7627  Logement situé dans le haut d’un duplex. Vivez...   \n7357  7628  My place is close to parks, . My place is good...   \n7358  7629  *** For security reasons, I will prioritize gu...   \n7359  7630  Stay in an amazing area of Montreal! 5-7 min f...   \n\n                  image  \n0        img_test/0.jpg  \n1        img_test/1.jpg  \n2        img_test/2.jpg  \n3        img_test/3.jpg  \n4        img_test/4.jpg  \n...                 ...  \n7355  img_test/7627.jpg  \n7356  img_test/7628.jpg  \n7357  img_test/7629.jpg  \n7358  img_test/7630.jpg  \n7359  img_test/7631.jpg  \n\n[7360 rows x 3 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>summary</th>\n      <th>image</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Charming warm house is ready to host you here ...</td>\n      <td>img_test/0.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>La chambre est spacieuse et lumineuse, dans un...</td>\n      <td>img_test/1.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Grande chambre confortable située au sous-sol ...</td>\n      <td>img_test/2.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Près d’un Métro, ligne orange. 10 minutes à pi...</td>\n      <td>img_test/3.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Very bright appartment and very cosy. 2 separa...</td>\n      <td>img_test/4.jpg</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7355</th>\n      <td>7626</td>\n      <td>Large, fully-furnished flat with brick walls a...</td>\n      <td>img_test/7627.jpg</td>\n    </tr>\n    <tr>\n      <th>7356</th>\n      <td>7627</td>\n      <td>Logement situé dans le haut d’un duplex. Vivez...</td>\n      <td>img_test/7628.jpg</td>\n    </tr>\n    <tr>\n      <th>7357</th>\n      <td>7628</td>\n      <td>My place is close to parks, . My place is good...</td>\n      <td>img_test/7629.jpg</td>\n    </tr>\n    <tr>\n      <th>7358</th>\n      <td>7629</td>\n      <td>*** For security reasons, I will prioritize gu...</td>\n      <td>img_test/7630.jpg</td>\n    </tr>\n    <tr>\n      <th>7359</th>\n      <td>7630</td>\n      <td>Stay in an amazing area of Montreal! 5-7 min f...</td>\n      <td>img_test/7631.jpg</td>\n    </tr>\n  </tbody>\n</table>\n<p>7360 rows × 3 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* there are 7360 samples in test data \n",
        "* there are features such as id,summary, image path\n",
        "* No labels in test data"
      ],
      "metadata": {
        "id": "4lUPdYT-Iuse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make a description on train data \n",
        "train.describe"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:23:55.980451Z",
          "iopub.execute_input": "2023-04-13T11:23:55.982634Z",
          "iopub.status.idle": "2023-04-13T11:23:55.996398Z",
          "shell.execute_reply.started": "2023-04-13T11:23:55.982597Z",
          "shell.execute_reply": "2023-04-13T11:23:55.995511Z"
        },
        "trusted": true,
        "id": "DsD9QniQIuse",
        "outputId": "a69b50c0-d4ad-40f5-e96b-fbd2d81f2e48"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 31,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<bound method NDFrame.describe of                                                 summary               image  \\\n0     Spacious, sunny and cozy modern apartment in t...     img_train/0.jpg   \n1     Located in one of the most vibrant and accessi...     img_train/1.jpg   \n2     Logement coquet et douillet à 10 minutes du ce...     img_train/2.jpg   \n3     Beautiful and spacious (1076 sc ft, / 100 mc) ...     img_train/3.jpg   \n4     Très grand appartement ''rustique'' et très ag...     img_train/4.jpg   \n...                                                 ...                 ...   \n7622  Un grand logement 4 et 1/2, tout inclut, bien ...  img_train/7626.jpg   \n7623  Magnificent condo directly on the river. You w...  img_train/7627.jpg   \n7624  This apartment is perfect for anyone visiting ...  img_train/7628.jpg   \n7625  It is a cozy ,clean ,and comfortable apartment...  img_train/7629.jpg   \n7626  Modern country style (newly-renovated); open c...  img_train/7630.jpg   \n\n           type  price  \n0     Apartment      1  \n1     Apartment      0  \n2     Apartment      1  \n3     Apartment      1  \n4     Apartment      0  \n...         ...    ...  \n7622  Apartment      0  \n7623  Apartment      2  \n7624  Apartment      1  \n7625  Apartment      0  \n7626      House      1  \n\n[7627 rows x 4 columns]>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make a description on test data \n",
        "train.describe"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:23:56.000299Z",
          "iopub.execute_input": "2023-04-13T11:23:56.002391Z",
          "iopub.status.idle": "2023-04-13T11:23:56.016975Z",
          "shell.execute_reply.started": "2023-04-13T11:23:56.002356Z",
          "shell.execute_reply": "2023-04-13T11:23:56.016089Z"
        },
        "trusted": true,
        "id": "d_4LHdQiIusf",
        "outputId": "21563447-0212-4937-a25f-f91976653104"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 32,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<bound method NDFrame.describe of                                                 summary               image  \\\n0     Spacious, sunny and cozy modern apartment in t...     img_train/0.jpg   \n1     Located in one of the most vibrant and accessi...     img_train/1.jpg   \n2     Logement coquet et douillet à 10 minutes du ce...     img_train/2.jpg   \n3     Beautiful and spacious (1076 sc ft, / 100 mc) ...     img_train/3.jpg   \n4     Très grand appartement ''rustique'' et très ag...     img_train/4.jpg   \n...                                                 ...                 ...   \n7622  Un grand logement 4 et 1/2, tout inclut, bien ...  img_train/7626.jpg   \n7623  Magnificent condo directly on the river. You w...  img_train/7627.jpg   \n7624  This apartment is perfect for anyone visiting ...  img_train/7628.jpg   \n7625  It is a cozy ,clean ,and comfortable apartment...  img_train/7629.jpg   \n7626  Modern country style (newly-renovated); open c...  img_train/7630.jpg   \n\n           type  price  \n0     Apartment      1  \n1     Apartment      0  \n2     Apartment      1  \n3     Apartment      1  \n4     Apartment      0  \n...         ...    ...  \n7622  Apartment      0  \n7623  Apartment      2  \n7624  Apartment      1  \n7625  Apartment      0  \n7626      House      1  \n\n[7627 rows x 4 columns]>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the frequency for each class in price label in train data \n",
        "train['price'].value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:23:56.038864Z",
          "iopub.execute_input": "2023-04-13T11:23:56.040981Z",
          "iopub.status.idle": "2023-04-13T11:23:56.052062Z",
          "shell.execute_reply.started": "2023-04-13T11:23:56.040945Z",
          "shell.execute_reply": "2023-04-13T11:23:56.050801Z"
        },
        "trusted": true,
        "id": "u1DJH89NIusf",
        "outputId": "48a02e82-d9b5-48f3-f13a-570f0580bac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 34,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0    4737\n1    2403\n2     487\nName: price, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the frequency for each class in price label in train data\n",
        "\"\"\"\n",
        "0 in price represent beginner\n",
        "1 in price represent plus\n",
        "2 in price represent premium\n",
        "\"\"\"\n",
        "sns.set(style='darkgrid')\n",
        "plt.figure(figsize=(8,8))\n",
        "ax=sns.countplot(y = 'price',data =train,order = train['price'].value_counts().index,palette = \"viridis\")\n",
        "ax.set_yticklabels(['beginner', 'plus', 'premium'])\n",
        "plt.ylabel('PRICE',fontsize = 16, weight = 'bold',color='black')\n",
        "plt.xlabel('COUNT',fontsize = 16, weight = 'bold',color='black')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:23:56.059525Z",
          "iopub.execute_input": "2023-04-13T11:23:56.061635Z",
          "iopub.status.idle": "2023-04-13T11:23:56.370304Z",
          "shell.execute_reply.started": "2023-04-13T11:23:56.061599Z",
          "shell.execute_reply": "2023-04-13T11:23:56.369138Z"
        },
        "trusted": true,
        "id": "PTFQxnifIusf",
        "outputId": "4e7d03bf-d968-4273-dafa-5f907db46c69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 800x800 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the frequency for each class in type label in train data \n",
        "train['type'].value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:23:56.371660Z",
          "iopub.execute_input": "2023-04-13T11:23:56.372425Z",
          "iopub.status.idle": "2023-04-13T11:23:56.383871Z",
          "shell.execute_reply.started": "2023-04-13T11:23:56.372376Z",
          "shell.execute_reply": "2023-04-13T11:23:56.382798Z"
        },
        "trusted": true,
        "id": "AI7Tyv2qIusf",
        "outputId": "586bc8a2-4fa1-4de1-d7a6-055e0d817907"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 36,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Apartment                 5765\nCondominium                691\nHouse                      406\nLoft                       324\nTownhouse                  167\nServiced apartment          77\nBed and breakfast           38\nGuest suite                 32\nHostel                      26\nBungalow                    25\nGuesthouse                  14\nCottage                     12\nAparthotel                  12\nBoutique hotel              10\nOther                        8\nVilla                        7\nTiny house                   3\nBoat                         2\nCabin                        2\nCamper/RV                    2\nCasa particular (Cuba)       1\nHotel                        1\nEarth house                  1\nCastle                       1\nName: type, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the frequency for each class in type label in train data \n",
        "sns.set(style='darkgrid')\n",
        "plt.figure(figsize=(8,8))\n",
        "sns.countplot(y = 'type',data =train,order = train['type'].value_counts().index,palette = \"viridis\")\n",
        "plt.ylabel('TYPE',fontsize = 16, weight = 'bold',color='black')\n",
        "plt.xlabel('COUNT',fontsize = 16, weight = 'bold',color='black')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:23:56.385493Z",
          "iopub.execute_input": "2023-04-13T11:23:56.386182Z",
          "iopub.status.idle": "2023-04-13T11:23:56.886870Z",
          "shell.execute_reply.started": "2023-04-13T11:23:56.386112Z",
          "shell.execute_reply": "2023-04-13T11:23:56.885652Z"
        },
        "trusted": true,
        "id": "XxYmTYCeIusf",
        "outputId": "a70ce950-10bd-4905-ecc5-2a6719396a1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 800x800 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check null values in train data \n",
        "train.isnull().sum()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:23:56.891022Z",
          "iopub.execute_input": "2023-04-13T11:23:56.891406Z",
          "iopub.status.idle": "2023-04-13T11:23:56.909768Z",
          "shell.execute_reply.started": "2023-04-13T11:23:56.891372Z",
          "shell.execute_reply": "2023-04-13T11:23:56.908467Z"
        },
        "trusted": true,
        "id": "TNVYV5iHIusf",
        "outputId": "761ccc8f-1c6d-400e-e4a5-ca3456cba90a"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 38,
          "output_type": "execute_result",
          "data": {
            "text/plain": "summary    301\nimage        0\ntype         0\nprice        0\ndtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove null values in train data \n",
        "train=train.dropna()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:23:56.911119Z",
          "iopub.execute_input": "2023-04-13T11:23:56.911732Z",
          "iopub.status.idle": "2023-04-13T11:23:56.924825Z",
          "shell.execute_reply.started": "2023-04-13T11:23:56.911694Z",
          "shell.execute_reply": "2023-04-13T11:23:56.923619Z"
        },
        "trusted": true,
        "id": "CI4erVlYIusg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check null values in train data after removing null values \n",
        "train.isnull().sum().sum()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:23:56.929169Z",
          "iopub.execute_input": "2023-04-13T11:23:56.929523Z",
          "iopub.status.idle": "2023-04-13T11:23:56.944920Z",
          "shell.execute_reply.started": "2023-04-13T11:23:56.929486Z",
          "shell.execute_reply": "2023-04-13T11:23:56.943820Z"
        },
        "trusted": true,
        "id": "RaYXLaHCIusg",
        "outputId": "aebda7d3-0cec-470f-ba8f-39c88934074c"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 40,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check null values in test data \n",
        "test.isnull().sum().sum()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:23:56.949226Z",
          "iopub.execute_input": "2023-04-13T11:23:56.951595Z",
          "iopub.status.idle": "2023-04-13T11:23:56.964930Z",
          "shell.execute_reply.started": "2023-04-13T11:23:56.951541Z",
          "shell.execute_reply": "2023-04-13T11:23:56.963932Z"
        },
        "trusted": true,
        "id": "MTDRUWLoIusg",
        "outputId": "dc1d2c49-6918-4749-b9c0-e5153884284b"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 41,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* No Null Values in Test Data "
      ],
      "metadata": {
        "id": "x8yQFW5uIusg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check duplication in train data\n",
        "train.duplicated().sum() "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:23:56.969764Z",
          "iopub.execute_input": "2023-04-13T11:23:56.972060Z",
          "iopub.status.idle": "2023-04-13T11:23:57.002699Z",
          "shell.execute_reply.started": "2023-04-13T11:23:56.972025Z",
          "shell.execute_reply": "2023-04-13T11:23:57.001714Z"
        },
        "trusted": true,
        "id": "FNhzG7AcIusg",
        "outputId": "41374aa4-d99b-40b8-ad47-f7006937af60"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 42,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check duplication in test data\n",
        "test.duplicated().sum()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:23:57.006818Z",
          "iopub.execute_input": "2023-04-13T11:23:57.009134Z",
          "iopub.status.idle": "2023-04-13T11:23:57.036193Z",
          "shell.execute_reply.started": "2023-04-13T11:23:57.009094Z",
          "shell.execute_reply": "2023-04-13T11:23:57.035227Z"
        },
        "trusted": true,
        "id": "wNSfqKCZIush",
        "outputId": "06fc9b62-acf2-4f6a-951d-1d1a87fc5514"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 43,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No data duplicated in train and test data"
      ],
      "metadata": {
        "id": "1D4nr5ZlIush"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make encoding on type label\n",
        "train[\"type\"]=train.type.astype('category').cat.codes"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:23:57.040314Z",
          "iopub.execute_input": "2023-04-13T11:23:57.042684Z",
          "iopub.status.idle": "2023-04-13T11:23:57.051228Z",
          "shell.execute_reply.started": "2023-04-13T11:23:57.042636Z",
          "shell.execute_reply": "2023-04-13T11:23:57.050219Z"
        },
        "trusted": true,
        "id": "cqyhHtB8Iush"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show type label after encoding\n",
        "train[\"type\"]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:23:57.056391Z",
          "iopub.execute_input": "2023-04-13T11:23:57.058756Z",
          "iopub.status.idle": "2023-04-13T11:23:57.071032Z",
          "shell.execute_reply.started": "2023-04-13T11:23:57.058718Z",
          "shell.execute_reply": "2023-04-13T11:23:57.069795Z"
        },
        "trusted": true,
        "id": "T56-rJVuIush",
        "outputId": "aae90d77-f80f-4ff8-d4a5-e66b397ba6ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 45,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0        1\n1        1\n2        1\n3        1\n4        1\n        ..\n7622     1\n7623     1\n7624     1\n7625     1\n7626    17\nName: type, Length: 7326, dtype: int8"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the length of unique values for \"type\" label\n",
        "length_of_type=len(train.type.unique())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:23:57.075532Z",
          "iopub.execute_input": "2023-04-13T11:23:57.077894Z",
          "iopub.status.idle": "2023-04-13T11:23:57.084375Z",
          "shell.execute_reply.started": "2023-04-13T11:23:57.077856Z",
          "shell.execute_reply": "2023-04-13T11:23:57.083270Z"
        },
        "trusted": true,
        "id": "RLeoZKeHIush"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the length\n",
        "length_of_type"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:23:57.089131Z",
          "iopub.execute_input": "2023-04-13T11:23:57.090330Z",
          "iopub.status.idle": "2023-04-13T11:23:57.099972Z",
          "shell.execute_reply.started": "2023-04-13T11:23:57.090293Z",
          "shell.execute_reply": "2023-04-13T11:23:57.098893Z"
        },
        "trusted": true,
        "id": "1VTI3CMqIush",
        "outputId": "87110037-77d3-497d-d34a-c4cdf86b8049"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 47,
          "output_type": "execute_result",
          "data": {
            "text/plain": "24"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the length of unique values for \"price\" label\n",
        "length_of_price=len(train.type.unique())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:23:57.101737Z",
          "iopub.execute_input": "2023-04-13T11:23:57.103121Z",
          "iopub.status.idle": "2023-04-13T11:23:57.112469Z",
          "shell.execute_reply.started": "2023-04-13T11:23:57.103082Z",
          "shell.execute_reply": "2023-04-13T11:23:57.111327Z"
        },
        "trusted": true,
        "id": "91TbKyT8Iush"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the length\n",
        "length_of_price"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:23:57.114136Z",
          "iopub.execute_input": "2023-04-13T11:23:57.114919Z",
          "iopub.status.idle": "2023-04-13T11:23:57.123363Z",
          "shell.execute_reply.started": "2023-04-13T11:23:57.114855Z",
          "shell.execute_reply": "2023-04-13T11:23:57.122297Z"
        },
        "trusted": true,
        "id": "hXV8m_tHIush",
        "outputId": "c388f970-6e91-468a-8933-0fd6c6acab0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 49,
          "output_type": "execute_result",
          "data": {
            "text/plain": "24"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# translator \n",
        "\"\"\"\n",
        " using the Google Translate API through the \"googletrans\" module to \n",
        " translate the text data in the \"summary\" column of a DataFrame. \n",
        " Specifically, it is using the \"apply\" method to apply the translation \n",
        " function to each element in the \"summary\" column.\n",
        "\"\"\"\n",
        "from googletrans import Translator\n",
        "translator = Translator()\n",
        "train.summary=train.summary.apply(lambda x:translator.translate(x,dest='en').text)\n",
        "test.summary=test.summary.apply(lambda x:translator.translate(x,dest='en').text) "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:23:57.125829Z",
          "iopub.execute_input": "2023-04-13T11:23:57.126588Z",
          "iopub.status.idle": "2023-04-13T11:31:15.530796Z",
          "shell.execute_reply.started": "2023-04-13T11:23:57.126535Z",
          "shell.execute_reply": "2023-04-13T11:31:15.529724Z"
        },
        "trusted": true,
        "id": "UirksodbIusi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download some essential resources for text processing\n",
        "import nltk\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:31:15.532244Z",
          "iopub.execute_input": "2023-04-13T11:31:15.532621Z",
          "iopub.status.idle": "2023-04-13T11:31:15.618541Z",
          "shell.execute_reply.started": "2023-04-13T11:31:15.532565Z",
          "shell.execute_reply": "2023-04-13T11:31:15.617490Z"
        },
        "trusted": true,
        "id": "5ZUrj6aIIusi",
        "outputId": "be10a568-3519-4e18-962d-00237ea91470"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n",
          "output_type": "stream"
        },
        {
          "execution_count": 51,
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The nltk.download() function is used to download NLTK data and resources\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('all')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:31:15.619956Z",
          "iopub.execute_input": "2023-04-13T11:31:15.620391Z",
          "iopub.status.idle": "2023-04-13T11:31:34.903819Z",
          "shell.execute_reply.started": "2023-04-13T11:31:15.620353Z",
          "shell.execute_reply": "2023-04-13T11:31:34.902650Z"
        },
        "trusted": true,
        "id": "tcVCGOUDIusi",
        "outputId": "d9df7fda-b431-4f58-977e-a2862c89a59e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data] Downloading collection 'all'\n[nltk_data]    | \n[nltk_data]    | Downloading package abc to /usr/share/nltk_data...\n[nltk_data]    |   Package abc is already up-to-date!\n[nltk_data]    | Downloading package alpino to /usr/share/nltk_data...\n[nltk_data]    |   Package alpino is already up-to-date!\n[nltk_data]    | Downloading package averaged_perceptron_tagger to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n[nltk_data]    |       to-date!\n[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping\n[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n[nltk_data]    | Downloading package basque_grammars to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package basque_grammars is already up-to-date!\n[nltk_data]    | Downloading package bcp47 to /usr/share/nltk_data...\n[nltk_data]    | Downloading package biocreative_ppi to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n[nltk_data]    | Downloading package bllip_wsj_no_aux to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n[nltk_data]    | Downloading package book_grammars to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package book_grammars is already up-to-date!\n[nltk_data]    | Downloading package brown to /usr/share/nltk_data...\n[nltk_data]    |   Package brown is already up-to-date!\n[nltk_data]    | Downloading package brown_tei to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package brown_tei is already up-to-date!\n[nltk_data]    | Downloading package cess_cat to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package cess_cat is already up-to-date!\n[nltk_data]    | Downloading package cess_esp to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package cess_esp is already up-to-date!\n[nltk_data]    | Downloading package chat80 to /usr/share/nltk_data...\n[nltk_data]    |   Package chat80 is already up-to-date!\n[nltk_data]    | Downloading package city_database to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package city_database is already up-to-date!\n[nltk_data]    | Downloading package cmudict to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package cmudict is already up-to-date!\n[nltk_data]    | Downloading package comparative_sentences to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n[nltk_data]    | Downloading package comtrans to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package comtrans is already up-to-date!\n[nltk_data]    | Downloading package conll2000 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package conll2000 is already up-to-date!\n[nltk_data]    | Downloading package conll2002 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package conll2002 is already up-to-date!\n[nltk_data]    | Downloading package conll2007 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package conll2007 is already up-to-date!\n[nltk_data]    | Downloading package crubadan to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package crubadan is already up-to-date!\n[nltk_data]    | Downloading package dependency_treebank to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package dependency_treebank is already up-to-date!\n[nltk_data]    | Downloading package dolch to /usr/share/nltk_data...\n[nltk_data]    |   Unzipping corpora/dolch.zip.\n[nltk_data]    | Downloading package europarl_raw to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package europarl_raw is already up-to-date!\n[nltk_data]    | Downloading package extended_omw to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    | Downloading package floresta to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package floresta is already up-to-date!\n[nltk_data]    | Downloading package framenet_v15 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n[nltk_data]    | Downloading package framenet_v17 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n[nltk_data]    | Downloading package gazetteers to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package gazetteers is already up-to-date!\n[nltk_data]    | Downloading package genesis to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package genesis is already up-to-date!\n[nltk_data]    | Downloading package gutenberg to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package gutenberg is already up-to-date!\n[nltk_data]    | Downloading package ieer to /usr/share/nltk_data...\n[nltk_data]    |   Package ieer is already up-to-date!\n[nltk_data]    | Downloading package inaugural to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package inaugural is already up-to-date!\n[nltk_data]    | Downloading package indian to /usr/share/nltk_data...\n[nltk_data]    |   Package indian is already up-to-date!\n[nltk_data]    | Downloading package jeita to /usr/share/nltk_data...\n[nltk_data]    |   Package jeita is already up-to-date!\n[nltk_data]    | Downloading package kimmo to /usr/share/nltk_data...\n[nltk_data]    |   Package kimmo is already up-to-date!\n[nltk_data]    | Downloading package knbc to /usr/share/nltk_data...\n[nltk_data]    |   Package knbc is already up-to-date!\n[nltk_data]    | Downloading package large_grammars to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package large_grammars is already up-to-date!\n[nltk_data]    | Downloading package lin_thesaurus to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n[nltk_data]    | Downloading package mac_morpho to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package mac_morpho is already up-to-date!\n[nltk_data]    | Downloading package machado to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package machado is already up-to-date!\n[nltk_data]    | Downloading package masc_tagged to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package masc_tagged is already up-to-date!\n[nltk_data]    | Downloading package maxent_ne_chunker to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n[nltk_data]    |       to-date!\n[nltk_data]    | Downloading package moses_sample to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package moses_sample is already up-to-date!\n[nltk_data]    | Downloading package movie_reviews to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package movie_reviews is already up-to-date!\n[nltk_data]    | Downloading package mte_teip5 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package mte_teip5 is already up-to-date!\n[nltk_data]    | Downloading package mwa_ppdb to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n[nltk_data]    | Downloading package names to /usr/share/nltk_data...\n[nltk_data]    |   Package names is already up-to-date!\n[nltk_data]    | Downloading package nombank.1.0 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    | Downloading package nonbreaking_prefixes to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n[nltk_data]    | Downloading package nps_chat to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package nps_chat is already up-to-date!\n[nltk_data]    | Downloading package omw to /usr/share/nltk_data...\n[nltk_data]    |   Package omw is already up-to-date!\n[nltk_data]    | Downloading package omw-1.4 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package omw-1.4 is already up-to-date!\n[nltk_data]    | Downloading package opinion_lexicon to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n[nltk_data]    | Downloading package panlex_swadesh to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    | Downloading package paradigms to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package paradigms is already up-to-date!\n[nltk_data]    | Downloading package pe08 to /usr/share/nltk_data...\n[nltk_data]    |   Unzipping corpora/pe08.zip.\n[nltk_data]    | Downloading package perluniprops to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping misc/perluniprops.zip.\n[nltk_data]    | Downloading package pil to /usr/share/nltk_data...\n[nltk_data]    |   Package pil is already up-to-date!\n[nltk_data]    | Downloading package pl196x to /usr/share/nltk_data...\n[nltk_data]    |   Package pl196x is already up-to-date!\n[nltk_data]    | Downloading package porter_test to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package porter_test is already up-to-date!\n[nltk_data]    | Downloading package ppattach to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package ppattach is already up-to-date!\n[nltk_data]    | Downloading package problem_reports to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package problem_reports is already up-to-date!\n[nltk_data]    | Downloading package product_reviews_1 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n[nltk_data]    | Downloading package product_reviews_2 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n[nltk_data]    | Downloading package propbank to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package propbank is already up-to-date!\n[nltk_data]    | Downloading package pros_cons to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package pros_cons is already up-to-date!\n[nltk_data]    | Downloading package ptb to /usr/share/nltk_data...\n[nltk_data]    |   Package ptb is already up-to-date!\n[nltk_data]    | Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]    |   Package punkt is already up-to-date!\n[nltk_data]    | Downloading package qc to /usr/share/nltk_data...\n[nltk_data]    |   Package qc is already up-to-date!\n[nltk_data]    | Downloading package reuters to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package reuters is already up-to-date!\n[nltk_data]    | Downloading package rslp to /usr/share/nltk_data...\n[nltk_data]    |   Package rslp is already up-to-date!\n[nltk_data]    | Downloading package rte to /usr/share/nltk_data...\n[nltk_data]    |   Package rte is already up-to-date!\n[nltk_data]    | Downloading package sample_grammars to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package sample_grammars is already up-to-date!\n[nltk_data]    | Downloading package semcor to /usr/share/nltk_data...\n[nltk_data]    |   Package semcor is already up-to-date!\n[nltk_data]    | Downloading package senseval to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package senseval is already up-to-date!\n[nltk_data]    | Downloading package sentence_polarity to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package sentence_polarity is already up-to-date!\n[nltk_data]    | Downloading package sentiwordnet to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package sentiwordnet is already up-to-date!\n[nltk_data]    | Downloading package shakespeare to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package shakespeare is already up-to-date!\n[nltk_data]    | Downloading package sinica_treebank to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package sinica_treebank is already up-to-date!\n[nltk_data]    | Downloading package smultron to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package smultron is already up-to-date!\n[nltk_data]    | Downloading package snowball_data to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package snowball_data is already up-to-date!\n[nltk_data]    | Downloading package spanish_grammars to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package spanish_grammars is already up-to-date!\n[nltk_data]    | Downloading package state_union to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package state_union is already up-to-date!\n[nltk_data]    | Downloading package stopwords to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package stopwords is already up-to-date!\n[nltk_data]    | Downloading package subjectivity to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package subjectivity is already up-to-date!\n[nltk_data]    | Downloading package swadesh to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package swadesh is already up-to-date!\n[nltk_data]    | Downloading package switchboard to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package switchboard is already up-to-date!\n[nltk_data]    | Downloading package tagsets to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package tagsets is already up-to-date!\n[nltk_data]    | Downloading package timit to /usr/share/nltk_data...\n[nltk_data]    |   Package timit is already up-to-date!\n[nltk_data]    | Downloading package toolbox to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package toolbox is already up-to-date!\n[nltk_data]    | Downloading package treebank to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package treebank is already up-to-date!\n[nltk_data]    | Downloading package twitter_samples to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package twitter_samples is already up-to-date!\n[nltk_data]    | Downloading package udhr to /usr/share/nltk_data...\n[nltk_data]    |   Package udhr is already up-to-date!\n[nltk_data]    | Downloading package udhr2 to /usr/share/nltk_data...\n[nltk_data]    |   Package udhr2 is already up-to-date!\n[nltk_data]    | Downloading package unicode_samples to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package unicode_samples is already up-to-date!\n[nltk_data]    | Downloading package universal_tagset to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package universal_tagset is already up-to-date!\n[nltk_data]    | Downloading package universal_treebanks_v20 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n[nltk_data]    |       date!\n[nltk_data]    | Downloading package vader_lexicon to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package vader_lexicon is already up-to-date!\n[nltk_data]    | Downloading package verbnet to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package verbnet is already up-to-date!\n[nltk_data]    | Downloading package verbnet3 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n[nltk_data]    | Downloading package webtext to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package webtext is already up-to-date!\n[nltk_data]    | Downloading package wmt15_eval to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n[nltk_data]    | Downloading package word2vec_sample to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package word2vec_sample is already up-to-date!\n[nltk_data]    | Downloading package wordnet to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package wordnet is already up-to-date!\n[nltk_data]    | Downloading package wordnet2021 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    | Downloading package wordnet2022 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n[nltk_data]    | Downloading package wordnet31 to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    | Downloading package wordnet_ic to\n[nltk_data]    |     /usr/share/nltk_data...\n[nltk_data]    |   Package wordnet_ic is already up-to-date!\n[nltk_data]    | Downloading package words to /usr/share/nltk_data...\n[nltk_data]    |   Package words is already up-to-date!\n[nltk_data]    | Downloading package ycoe to /usr/share/nltk_data...\n[nltk_data]    |   Package ycoe is already up-to-date!\n[nltk_data]    | \n[nltk_data]  Done downloading collection all\n",
          "output_type": "stream"
        },
        {
          "execution_count": 52,
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This command removes the directory \n",
        "/usr/share/nltk_data/corpora/wordnet and all its contents,\n",
        "and then recursively copies the directory \n",
        "/usr/share/nltk_data/corpora/wordnet2022 to /usr/share/nltk_data/corpora/wordnet.\"\n",
        "\"\"\"\n",
        "!cp -rf /usr/share/nltk_data/corpora/wordnet2022 /usr/share/nltk_data/corpora/wordnet "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:31:34.912417Z",
          "iopub.execute_input": "2023-04-13T11:31:34.912730Z",
          "iopub.status.idle": "2023-04-13T11:31:36.116136Z",
          "shell.execute_reply.started": "2023-04-13T11:31:34.912694Z",
          "shell.execute_reply": "2023-04-13T11:31:36.114736Z"
        },
        "trusted": true,
        "id": "7obsSO9iIusi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "building function to clean data from\n",
        "1- html tags\n",
        "2- digits\n",
        "3- special characters\n",
        "4- links \n",
        "5- all whitespaces\n",
        "6-single letter character\n",
        "7- Tokenize the text into words\n",
        "\"\"\"\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "def clean_text(text, for_embedding):\n",
        "    # a regular expression pattern that matches one or more whitespace characters (spaces, tabs, and newlines)\n",
        "    #re.IGNORECASE flag is used to make the regular expression case-insensitive\n",
        "    whitespace = re.compile(r\"\\s+\", re.IGNORECASE)\n",
        "    # a regular expression pattern that matches HTML or XML tags\n",
        "    tags = re.compile(r\"<.*?>\") \n",
        "    # a regular expression pattern that matches any single character (i.e., a character that is not part of a word)\n",
        "    single_char = re.compile(r\"\\b^[^A-Za-zÀ-ž0-9]+\\b\", re.IGNORECASE) \n",
        "    if for_embedding:\n",
        "        # Keep punctuation\n",
        "        single_char = re.compile(r\"\\b[A-Za-zÀ-ž,.!?]\\b\", re.IGNORECASE)\n",
        "    \n",
        "    # Remove any HTML tags\n",
        "    text = re.sub(tags, ' ', text)\n",
        "\n",
        "    # Remove single letter chars\n",
        "    text = re.sub(single_char, ' ', text)\n",
        "\n",
        "    # Convert all whitespaces (tabs etc.) to single wspace\n",
        "    text = re.sub(whitespace, ' ', text)\n",
        "\n",
        "    # Tokenize the text into words\n",
        "    word_tokens = word_tokenize(text)\n",
        " \n",
        "    return word_tokens "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:31:36.117958Z",
          "iopub.execute_input": "2023-04-13T11:31:36.118326Z",
          "iopub.status.idle": "2023-04-13T11:31:37.880862Z",
          "shell.execute_reply.started": "2023-04-13T11:31:36.118291Z",
          "shell.execute_reply": "2023-04-13T11:31:37.879554Z"
        },
        "trusted": true,
        "id": "HDAdMxFLIusi",
        "outputId": "0496eda5-c497-4f77-e17a-7651bee6edb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 54,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'\\nbuilding function to clean data from\\n1- html tags\\n2- digits\\n3- special characters\\n4- links \\n5- all whitespaces\\n6-single letter character\\n7- Tokenize the text into words\\n'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Method 1: Text Cleaning with Lemmatization\n",
        "# lemmatization mean drop Extra letters from each word and back the word to its base \n",
        "\n",
        "\"\"\"\n",
        "An Examble \n",
        "the word of \"studies\" after lemmatization will be \"study\"\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "This method will clean the text by removing any unnecessary characters, \n",
        "such as stop words, and punctuation marks, and then perform lemmatization on the remaining words.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def cleaning_with_lemmatization(text: str, for_embedding= False):\n",
        "    # make Tokenization and tag the words\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    word_tokens = clean_text(text,for_embedding)\n",
        "    if for_embedding:\n",
        "        words_filtered = word_tokens \n",
        "    else:\n",
        "        tokens_tokens_lower = [word.lower() for word in word_tokens]\n",
        "        words_filtered = [lemmatizer.lemmatize(word) for word in tokens_tokens_lower if word not in stop_words]\n",
        "    clean_texts = \" \".join(words_filtered)\n",
        "    return clean_texts"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:31:37.882792Z",
          "iopub.execute_input": "2023-04-13T11:31:37.883315Z",
          "iopub.status.idle": "2023-04-13T11:31:37.892284Z",
          "shell.execute_reply.started": "2023-04-13T11:31:37.883265Z",
          "shell.execute_reply": "2023-04-13T11:31:37.891213Z"
        },
        "trusted": true,
        "id": "Mddwp_QHIusi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# include only rows where the length of the text in summary feature string is greater than 20 characters\n",
        "train[\"summary\"] = train.loc[train[\"summary\"].str.len() > 20, \"summary\"]\n",
        "test[\"summary\"] = test.loc[test[\"summary\"].str.len() > 20, \"summary\"]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:31:37.893730Z",
          "iopub.execute_input": "2023-04-13T11:31:37.894247Z",
          "iopub.status.idle": "2023-04-13T11:31:37.902035Z",
          "shell.execute_reply.started": "2023-04-13T11:31:37.894212Z",
          "shell.execute_reply": "2023-04-13T11:31:37.900977Z"
        },
        "trusted": true,
        "id": "kVoOdKVjIusj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean and make of lemmatization on summary feature in train data\n",
        "train[\"summary\"]= train[\"summary\"].map(lambda x: cleaning_with_lemmatization(x ,for_embedding=False) if isinstance(x, str) else x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:31:37.903731Z",
          "iopub.execute_input": "2023-04-13T11:31:37.904533Z",
          "iopub.status.idle": "2023-04-13T11:31:37.913435Z",
          "shell.execute_reply.started": "2023-04-13T11:31:37.904496Z",
          "shell.execute_reply": "2023-04-13T11:31:37.912312Z"
        },
        "trusted": true,
        "id": "vzf3UnZVIusj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean and make of lemmatization on summary feature in test data\n",
        "test[\"summary\"]= test[\"summary\"].map(lambda x: cleaning_with_lemmatization(x ,for_embedding=False) if isinstance(x, str) else x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:31:37.914942Z",
          "iopub.execute_input": "2023-04-13T11:31:37.916068Z",
          "iopub.status.idle": "2023-04-13T11:31:37.925922Z",
          "shell.execute_reply.started": "2023-04-13T11:31:37.916031Z",
          "shell.execute_reply": "2023-04-13T11:31:37.924886Z"
        },
        "trusted": true,
        "id": "N9oWrZNvIusj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data preprocessing\n",
        "# preprocess on image data\n",
        "\"\"\"\n",
        "1- The function tries to open the image file using the PIL  module's \"Image.open\" method.\n",
        "2- It then converts the image to grayscale (\"LA\" mode) and resizes it to a 64x64 pixel image.\n",
        "3- The resulting image is then converted to a NumPy array using the \"np.array\" method.\n",
        "\"\"\"\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def load_image(file):\n",
        "    try:\n",
        "        image = Image.open(\n",
        "            file\n",
        "        ).convert('LA').resize((64, 64))\n",
        "        arr = np.array(image)\n",
        "    except:\n",
        "        arr = np.zeros((64, 64,2))\n",
        "    return arr"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T16:08:36.386400Z",
          "iopub.execute_input": "2023-04-13T16:08:36.387755Z",
          "iopub.status.idle": "2023-04-13T16:08:36.395867Z",
          "shell.execute_reply.started": "2023-04-13T16:08:36.387700Z",
          "shell.execute_reply": "2023-04-13T16:08:36.394428Z"
        },
        "trusted": true,
        "id": "5hUYGuhgIusj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading images:\n",
        "\"\"\"\n",
        "The \"tqdm\" method is used to display a progress bar during the loop, \n",
        "which can be helpful for keeping track of the processing time for large datasets.\n",
        "\"\"\"\n",
        "x_train_image = np.array([load_image('/kaggle/input/copy-of-cisc-873-dm-w23-a4/a4/'+str(i)) for i in tqdm(train[\"image\"])])\n",
        "x_test_image = np.array([load_image('/kaggle/input/copy-of-cisc-873-dm-w23-a4/a4/'+str(i)) for i in tqdm(test[\"image\"])])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T16:10:24.841587Z",
          "iopub.execute_input": "2023-04-13T16:10:24.841968Z",
          "iopub.status.idle": "2023-04-13T16:12:47.617170Z",
          "shell.execute_reply.started": "2023-04-13T16:10:24.841936Z",
          "shell.execute_reply": "2023-04-13T16:12:47.615995Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "464e75c1b8fd4ee48d11b97651a697a2",
            "845077c71c64401d8cd300021964593c"
          ]
        },
        "id": "mKr36ByDIusj",
        "outputId": "e9f50f45-b6d7-46f3-985e-5cef170eb848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/7326 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "464e75c1b8fd4ee48d11b97651a697a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/7360 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "845077c71c64401d8cd300021964593c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get type \n",
        "y_train_type = train.type\n",
        "# get price\n",
        "y_train_price = train.price"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T16:12:54.980561Z",
          "iopub.execute_input": "2023-04-13T16:12:54.980949Z",
          "iopub.status.idle": "2023-04-13T16:12:54.986878Z",
          "shell.execute_reply.started": "2023-04-13T16:12:54.980915Z",
          "shell.execute_reply": "2023-04-13T16:12:54.985751Z"
        },
        "trusted": true,
        "id": "dVSNdjhiIusj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading summary: (force convert some of the non-string cell to string)\n",
        "# selecting the \"summary\" column from the \"train\" DataFrame and converting its data type to a string using the \"astype\" method.\n",
        "# selecting the \"summary\" column from the \"test\" DataFrame and converting its data type to a string using the \"astype\" method.\n",
        "x_train_text = train.summary.astype('str')\n",
        "x_test_text = test.summary.astype('str')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T16:12:56.882886Z",
          "iopub.execute_input": "2023-04-13T16:12:56.883425Z",
          "iopub.status.idle": "2023-04-13T16:12:56.892463Z",
          "shell.execute_reply.started": "2023-04-13T16:12:56.883356Z",
          "shell.execute_reply": "2023-04-13T16:12:56.891176Z"
        },
        "trusted": true,
        "id": "agK2NfsuIusk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess on text data\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "1- building Tokenizer object from the Keras preprocessing module with a vocabulary size of \n",
        "\"vocab_size\" and fits it on the text data in \"x_train_text\" using the \"fit_on_texts\" method.\n",
        "This builds the vocabulary from the training set.\n",
        "2- The \"text_to_sequences\" method converts the text data to sequences of word indices based on the vocabulary built by the Tokenizer object\n",
        "\"\"\"\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pprint import pprint\n",
        "\n",
        "vocab_size = 40000\n",
        "max_len = 100\n",
        "\n",
        "\n",
        "# build vocabulary from training set\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(x_train_text)\n",
        "\n",
        "\n",
        "def _preprocess(list_of_text):\n",
        "    return pad_sequences(\n",
        "        tokenizer.texts_to_sequences(list_of_text),\n",
        "        maxlen=max_len,\n",
        "        padding='post',\n",
        "    )\n",
        "    \n",
        "\n",
        "# padding is done inside: \n",
        "x_train_text_id = _preprocess(x_train_text)\n",
        "\n",
        "print(x_train_text_id.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:35:03.786931Z",
          "iopub.execute_input": "2023-04-13T11:35:03.787469Z",
          "iopub.status.idle": "2023-04-13T11:35:04.511904Z",
          "shell.execute_reply.started": "2023-04-13T11:35:03.787432Z",
          "shell.execute_reply": "2023-04-13T11:35:04.510706Z"
        },
        "trusted": true,
        "id": "hMF60zNxIusk",
        "outputId": "6f4eb63c-7965-4f1c-9735-5fec679cd4f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "(7326, 100)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# apply the function of _preprocess on summary feature\n",
        "x_test_text = _preprocess(test.summary.astype('str'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:35:04.513621Z",
          "iopub.execute_input": "2023-04-13T11:35:04.513999Z",
          "iopub.status.idle": "2023-04-13T11:35:04.850923Z",
          "shell.execute_reply.started": "2023-04-13T11:35:04.513960Z",
          "shell.execute_reply": "2023-04-13T11:35:04.850011Z"
        },
        "trusted": true,
        "id": "6g7jwg83Iusk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can use the tokenizer to convert IDs to words.\n",
        "pprint(tokenizer.sequences_to_texts(x_train_text_id[:5]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:35:04.852429Z",
          "iopub.execute_input": "2023-04-13T11:35:04.852811Z",
          "iopub.status.idle": "2023-04-13T11:35:04.860126Z",
          "shell.execute_reply.started": "2023-04-13T11:35:04.852775Z",
          "shell.execute_reply": "2023-04-13T11:35:04.858990Z"
        },
        "trusted": true,
        "id": "xmdA4O3tIusk",
        "outputId": "69d8b6f3-f2b8-4e23-f1d7-6b813a722134"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "['spacious sunny and cozy modern apartment in the heart of montreal this 3 '\n 'bedroom centrally located in the very popular plateau mont royal '\n 'neighborhood in the middle of prince arthur pedestrian only street close to '\n 'all amenities restaurants coffee house bars clubs shopping universities '\n 'subway stations experience montreal like a real local resident be in the '\n 'heart of the action grand prix week grill saint laurent festival mural 2019 '\n 'and so much more',\n 'located in one of the most vibrant and accessible locations of downtown '\n 'montreal this one bedroom condo will not only impress you but leave you with '\n 'one of the most memorable experiences it is walking distance of the popular '\n 'sainte catherine street the bell center the old port lachine canal '\n 'bonaventure metro and much much more',\n 'pretty and cozy accommodation 10 minutes from downtown montreal grocery '\n 'store pharmacy saq restaurants and public transport nearby two closed '\n 'bedrooms that can accommodate 4 adults',\n 'beautiful and spacious 1076 sc ft 100 mc condo on the 1th floor in the west '\n 'island of montreal located in a quiet residential area near a number of '\n 'superb green spaces 3 min car from highways 13 40 7 min from le marché de '\n \"l'ouest 15 min from the airport 6 min walk from sunnybrooke train station \"\n 'that goes downtown mtl in 20 min and is close to the beautiful nature park '\n 'bois de liesse walk and bike paths in summer and snowshoe and cross country '\n 'skiing paths in winter',\n \"very large ''rustic'' and very pleasant apartment for rent in a nice \"\n 'neighborhood of montreal a large bedroom in the basement and on the ground '\n 'floor there is a bedroom a large kitchen dining room and a large double '\n 'living room the kitchen offers many machines such as a blender a food '\n 'processor a coffee maker a panini machine a waffle machine very close to the '\n 'riverfront and downtown verdun and montreal on foot by metro bike or bus']\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can use the tokenizer to convert IDs to words.\n",
        "pprint(tokenizer.sequences_to_texts(x_test_text[:5]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:35:04.861845Z",
          "iopub.execute_input": "2023-04-13T11:35:04.862189Z",
          "iopub.status.idle": "2023-04-13T11:35:04.872423Z",
          "shell.execute_reply.started": "2023-04-13T11:35:04.862153Z",
          "shell.execute_reply": "2023-04-13T11:35:04.871273Z"
        },
        "trusted": true,
        "id": "75TSY0WCIusk",
        "outputId": "9ddcb07b-ba94-4d8a-ca4e-3b5246aa82e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "['charming warm house is ready to host you here in multi cultural parc ex '\n 'short walk to parc jarry to watch rogers cup and on major bus lines to metro '\n 'and downtown',\n 'the room is spacious and bright in an apartment shared with three other '\n 'roommates',\n 'large comfortable room located in the basement of our house a large bathroom '\n 'with shower washer and dryer are included',\n 'near a metro orange line 10 minutes walking ahuntsic residential area of '\n '\\u200b\\u200bmontreal north center easy street parking one bedroom double bed '\n '2 people maximum during my presence 1 bedroom and 2 bedrooms during my '\n 'absence friendly and warm',\n 'very bright appartment and very cosy 2 separate bedrooms 1 with a queen size '\n 'and the other with a double sofa bed located in verdun near promenade '\n 'wellington and its nice bars and restaurants']\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Trial 1 : Dropout Layer**"
      ],
      "metadata": {
        "id": "QqL-J-J9Iusk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "the steps : \n",
        "1- The code you provided defines a multi-task neural network model using the Keras API with two inputs and two outputs.\n",
        "2- in two inputs: image data and text data, and outputs two labels: the price of real estate and it's type\n",
        "3- The text input is processed using an embedding layer and a simple average pooling layer that called \"reduce_mean\"\n",
        "4- the image input is processed using two convolutional layers, a dropout layer, a max pooling layer, and a flatten layer.\n",
        "5- The resulting output from the text and image processing layers are then concatenated and fed into two separate dense layers,\n",
        "one for each output task.\n",
        "6- The model is compiled with the Adam optimizer and sparse categorical cross-entropy loss functions for both tasks\n",
        "7- The loss weights are set to 0.2 for the \"type\" output and 0.8 for the \"price\" \n",
        "8- The metrics for evaluation are set to sparse categorical accuracy for both tasks.\n",
        "9-  make summarization on model\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "thoughts and observations\n",
        "1- I used  dropout layer after convolution  because adding dropout after the convolutional layers,\n",
        "the model can learn more diverse and less correlated features,\n",
        "which can improve its performance on new, unseen data and reduce overfitting.\n",
        "\n",
        "2- I think the model will fit well with the dropout technique \n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "my plan is using multiple Conv2d layer without dropout technique.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "# here we have two inputs. one for image and the other for text.\n",
        "in_text = keras.Input(batch_shape=(None, max_len))\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2))\n",
        "\n",
        "# text part\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text)\n",
        "averaged = tf.reduce_mean(embedded, axis=1) \n",
        "\n",
        "# image part \n",
        "cov1 = Conv2D(10, (15,15) , activation='relu')(in_image) # 10 number of filters  and  (15, 15) size of filter\n",
        "cov2 = Conv2D(10, (15,15) , activation='relu')(cov1) # 10 number of filters  and  (15, 15) size of filter\n",
        "con_drop = Dropout(0.2)(cov2) #add drop out layer \n",
        "pl = MaxPool2D((10, 10))(con_drop)#add maxpooling layer \n",
        "\n",
        "flattened = Flatten()(pl)#add flatten layer \n",
        "\n",
        "# combinig \n",
        "fused = tf.concat([averaged, flattened], axis=-1)#merge between two input \n",
        "\n",
        "p_type = Dense(length_of_type, activation='softmax', name='type')(fused)#layer for predict type \n",
        "p_price = Dense(length_of_price, activation='softmax', name='price')(fused)#layer for predict price \n",
        "\n",
        "\n",
        "model_dropout = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text,\n",
        "        'image': in_image\n",
        "    },\n",
        "    outputs={\n",
        "        'type': p_type,\n",
        "        'price': p_price,\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "model_dropout.compile(\n",
        "    optimizer=Adam(),#using adam optimizer with learning rate 1e-3\n",
        "    loss={\n",
        "        'type': 'sparse_categorical_crossentropy',\n",
        "        'price': 'sparse_categorical_crossentropy',\n",
        "    },\n",
        "    loss_weights={\n",
        "        'type': 0.2, \n",
        "        'price': 0.8,       \n",
        "    },\n",
        "    metrics={\n",
        "        'type': ['SparseCategoricalAccuracy'],\n",
        "        'price': ['SparseCategoricalAccuracy'],\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "model_dropout.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:35:04.912435Z",
          "iopub.execute_input": "2023-04-13T11:35:04.914880Z",
          "iopub.status.idle": "2023-04-13T11:35:07.594270Z",
          "shell.execute_reply.started": "2023-04-13T11:35:04.914775Z",
          "shell.execute_reply": "2023-04-13T11:35:07.593437Z"
        },
        "trusted": true,
        "id": "rdaow_-hIusk",
        "outputId": "64a70319-8d49-4dfa-e1b3-eeca71d5b612"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_2 (InputLayer)           [(None, 64, 64, 2)]  0           []                               \n                                                                                                  \n conv2d (Conv2D)                (None, 50, 50, 10)   4510        ['input_2[0][0]']                \n                                                                                                  \n conv2d_1 (Conv2D)              (None, 36, 36, 10)   22510       ['conv2d[0][0]']                 \n                                                                                                  \n input_1 (InputLayer)           [(None, 100)]        0           []                               \n                                                                                                  \n dropout (Dropout)              (None, 36, 36, 10)   0           ['conv2d_1[0][0]']               \n                                                                                                  \n embedding (Embedding)          (None, 100, 100)     4000000     ['input_1[0][0]']                \n                                                                                                  \n max_pooling2d (MaxPooling2D)   (None, 3, 3, 10)     0           ['dropout[0][0]']                \n                                                                                                  \n tf.math.reduce_mean (TFOpLambd  (None, 100)         0           ['embedding[0][0]']              \n a)                                                                                               \n                                                                                                  \n flatten (Flatten)              (None, 90)           0           ['max_pooling2d[0][0]']          \n                                                                                                  \n tf.concat (TFOpLambda)         (None, 190)          0           ['tf.math.reduce_mean[0][0]',    \n                                                                  'flatten[0][0]']                \n                                                                                                  \n price (Dense)                  (None, 24)           4584        ['tf.concat[0][0]']              \n                                                                                                  \n type (Dense)                   (None, 24)           4584        ['tf.concat[0][0]']              \n                                                                                                  \n==================================================================================================\nTotal params: 4,036,188\nTrainable params: 4,036,188\nNon-trainable params: 0\n__________________________________________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set seed to reproduce results\n",
        "\"\"\"\n",
        "1- trains the \"model_dropout\" neural network model using the \"fit\" method\n",
        "2- The training data consists of two inputs: \"x_train_text_id\" ,\"x_train_image\" . The target outputs consist of two separate arrays: \n",
        "\"y_train_type\" for the real estate type classification and \"y_train_price\" for the real estate price range classification.\n",
        "3- The model is trained for 10 epochs with a batch size of 16 and a validation split of 0.2,\n",
        "meaning that 20% of the training data is reserved for validation during training\n",
        "\"\"\"\n",
        "seed = 2021\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "history= model_dropout.fit(\n",
        "    x={\n",
        "        'summary': x_train_text_id,\n",
        "        'image': x_train_image\n",
        "    },\n",
        "    y={\n",
        "        'type': y_train_type,\n",
        "        'price': y_train_price,\n",
        "    },\n",
        "    epochs=10,\n",
        "    batch_size=16,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=6,)\n",
        "    ],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:35:07.595420Z",
          "iopub.execute_input": "2023-04-13T11:35:07.595778Z",
          "iopub.status.idle": "2023-04-13T11:36:20.548986Z",
          "shell.execute_reply.started": "2023-04-13T11:35:07.595739Z",
          "shell.execute_reply": "2023-04-13T11:36:20.547956Z"
        },
        "trusted": true,
        "id": "XbM9ocauIusl",
        "outputId": "1349f540-8d3e-43e4-968f-296dbd2c376e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/10\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2023-04-13 11:35:09.799887: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "367/367 [==============================] - 35s 74ms/step - loss: 2.0124 - price_loss: 2.0204 - type_loss: 1.9803 - price_sparse_categorical_accuracy: 0.6067 - type_sparse_categorical_accuracy: 0.7452 - val_loss: 0.8578 - val_price_loss: 0.8323 - val_type_loss: 0.9598 - val_price_sparse_categorical_accuracy: 0.6241 - val_type_sparse_categorical_accuracy: 0.7688\nEpoch 2/10\n367/367 [==============================] - 8s 21ms/step - loss: 0.8576 - price_loss: 0.8234 - type_loss: 0.9942 - price_sparse_categorical_accuracy: 0.6206 - type_sparse_categorical_accuracy: 0.7560 - val_loss: 0.8341 - val_price_loss: 0.8059 - val_type_loss: 0.9468 - val_price_sparse_categorical_accuracy: 0.6317 - val_type_sparse_categorical_accuracy: 0.7688\nEpoch 3/10\n367/367 [==============================] - 5s 15ms/step - loss: 0.8277 - price_loss: 0.7894 - type_loss: 0.9809 - price_sparse_categorical_accuracy: 0.6283 - type_sparse_categorical_accuracy: 0.7560 - val_loss: 0.8063 - val_price_loss: 0.7737 - val_type_loss: 0.9369 - val_price_sparse_categorical_accuracy: 0.6439 - val_type_sparse_categorical_accuracy: 0.7688\nEpoch 4/10\n367/367 [==============================] - 3s 9ms/step - loss: 0.7935 - price_loss: 0.7495 - type_loss: 0.9694 - price_sparse_categorical_accuracy: 0.6532 - type_sparse_categorical_accuracy: 0.7560 - val_loss: 0.7817 - val_price_loss: 0.7452 - val_type_loss: 0.9274 - val_price_sparse_categorical_accuracy: 0.6610 - val_type_sparse_categorical_accuracy: 0.7688\nEpoch 5/10\n367/367 [==============================] - 3s 9ms/step - loss: 0.7601 - price_loss: 0.7113 - type_loss: 0.9553 - price_sparse_categorical_accuracy: 0.6814 - type_sparse_categorical_accuracy: 0.7560 - val_loss: 0.7632 - val_price_loss: 0.7250 - val_type_loss: 0.9159 - val_price_sparse_categorical_accuracy: 0.6658 - val_type_sparse_categorical_accuracy: 0.7688\nEpoch 6/10\n367/367 [==============================] - 4s 10ms/step - loss: 0.7297 - price_loss: 0.6766 - type_loss: 0.9419 - price_sparse_categorical_accuracy: 0.7068 - type_sparse_categorical_accuracy: 0.7560 - val_loss: 0.7486 - val_price_loss: 0.7090 - val_type_loss: 0.9072 - val_price_sparse_categorical_accuracy: 0.6855 - val_type_sparse_categorical_accuracy: 0.7688\nEpoch 7/10\n367/367 [==============================] - 3s 9ms/step - loss: 0.7029 - price_loss: 0.6465 - type_loss: 0.9286 - price_sparse_categorical_accuracy: 0.7196 - type_sparse_categorical_accuracy: 0.7560 - val_loss: 0.7398 - val_price_loss: 0.7002 - val_type_loss: 0.8981 - val_price_sparse_categorical_accuracy: 0.6862 - val_type_sparse_categorical_accuracy: 0.7688\nEpoch 8/10\n367/367 [==============================] - 4s 11ms/step - loss: 0.6775 - price_loss: 0.6185 - type_loss: 0.9137 - price_sparse_categorical_accuracy: 0.7372 - type_sparse_categorical_accuracy: 0.7560 - val_loss: 0.7318 - val_price_loss: 0.6927 - val_type_loss: 0.8882 - val_price_sparse_categorical_accuracy: 0.7012 - val_type_sparse_categorical_accuracy: 0.7688\nEpoch 9/10\n367/367 [==============================] - 3s 9ms/step - loss: 0.6536 - price_loss: 0.5926 - type_loss: 0.8978 - price_sparse_categorical_accuracy: 0.7495 - type_sparse_categorical_accuracy: 0.7560 - val_loss: 0.7294 - val_price_loss: 0.6922 - val_type_loss: 0.8782 - val_price_sparse_categorical_accuracy: 0.6896 - val_type_sparse_categorical_accuracy: 0.7688\nEpoch 10/10\n367/367 [==============================] - 3s 8ms/step - loss: 0.6296 - price_loss: 0.5668 - type_loss: 0.8808 - price_sparse_categorical_accuracy: 0.7652 - type_sparse_categorical_accuracy: 0.7561 - val_loss: 0.7276 - val_price_loss: 0.6926 - val_type_loss: 0.8678 - val_price_sparse_categorical_accuracy: 0.6924 - val_type_sparse_categorical_accuracy: 0.7688\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1- use \"predict\" method to generate predictions on new test data, \n",
        "which consists of both text and image inputs. The text input is represented by the \"x_test_text\" variable,\n",
        "and the image input is represented by the \"x_test_image\" variable.\n",
        "\n",
        "2-  \"argmax\" use to  convert the  probabilities into predicted categories \n",
        "\"\"\"\n",
        "y_predict_dropout = model_dropout.predict(\n",
        "    {\n",
        "        'summary': x_test_text,\n",
        "        'image': x_test_image\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "# probabilities\n",
        "price_predicted_dropout = y_predict_dropout['price'] #predict one target from multi objective \n",
        "print(price_predicted_dropout)\n",
        "\n",
        "# categories\n",
        "price_category_predicted_dropout = np.argmax(price_predicted_dropout, axis=1)\n",
        "print(price_category_predicted_dropout)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:36:20.552815Z",
          "iopub.execute_input": "2023-04-13T11:36:20.553783Z",
          "iopub.status.idle": "2023-04-13T11:36:22.285967Z",
          "shell.execute_reply.started": "2023-04-13T11:36:20.553741Z",
          "shell.execute_reply": "2023-04-13T11:36:22.284822Z"
        },
        "trusted": true,
        "id": "-atJNX3GIusl",
        "outputId": "c6db5f7c-afe4-4e44-afb5-be57a2b65172"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "230/230 [==============================] - 1s 2ms/step\n[[8.32926631e-01 1.31908149e-01 3.48950624e-02 ... 1.25524239e-05\n  2.40106674e-05 1.41656310e-05]\n [9.04407918e-01 7.09752664e-02 2.45207436e-02 ... 4.53655684e-06\n  8.81507640e-06 5.06066272e-06]\n [8.71435285e-01 8.99046659e-02 3.84228230e-02 ... 1.11106710e-05\n  2.10725702e-05 1.27045014e-05]\n ...\n [8.36533666e-01 1.33875504e-01 2.94866301e-02 ... 4.87665375e-06\n  9.84442431e-06 5.49604692e-06]\n [9.73674536e-01 1.73992068e-02 8.76167044e-03 ... 7.69843609e-06\n  1.33588101e-05 8.82964287e-06]\n [7.86975920e-01 1.75777093e-01 3.71042639e-02 ... 6.54816131e-06\n  1.32502355e-05 7.30347620e-06]]\n[0 0 0 ... 0 0 0]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create submission file\n",
        "pd.DataFrame(\n",
        "    {'id':test.id,\n",
        "     'price': price_category_predicted_dropout}\n",
        ").to_csv('trail_1.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:36:22.287598Z",
          "iopub.execute_input": "2023-04-13T11:36:22.288285Z",
          "iopub.status.idle": "2023-04-13T11:36:22.304981Z",
          "shell.execute_reply.started": "2023-04-13T11:36:22.288231Z",
          "shell.execute_reply": "2023-04-13T11:36:22.304058Z"
        },
        "trusted": true,
        "id": "BpmeGwnSIusl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Trial 2 : Conv2d layer**"
      ],
      "metadata": {
        "id": "wu_NCEb3Iusl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# trial 2\n",
        "\"\"\"\n",
        "the steps : \n",
        "1- The code provide defines a multi-task neural network model using the Keras API with two inputs and two outputs,\n",
        "2- in two inputs: image data and text data, and outputs two labels: the price of real estate and it's type\n",
        "3- The text input is processed using an embedding layer and a simple average pooling layer that called \"reduce_mean\"\n",
        "4- The image input is processed using three convolutional layers with different kernel sizes, followed by a max pooling layer and a flatten layer\n",
        "5- The resulting output from the text and image processing layers are then concatenated and fed into two separate dense layers,\n",
        "one for each output task.\n",
        "6- The model is compiled with the Adam optimizer and sparse categorical cross-entropy loss functions for both tasks\n",
        "7- The loss weights are set to 0.2 for the \"type\" output and 0.8 for the \"price\" \n",
        "8- The metrics for evaluation are set to sparse categorical accuracy for both tasks.\n",
        "9-  make summarization on model\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "thoughts and observations\n",
        "1- I used multiple convolution layers to enable the model to learn more complex and expressive representations of the input data  \n",
        "and prevent overfitting.\n",
        "\n",
        "2- I think the model will fit well with the multiple convolution layer\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "my plan is using LSTM technique \n",
        "\"\"\"\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "# here we have two inputs. one for image and the other for text.\n",
        "in_text = keras.Input(batch_shape=(None, max_len))\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2))\n",
        "\n",
        "# text part\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text)\n",
        "averaged = tf.reduce_mean(embedded, axis=1)\n",
        "\n",
        "\n",
        "# image part \n",
        "convolution1 =layers.Conv2D(15, 15 ,activation='relu')(in_image)\n",
        "convolution2 =layers.Conv2D(10, 10,activation='relu')(convolution1)\n",
        "convolution3=layers.Conv2D(15, 15,activation='relu')(convolution2)\n",
        "pl = MaxPool2D((3, 3))(convolution3)\n",
        "flattened = Flatten()(pl)\n",
        "\n",
        "#combinig\n",
        "fused_com = tf.concat([averaged, flattened], axis=-1)\n",
        "\n",
        "\n",
        "p_type = Dense(length_of_type, activation='softmax', name='type')(fused_com)\n",
        "p_price = Dense(length_of_price, activation='softmax', name='price')(fused_com)\n",
        "\n",
        "\n",
        "model_conv = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text,\n",
        "        'image': in_image\n",
        "    },\n",
        "    outputs={\n",
        "        'type': p_type,\n",
        "        'price': p_price,\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "model_conv.compile(\n",
        "    optimizer=Adam(),\n",
        "    loss={\n",
        "        'type': 'sparse_categorical_crossentropy',\n",
        "        'price': 'sparse_categorical_crossentropy',\n",
        "    },\n",
        "    loss_weights={\n",
        "        'type': 0.2,\n",
        "        'price': 0.8,       \n",
        "    },\n",
        "    metrics={\n",
        "        'type': ['SparseCategoricalAccuracy'],\n",
        "        'price': ['SparseCategoricalAccuracy'],\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "model_conv.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:36:22.306328Z",
          "iopub.execute_input": "2023-04-13T11:36:22.306778Z",
          "iopub.status.idle": "2023-04-13T11:36:22.440215Z",
          "shell.execute_reply.started": "2023-04-13T11:36:22.306740Z",
          "shell.execute_reply": "2023-04-13T11:36:22.439423Z"
        },
        "trusted": true,
        "id": "au8f5D1SIusl",
        "outputId": "41e658b5-1096-49b5-86c9-bb38361cfad1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"model_1\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_4 (InputLayer)           [(None, 64, 64, 2)]  0           []                               \n                                                                                                  \n conv2d_2 (Conv2D)              (None, 50, 50, 15)   6765        ['input_4[0][0]']                \n                                                                                                  \n conv2d_3 (Conv2D)              (None, 41, 41, 10)   15010       ['conv2d_2[0][0]']               \n                                                                                                  \n input_3 (InputLayer)           [(None, 100)]        0           []                               \n                                                                                                  \n conv2d_4 (Conv2D)              (None, 27, 27, 15)   33765       ['conv2d_3[0][0]']               \n                                                                                                  \n embedding_1 (Embedding)        (None, 100, 100)     4000000     ['input_3[0][0]']                \n                                                                                                  \n max_pooling2d_1 (MaxPooling2D)  (None, 9, 9, 15)    0           ['conv2d_4[0][0]']               \n                                                                                                  \n tf.math.reduce_mean_1 (TFOpLam  (None, 100)         0           ['embedding_1[0][0]']            \n bda)                                                                                             \n                                                                                                  \n flatten_1 (Flatten)            (None, 1215)         0           ['max_pooling2d_1[0][0]']        \n                                                                                                  \n tf.concat_1 (TFOpLambda)       (None, 1315)         0           ['tf.math.reduce_mean_1[0][0]',  \n                                                                  'flatten_1[0][0]']              \n                                                                                                  \n price (Dense)                  (None, 24)           31584       ['tf.concat_1[0][0]']            \n                                                                                                  \n type (Dense)                   (None, 24)           31584       ['tf.concat_1[0][0]']            \n                                                                                                  \n==================================================================================================\nTotal params: 4,118,708\nTrainable params: 4,118,708\nNon-trainable params: 0\n__________________________________________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1- trains the \"model_conv\" neural network model using the \"fit\" method\n",
        "2- The training data consists of two inputs: \"x_train_text_id\" ,\"x_train_image\" . The target outputs consist of two separate arrays: \n",
        "\"y_train_type\" for the real estate type classification and \"y_train_price\" for the real estate price range classification.\n",
        "3- The model is trained for 10 epochs with a batch size of 16 and a validation split of 0.2,\n",
        "meaning that 20% of the training data is reserved for validation during training\n",
        "\"\"\"\n",
        "history = model_conv.fit(\n",
        "    x={\n",
        "        'summary': x_train_text_id,\n",
        "        'image': x_train_image\n",
        "    },\n",
        "    y={\n",
        "        'type': y_train_type,\n",
        "        'price': y_train_price,\n",
        "    },\n",
        "    epochs=10,\n",
        "    batch_size=16,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=10, )\n",
        "    ],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:36:22.441221Z",
          "iopub.execute_input": "2023-04-13T11:36:22.441540Z",
          "iopub.status.idle": "2023-04-13T11:37:45.961732Z",
          "shell.execute_reply.started": "2023-04-13T11:36:22.441505Z",
          "shell.execute_reply": "2023-04-13T11:37:45.960553Z"
        },
        "trusted": true,
        "id": "b8LpZX5dIusl",
        "outputId": "68b9a632-e80d-4728-a8a1-2a7d0595a15c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/10\n367/367 [==============================] - 19s 45ms/step - loss: 1.4360 - price_loss: 1.3276 - type_loss: 1.8695 - price_sparse_categorical_accuracy: 0.5874 - type_sparse_categorical_accuracy: 0.7290 - val_loss: 0.8521 - val_price_loss: 0.8195 - val_type_loss: 0.9825 - val_price_sparse_categorical_accuracy: 0.6282 - val_type_sparse_categorical_accuracy: 0.7688\nEpoch 2/10\n367/367 [==============================] - 6s 17ms/step - loss: 0.8236 - price_loss: 0.7795 - type_loss: 1.0000 - price_sparse_categorical_accuracy: 0.6474 - type_sparse_categorical_accuracy: 0.7560 - val_loss: 0.7900 - val_price_loss: 0.7500 - val_type_loss: 0.9499 - val_price_sparse_categorical_accuracy: 0.6583 - val_type_sparse_categorical_accuracy: 0.7688\nEpoch 3/10\n367/367 [==============================] - 4s 12ms/step - loss: 0.7584 - price_loss: 0.7073 - type_loss: 0.9631 - price_sparse_categorical_accuracy: 0.6901 - type_sparse_categorical_accuracy: 0.7560 - val_loss: 0.7492 - val_price_loss: 0.7087 - val_type_loss: 0.9113 - val_price_sparse_categorical_accuracy: 0.6828 - val_type_sparse_categorical_accuracy: 0.7688\nEpoch 4/10\n367/367 [==============================] - 3s 9ms/step - loss: 0.7165 - price_loss: 0.6617 - type_loss: 0.9358 - price_sparse_categorical_accuracy: 0.7118 - type_sparse_categorical_accuracy: 0.7561 - val_loss: 0.7336 - val_price_loss: 0.6931 - val_type_loss: 0.8954 - val_price_sparse_categorical_accuracy: 0.6917 - val_type_sparse_categorical_accuracy: 0.7688\nEpoch 5/10\n367/367 [==============================] - 3s 8ms/step - loss: 0.6802 - price_loss: 0.6230 - type_loss: 0.9091 - price_sparse_categorical_accuracy: 0.7326 - type_sparse_categorical_accuracy: 0.7560 - val_loss: 0.7273 - val_price_loss: 0.6896 - val_type_loss: 0.8781 - val_price_sparse_categorical_accuracy: 0.6924 - val_type_sparse_categorical_accuracy: 0.7694\nEpoch 6/10\n367/367 [==============================] - 3s 9ms/step - loss: 0.6492 - price_loss: 0.5894 - type_loss: 0.8883 - price_sparse_categorical_accuracy: 0.7526 - type_sparse_categorical_accuracy: 0.7570 - val_loss: 0.7215 - val_price_loss: 0.6851 - val_type_loss: 0.8670 - val_price_sparse_categorical_accuracy: 0.7005 - val_type_sparse_categorical_accuracy: 0.7694\nEpoch 7/10\n367/367 [==============================] - 3s 8ms/step - loss: 0.6224 - price_loss: 0.5611 - type_loss: 0.8677 - price_sparse_categorical_accuracy: 0.7631 - type_sparse_categorical_accuracy: 0.7580 - val_loss: 0.7215 - val_price_loss: 0.6875 - val_type_loss: 0.8574 - val_price_sparse_categorical_accuracy: 0.6965 - val_type_sparse_categorical_accuracy: 0.7715\nEpoch 8/10\n367/367 [==============================] - 3s 9ms/step - loss: 0.5951 - price_loss: 0.5320 - type_loss: 0.8476 - price_sparse_categorical_accuracy: 0.7807 - type_sparse_categorical_accuracy: 0.7582 - val_loss: 0.7220 - val_price_loss: 0.6905 - val_type_loss: 0.8481 - val_price_sparse_categorical_accuracy: 0.6965 - val_type_sparse_categorical_accuracy: 0.7722\nEpoch 9/10\n367/367 [==============================] - 3s 9ms/step - loss: 0.5705 - price_loss: 0.5062 - type_loss: 0.8276 - price_sparse_categorical_accuracy: 0.7956 - type_sparse_categorical_accuracy: 0.7613 - val_loss: 0.7299 - val_price_loss: 0.7027 - val_type_loss: 0.8385 - val_price_sparse_categorical_accuracy: 0.6849 - val_type_sparse_categorical_accuracy: 0.7749\nEpoch 10/10\n367/367 [==============================] - 3s 9ms/step - loss: 0.5464 - price_loss: 0.4802 - type_loss: 0.8112 - price_sparse_categorical_accuracy: 0.8055 - type_sparse_categorical_accuracy: 0.7655 - val_loss: 0.7364 - val_price_loss: 0.7114 - val_type_loss: 0.8366 - val_price_sparse_categorical_accuracy: 0.6910 - val_type_sparse_categorical_accuracy: 0.7769\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can do prediction on training set\n",
        "\n",
        "\"\"\"\n",
        "1- use \"predict\" method to generate predictions on new test data, \n",
        "which consists of both text and image inputs. The text input is represented by the \"x_test_text\" variable,\n",
        "and the image input is represented by the \"x_test_image\" variable.\n",
        "\n",
        "2-  \"argmax\" use to  convert the  probabilities into predicted categories \n",
        "\"\"\"\n",
        "y_predict_conv = model_conv.predict(\n",
        "    {\n",
        "        'summary': x_test_text,\n",
        "        'image': x_test_image\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "# probabilities\n",
        "price_predicted_conv = y_predict_conv['price']\n",
        "print(price_predicted_conv)\n",
        "\n",
        "# categories\n",
        "price_category_predicted_conv = np.argmax(price_predicted_conv, axis=1)\n",
        "print(price_category_predicted_conv)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:37:45.964059Z",
          "iopub.execute_input": "2023-04-13T11:37:45.965037Z",
          "iopub.status.idle": "2023-04-13T11:37:47.528964Z",
          "shell.execute_reply.started": "2023-04-13T11:37:45.964993Z",
          "shell.execute_reply": "2023-04-13T11:37:47.527969Z"
        },
        "trusted": true,
        "id": "gH-sUeooIusm",
        "outputId": "64f571c4-cddf-4a5a-fa82-49ff60a98456"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "230/230 [==============================] - 1s 3ms/step\n[[8.30187082e-01 1.30616799e-01 3.89041305e-02 ... 1.35916735e-05\n  1.16270603e-05 9.61425576e-06]\n [9.51798141e-01 3.74613926e-02 1.06498636e-02 ... 4.12432064e-06\n  3.56638247e-06 2.93705534e-06]\n [9.30969536e-01 4.35884967e-02 2.52267849e-02 ... 1.02690201e-05\n  8.69182986e-06 7.13395821e-06]\n ...\n [8.53956640e-01 1.21889345e-01 2.39772871e-02 ... 8.01630176e-06\n  6.96405868e-06 5.70035854e-06]\n [9.96598184e-01 2.27763457e-03 1.10220443e-03 ... 1.03522325e-06\n  8.68716199e-07 7.25680991e-07]\n [8.73581350e-01 1.06853485e-01 1.94059759e-02 ... 7.23387348e-06\n  6.24166432e-06 5.21314632e-06]]\n[0 0 0 ... 0 0 0]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create submission file\n",
        "pd.DataFrame(\n",
        "    {'id': test.index,\n",
        "     'price': price_category_predicted_conv}\n",
        ").to_csv('trail_2.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:37:47.530491Z",
          "iopub.execute_input": "2023-04-13T11:37:47.530858Z",
          "iopub.status.idle": "2023-04-13T11:37:47.547166Z",
          "shell.execute_reply.started": "2023-04-13T11:37:47.530821Z",
          "shell.execute_reply": "2023-04-13T11:37:47.546224Z"
        },
        "trusted": true,
        "id": "txEn7YsJIusm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Trial 3 : LSTM**"
      ],
      "metadata": {
        "id": "P35LKmGkIusm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# trial 3\n",
        "\"\"\"\n",
        "the steps : \n",
        "1- defines a neural network model using the Keras API with two inputs and two outputs\n",
        "2- in two inputs: image data and text data, and outputs two labels: the price of real estate and it's type\n",
        "3- The text input is processed using an embedding layer followed by a long short-term memory (LSTM) layer.\n",
        "4- The image input is processed using a single convolutional layer with a large kernel size, followed by a max pooling layer and a flatten layer\n",
        "5- The resulting output from the text and image processing layers are then concatenated and fed into two separate dense layers,\n",
        "one for each output task.\n",
        "6- The model is compiled with the Adam optimizer and sparse categorical cross-entropy loss functions for both tasks\n",
        "7- The loss weights are set to 0.7 for the \"type\" output and 0.3 for the \"price\" \n",
        "8- The metrics for evaluation are set to sparse categorical accuracy for both tasks.\n",
        "9-  make summarization on model\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "thoughts and observations\n",
        "1- I Apply LSTM technique on the text input for understanding the context and meaning of the input data , \n",
        "LSTMs allow the model to learn long-term dependencies in sequential data\n",
        "\n",
        "2- I think the model will fit well but get the accuracy on validation less than the validation accuracy on trial 1, and tria 2\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "my plan is using  BiDirectional layer on input text  \n",
        "\"\"\"\n",
        "\n",
        "# here we have two inputs. one for image and the other for text.\n",
        "in_text = keras.Input(batch_shape=(None, max_len))\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2))\n",
        "\n",
        "# text part\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text)\n",
        "lstm = tf.keras.layers.LSTM(4)(embedded)\n",
        "\n",
        "\n",
        "# image part \n",
        "cov1 = Conv2D(32, (16, 16))(in_image) \n",
        "pl = MaxPool2D((16, 16))(cov1)\n",
        "flattened = Flatten()(pl)\n",
        "\n",
        "#combinig \n",
        "fused = tf.concat([lstm, flattened], axis=-1)\n",
        "\n",
        "\n",
        "p_type = Dense(length_of_type, activation='softmax', name='type')(fused)\n",
        "p_price = Dense(length_of_price, activation='softmax', name='price')(fused)\n",
        "\n",
        "\n",
        "# define model input/output using keys.\n",
        "model_lstm = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text,\n",
        "        'image': in_image\n",
        "    },\n",
        "    outputs={\n",
        "        'type': p_type,\n",
        "        'price': p_price,\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "model_lstm.compile(\n",
        "    optimizer=Adam(),\n",
        "    loss={\n",
        "        'type': 'sparse_categorical_crossentropy',\n",
        "        'price': 'sparse_categorical_crossentropy',\n",
        "    },\n",
        "    loss_weights={\n",
        "        'type': 0.7,\n",
        "        'price': 0.3,       \n",
        "    },\n",
        "    metrics={\n",
        "        'type': ['SparseCategoricalAccuracy'],\n",
        "        'price': ['SparseCategoricalAccuracy'],\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "model_lstm.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:37:47.548740Z",
          "iopub.execute_input": "2023-04-13T11:37:47.549310Z",
          "iopub.status.idle": "2023-04-13T11:37:47.911362Z",
          "shell.execute_reply.started": "2023-04-13T11:37:47.549272Z",
          "shell.execute_reply": "2023-04-13T11:37:47.910547Z"
        },
        "trusted": true,
        "id": "t1SrNCkSIusm",
        "outputId": "ec03b5eb-9ca0-4f1a-e7dd-496aee976316"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"model_2\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_6 (InputLayer)           [(None, 64, 64, 2)]  0           []                               \n                                                                                                  \n input_5 (InputLayer)           [(None, 100)]        0           []                               \n                                                                                                  \n conv2d_5 (Conv2D)              (None, 49, 49, 32)   16416       ['input_6[0][0]']                \n                                                                                                  \n embedding_2 (Embedding)        (None, 100, 100)     4000000     ['input_5[0][0]']                \n                                                                                                  \n max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 32)    0           ['conv2d_5[0][0]']               \n                                                                                                  \n lstm (LSTM)                    (None, 4)            1680        ['embedding_2[0][0]']            \n                                                                                                  \n flatten_2 (Flatten)            (None, 288)          0           ['max_pooling2d_2[0][0]']        \n                                                                                                  \n tf.concat_2 (TFOpLambda)       (None, 292)          0           ['lstm[0][0]',                   \n                                                                  'flatten_2[0][0]']              \n                                                                                                  \n price (Dense)                  (None, 24)           7032        ['tf.concat_2[0][0]']            \n                                                                                                  \n type (Dense)                   (None, 24)           7032        ['tf.concat_2[0][0]']            \n                                                                                                  \n==================================================================================================\nTotal params: 4,032,160\nTrainable params: 4,032,160\nNon-trainable params: 0\n__________________________________________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1- trains the \"model_lstm\" neural network model using the \"fit\" method\n",
        "2- The training data consists of two inputs: \"x_train_text_id\" ,\"x_train_image\" . The target outputs consist of two separate arrays: \n",
        "\"y_train_type\" for the real estate type classification and \"y_train_price\" for the real estate price range classification.\n",
        "3- The model is trained for 10 epochs with a batch size of 16 and a validation split of 0.2,\n",
        "meaning that 20% of the training data is reserved for validation during training\n",
        "\"\"\"\n",
        "\n",
        "history = model_lstm.fit(\n",
        "    x={\n",
        "        'summary': x_train_text_id,\n",
        "        'image': x_train_image\n",
        "    },\n",
        "    y={\n",
        "        'type': y_train_type,\n",
        "        'price': y_train_price,\n",
        "    },\n",
        "    epochs=10,\n",
        "    batch_size=16,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=6,)\n",
        "    ],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:37:47.912415Z",
          "iopub.execute_input": "2023-04-13T11:37:47.912767Z",
          "iopub.status.idle": "2023-04-13T11:38:50.058110Z",
          "shell.execute_reply.started": "2023-04-13T11:37:47.912730Z",
          "shell.execute_reply": "2023-04-13T11:38:50.057079Z"
        },
        "trusted": true,
        "id": "w6rPsFsoIusm",
        "outputId": "f18b5e4c-6111-4a9e-9fd5-e9a8205278a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/10\n367/367 [==============================] - 21s 48ms/step - loss: 41.0419 - price_loss: 28.7784 - type_loss: 46.2977 - price_sparse_categorical_accuracy: 0.4874 - type_sparse_categorical_accuracy: 0.5824 - val_loss: 25.3097 - val_price_loss: 12.1843 - val_type_loss: 30.9349 - val_price_sparse_categorical_accuracy: 0.5375 - val_type_sparse_categorical_accuracy: 0.0859\nEpoch 2/10\n367/367 [==============================] - 6s 17ms/step - loss: 17.2256 - price_loss: 12.4287 - type_loss: 19.2814 - price_sparse_categorical_accuracy: 0.5019 - type_sparse_categorical_accuracy: 0.5870 - val_loss: 14.2013 - val_price_loss: 9.3381 - val_type_loss: 16.2855 - val_price_sparse_categorical_accuracy: 0.5969 - val_type_sparse_categorical_accuracy: 0.3990\nEpoch 3/10\n367/367 [==============================] - 6s 15ms/step - loss: 10.9361 - price_loss: 7.2369 - type_loss: 12.5214 - price_sparse_categorical_accuracy: 0.5061 - type_sparse_categorical_accuracy: 0.5944 - val_loss: 8.0281 - val_price_loss: 7.3276 - val_type_loss: 8.3282 - val_price_sparse_categorical_accuracy: 0.3574 - val_type_sparse_categorical_accuracy: 0.6685\nEpoch 4/10\n367/367 [==============================] - 4s 11ms/step - loss: 8.5763 - price_loss: 5.7574 - type_loss: 9.7845 - price_sparse_categorical_accuracy: 0.5121 - type_sparse_categorical_accuracy: 0.6014 - val_loss: 23.7263 - val_price_loss: 14.0651 - val_type_loss: 27.8669 - val_price_sparse_categorical_accuracy: 0.6146 - val_type_sparse_categorical_accuracy: 0.7538\nEpoch 5/10\n367/367 [==============================] - 4s 11ms/step - loss: 13.6208 - price_loss: 7.2201 - type_loss: 16.3639 - price_sparse_categorical_accuracy: 0.5078 - type_sparse_categorical_accuracy: 0.5939 - val_loss: 6.2021 - val_price_loss: 6.0379 - val_type_loss: 6.2725 - val_price_sparse_categorical_accuracy: 0.4973 - val_type_sparse_categorical_accuracy: 0.6241\nEpoch 6/10\n367/367 [==============================] - 4s 12ms/step - loss: 6.3506 - price_loss: 4.8453 - type_loss: 6.9957 - price_sparse_categorical_accuracy: 0.5213 - type_sparse_categorical_accuracy: 0.6056 - val_loss: 5.3721 - val_price_loss: 4.2767 - val_type_loss: 5.8415 - val_price_sparse_categorical_accuracy: 0.5730 - val_type_sparse_categorical_accuracy: 0.6726\nEpoch 7/10\n367/367 [==============================] - 4s 11ms/step - loss: 9.4040 - price_loss: 9.0950 - type_loss: 9.5364 - price_sparse_categorical_accuracy: 0.5148 - type_sparse_categorical_accuracy: 0.6036 - val_loss: 8.3823 - val_price_loss: 5.5277 - val_type_loss: 9.6057 - val_price_sparse_categorical_accuracy: 0.4748 - val_type_sparse_categorical_accuracy: 0.5839\nEpoch 8/10\n367/367 [==============================] - 4s 12ms/step - loss: 8.6807 - price_loss: 6.4073 - type_loss: 9.6550 - price_sparse_categorical_accuracy: 0.5172 - type_sparse_categorical_accuracy: 0.6106 - val_loss: 12.2774 - val_price_loss: 6.6532 - val_type_loss: 14.6878 - val_price_sparse_categorical_accuracy: 0.5846 - val_type_sparse_categorical_accuracy: 0.2599\nEpoch 9/10\n367/367 [==============================] - 4s 10ms/step - loss: 14.5162 - price_loss: 9.2231 - type_loss: 16.7846 - price_sparse_categorical_accuracy: 0.5068 - type_sparse_categorical_accuracy: 0.6044 - val_loss: 14.7078 - val_price_loss: 8.8544 - val_type_loss: 17.2165 - val_price_sparse_categorical_accuracy: 0.3417 - val_type_sparse_categorical_accuracy: 0.3240\nEpoch 10/10\n367/367 [==============================] - 4s 12ms/step - loss: 15.8453 - price_loss: 10.2515 - type_loss: 18.2427 - price_sparse_categorical_accuracy: 0.5027 - type_sparse_categorical_accuracy: 0.6051 - val_loss: 20.8223 - val_price_loss: 17.4481 - val_type_loss: 22.2684 - val_price_sparse_categorical_accuracy: 0.6201 - val_type_sparse_categorical_accuracy: 0.4952\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can do prediction on training set\n",
        "\"\"\"\n",
        "1- use \"predict\" method to generate predictions on new test data, \n",
        "which consists of both text and image inputs. The text input is represented by the \"x_test_text\" variable,\n",
        "and the image input is represented by the \"x_test_image\" variable.\n",
        "\n",
        "2-  \"argmax\" use to  convert the  probabilities into predicted categories \n",
        "\"\"\"\n",
        "y_predict_lstm= model_lstm.predict(\n",
        "    {\n",
        "        'summary': x_test_text,\n",
        "        'image': x_test_image\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "# probabilities\n",
        "price_predicted_lstm = y_predict_lstm['price']\n",
        "print(price_predicted_lstm)\n",
        "\n",
        "# categories\n",
        "price_category_predicted_lstm = np.argmax(price_predicted_lstm, axis=1)\n",
        "print(price_category_predicted_lstm)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:38:50.060563Z",
          "iopub.execute_input": "2023-04-13T11:38:50.060984Z",
          "iopub.status.idle": "2023-04-13T11:38:52.613264Z",
          "shell.execute_reply.started": "2023-04-13T11:38:50.060943Z",
          "shell.execute_reply": "2023-04-13T11:38:52.611960Z"
        },
        "trusted": true,
        "id": "J-lnj1PjIusn",
        "outputId": "3b88551c-88e7-4556-cdb0-bcff71979cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "230/230 [==============================] - 1s 4ms/step\n[[1.0000000e+00 2.3043900e-30 2.0092168e-25 ... 0.0000000e+00\n  0.0000000e+00 0.0000000e+00]\n [1.0000000e+00 4.8254631e-21 8.9533960e-28 ... 0.0000000e+00\n  0.0000000e+00 0.0000000e+00]\n [1.0000000e+00 2.0386383e-19 2.8969947e-32 ... 0.0000000e+00\n  0.0000000e+00 0.0000000e+00]\n ...\n [1.0000000e+00 1.7275845e-19 1.7821226e-14 ... 0.0000000e+00\n  0.0000000e+00 0.0000000e+00]\n [1.0000000e+00 4.5476127e-23 1.3132015e-16 ... 0.0000000e+00\n  0.0000000e+00 0.0000000e+00]\n [1.0000000e+00 1.6962980e-11 0.0000000e+00 ... 0.0000000e+00\n  0.0000000e+00 0.0000000e+00]]\n[0 0 0 ... 0 0 0]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create submission file\n",
        "pd.DataFrame(\n",
        "    {'id': test.index,\n",
        "     'price': price_category_predicted_lstm}\n",
        ").to_csv('trail_3.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:38:52.614820Z",
          "iopub.execute_input": "2023-04-13T11:38:52.615301Z",
          "iopub.status.idle": "2023-04-13T11:38:52.631811Z",
          "shell.execute_reply.started": "2023-04-13T11:38:52.615259Z",
          "shell.execute_reply": "2023-04-13T11:38:52.630857Z"
        },
        "trusted": true,
        "id": "rMWK_ecKIusn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Trial 4 : BiDirectional LSTM layer**"
      ],
      "metadata": {
        "id": "tHijiBKJIusn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "the steps : \n",
        "1- The code provide defines a neural network model using the Keras API with two inputs and two outputs,\n",
        "2- in two inputs: image data and text data, and outputs two labels: the price of real estate and it's type\n",
        "3- The text input is processed using an embedding layer followed by a bidirectional LSTM layer. The bidirectional LSTM layer is a type of recurrent neural network (RNN) \n",
        "layer that can capture information from both past and future input data\n",
        "4-The image input is processed using two convolutional layers with different kernel sizes and a max pooling layer, followed by a flatten layer\n",
        "5- The resulting output from the text and image processing layers are then concatenated and fed into two separate dense layers,\n",
        "one for each output task.\n",
        "6- The model is compiled with the Adam optimizer and sparse categorical cross-entropy loss functions for both tasks\n",
        "7- The loss weights are set to 0.5 for the \"type\" output and 0.5 for the \"price\" \n",
        "8- The metrics for evaluation are set to sparse categorical accuracy for both tasks.\n",
        "9-  make summarization on model\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "thoughts and observations\n",
        "1- I Apply bidirectional LSTM layer technique on the text input.\n",
        "\n",
        "Bidirectional LSTMs allow the model to capture dependencies and relationships between words or phrases that occur in both directions, \n",
        "and help to prevent the vanishing gradient problem that can occur in traditional LSTMs.\n",
        "\n",
        "2- I think the model will fit well with using Bidirectional LSTMs \n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "my plan is using bidirectional GRU with  multi-modality and single-task\n",
        "\"\"\"\n",
        "in_text = keras.Input(batch_shape=(None, max_len))\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2)) \n",
        "\n",
        "# text part\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text) \n",
        "bi_lstm = Bidirectional(LSTM(20))(embedded) \n",
        "\n",
        "# image part\n",
        "cov = Conv2D(32, (3, 3))(in_image) # convolutional layer with 32 filters, no padding\n",
        "pl = MaxPool2D((3, 3))(cov) # max pooling with a 3x3 mask, reducing the size to 20x20x32\n",
        "cov2 = Conv2D(32, (2,2))(pl) # convolutional layer with 32 filters, and a 2x2 mask, no padding\n",
        "pl2 = MaxPool2D((2,2))(cov2) # max pooling with a 2x2 mask, reducing the size to 9x9x32\n",
        "flattened = Flatten()(pl2) # flatten the shape to (2592,)\n",
        "\n",
        "\n",
        "# concat\n",
        "fused = tf.concat([bi_lstm, flattened], axis=-1) # concatenate text features with images\n",
        "\n",
        "# multi-objectives \n",
        "p_price = Dense(length_of_price, activation='softmax', name='price')(fused) \n",
        "p_type = Dense(length_of_type, activation='softmax', name='type')(fused) \n",
        "\n",
        "# model definition\n",
        "model_bidircectional= keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text, \n",
        "        'image': in_image \n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price, \n",
        "        'type': p_type, \n",
        "    },\n",
        ")\n",
        "\n",
        "# compiling the bidirectional model \n",
        "model_bidircectional.compile(\n",
        "    optimizer=Adam(),\n",
        "    loss={\n",
        "        'type': 'sparse_categorical_crossentropy',\n",
        "        'price': 'sparse_categorical_crossentropy',\n",
        "    },\n",
        "    loss_weights={\n",
        "        'type': 0.5,\n",
        "        'price': 0.5,       \n",
        "    },\n",
        "    metrics={\n",
        "        'type': ['SparseCategoricalAccuracy'],\n",
        "        'price': ['SparseCategoricalAccuracy'],\n",
        "    },\n",
        ")\n",
        "model_bidircectional.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:38:52.633250Z",
          "iopub.execute_input": "2023-04-13T11:38:52.633819Z",
          "iopub.status.idle": "2023-04-13T11:38:53.222392Z",
          "shell.execute_reply.started": "2023-04-13T11:38:52.633780Z",
          "shell.execute_reply": "2023-04-13T11:38:53.221548Z"
        },
        "trusted": true,
        "id": "NvUtDpH0Iusn",
        "outputId": "0619eabe-b40a-4427-bb63-49a89a4f2d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"model_3\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_8 (InputLayer)           [(None, 64, 64, 2)]  0           []                               \n                                                                                                  \n conv2d_6 (Conv2D)              (None, 62, 62, 32)   608         ['input_8[0][0]']                \n                                                                                                  \n max_pooling2d_3 (MaxPooling2D)  (None, 20, 20, 32)  0           ['conv2d_6[0][0]']               \n                                                                                                  \n input_7 (InputLayer)           [(None, 100)]        0           []                               \n                                                                                                  \n conv2d_7 (Conv2D)              (None, 19, 19, 32)   4128        ['max_pooling2d_3[0][0]']        \n                                                                                                  \n embedding_3 (Embedding)        (None, 100, 100)     4000000     ['input_7[0][0]']                \n                                                                                                  \n max_pooling2d_4 (MaxPooling2D)  (None, 9, 9, 32)    0           ['conv2d_7[0][0]']               \n                                                                                                  \n bidirectional (Bidirectional)  (None, 40)           19360       ['embedding_3[0][0]']            \n                                                                                                  \n flatten_3 (Flatten)            (None, 2592)         0           ['max_pooling2d_4[0][0]']        \n                                                                                                  \n tf.concat_3 (TFOpLambda)       (None, 2632)         0           ['bidirectional[0][0]',          \n                                                                  'flatten_3[0][0]']              \n                                                                                                  \n price (Dense)                  (None, 24)           63192       ['tf.concat_3[0][0]']            \n                                                                                                  \n type (Dense)                   (None, 24)           63192       ['tf.concat_3[0][0]']            \n                                                                                                  \n==================================================================================================\nTotal params: 4,150,480\nTrainable params: 4,150,480\nNon-trainable params: 0\n__________________________________________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1- trains the \"model_bidircectional\" neural network model using the \"fit\" method\n",
        "2- The training data consists of two inputs: \"x_train_text_id\" ,\"x_train_image\" . The target outputs consist of two separate arrays: \n",
        "\"y_train_type\" for the real estate type classification and \"y_train_price\" for the real estate price range classification.\n",
        "3- The model is trained for 5 epochs with a batch size of 17 and a validation split of 0.2,\n",
        "meaning that 20% of the training data is reserved for validation during training\n",
        "\"\"\"\n",
        "history = model_bidircectional.fit(\n",
        "    x={\n",
        "        'summary': x_train_text_id,\n",
        "        'image': x_train_image\n",
        "    },\n",
        "    y={\n",
        "        'type': y_train_type,\n",
        "        'price': y_train_price,\n",
        "    },\n",
        "    epochs=5,\n",
        "    batch_size=17,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=6, )\n",
        "    ],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:38:53.223462Z",
          "iopub.execute_input": "2023-04-13T11:38:53.223833Z",
          "iopub.status.idle": "2023-04-13T11:39:44.906646Z",
          "shell.execute_reply.started": "2023-04-13T11:38:53.223795Z",
          "shell.execute_reply": "2023-04-13T11:39:44.905628Z"
        },
        "trusted": true,
        "id": "z2JjSEUUIusn",
        "outputId": "133e2e76-aadc-42e4-9915-88b20c8bff88"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/5\n345/345 [==============================] - 24s 56ms/step - loss: 10.1294 - price_loss: 8.9939 - type_loss: 11.2649 - price_sparse_categorical_accuracy: 0.5140 - type_sparse_categorical_accuracy: 0.5867 - val_loss: 2.8523 - val_price_loss: 2.5509 - val_type_loss: 3.1537 - val_price_sparse_categorical_accuracy: 0.4877 - val_type_sparse_categorical_accuracy: 0.6903\nEpoch 2/5\n345/345 [==============================] - 9s 25ms/step - loss: 2.1861 - price_loss: 1.9226 - type_loss: 2.4496 - price_sparse_categorical_accuracy: 0.5799 - type_sparse_categorical_accuracy: 0.6543 - val_loss: 1.9738 - val_price_loss: 1.6795 - val_type_loss: 2.2681 - val_price_sparse_categorical_accuracy: 0.5621 - val_type_sparse_categorical_accuracy: 0.7196\nEpoch 3/5\n345/345 [==============================] - 7s 19ms/step - loss: 1.2999 - price_loss: 1.2182 - type_loss: 1.3817 - price_sparse_categorical_accuracy: 0.6515 - type_sparse_categorical_accuracy: 0.7191 - val_loss: 2.0333 - val_price_loss: 1.6849 - val_type_loss: 2.3817 - val_price_sparse_categorical_accuracy: 0.5211 - val_type_sparse_categorical_accuracy: 0.7244\nEpoch 4/5\n345/345 [==============================] - 6s 18ms/step - loss: 1.6772 - price_loss: 1.3394 - type_loss: 2.0150 - price_sparse_categorical_accuracy: 0.6872 - type_sparse_categorical_accuracy: 0.7377 - val_loss: 13.4062 - val_price_loss: 10.5077 - val_type_loss: 16.3047 - val_price_sparse_categorical_accuracy: 0.6241 - val_type_sparse_categorical_accuracy: 0.1139\nEpoch 5/5\n345/345 [==============================] - 5s 16ms/step - loss: 5.8716 - price_loss: 4.2722 - type_loss: 7.4709 - price_sparse_categorical_accuracy: 0.6643 - type_sparse_categorical_accuracy: 0.6978 - val_loss: 1.8931 - val_price_loss: 1.6295 - val_type_loss: 2.1568 - val_price_sparse_categorical_accuracy: 0.6057 - val_type_sparse_categorical_accuracy: 0.7026\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can do prediction on training set\n",
        "\"\"\"\n",
        "1- use \"predict\" method to generate predictions on new test data, \n",
        "which consists of both text and image inputs. The text input is represented by the \"x_test_text\" variable,\n",
        "and the image input is represented by the \"x_test_image\" variable.\n",
        "\n",
        "2-  \"argmax\" use to  convert the  probabilities into predicted categories \n",
        "\"\"\"\n",
        "y_predict_bidircectional = model_bidircectional.predict(\n",
        "    {\n",
        "        'summary': x_test_text,\n",
        "        'image': x_test_image\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "# probabilities\n",
        "price_predicted_bidircectional = y_predict_bidircectional['price']\n",
        "print(price_predicted_bidircectional)\n",
        "\n",
        "# categories\n",
        "price_category_predicted_bidircectional = np.argmax(price_predicted_bidircectional, axis=1)\n",
        "print(price_category_predicted_bidircectional)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:39:44.910351Z",
          "iopub.execute_input": "2023-04-13T11:39:44.910662Z",
          "iopub.status.idle": "2023-04-13T11:39:47.542277Z",
          "shell.execute_reply.started": "2023-04-13T11:39:44.910633Z",
          "shell.execute_reply": "2023-04-13T11:39:47.541212Z"
        },
        "trusted": true,
        "id": "6d3nbzZ7Iusn",
        "outputId": "17389140-5bf5-4190-dfd6-ec225276c199"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "230/230 [==============================] - 2s 5ms/step\n[[6.9479889e-01 3.0064374e-01 4.5573693e-03 ... 4.3250972e-15\n  1.0904095e-10 5.4938103e-11]\n [9.8048055e-01 1.9422997e-02 9.6387572e-05 ... 1.7224247e-16\n  2.2088403e-14 1.8723281e-10]\n [9.9858284e-01 1.4168469e-03 3.6350187e-07 ... 5.0854454e-21\n  6.0878232e-15 2.0284145e-13]\n ...\n [9.9808228e-01 1.9167847e-03 9.3436665e-07 ... 5.6778566e-18\n  5.8286119e-14 2.1109111e-14]\n [9.8097712e-01 1.8607037e-02 4.1565869e-04 ... 2.4293034e-15\n  4.1951477e-11 3.4597740e-13]\n [1.2501171e-02 9.8674124e-01 7.5757981e-04 ... 5.6074815e-16\n  1.1461290e-09 1.4048023e-09]]\n[0 0 0 ... 0 0 1]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create submission file\n",
        "pd.DataFrame(\n",
        "    {'id': test.index,\n",
        "     'price': price_category_predicted_bidircectional}\n",
        ").to_csv('trial_4.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:39:47.543610Z",
          "iopub.execute_input": "2023-04-13T11:39:47.543984Z",
          "iopub.status.idle": "2023-04-13T11:39:47.561294Z",
          "shell.execute_reply.started": "2023-04-13T11:39:47.543945Z",
          "shell.execute_reply": "2023-04-13T11:39:47.560194Z"
        },
        "trusted": true,
        "id": "bdIp99HcIusn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Trial 5 : multi-modality and single-task**"
      ],
      "metadata": {
        "id": "SwTo_-WoIuso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "the steps : \n",
        "1- The code provide defines a neural network model using the Keras API with two inputs and one output.\n",
        "2- in two inputs: image data and text data, and outputs two labels: the price of real estate \n",
        "3-The text input is processed using an embedding layer followed by a bidirectional GRU layer\n",
        "4-The image input is processed using a single convolutional layer and a max pooling layer, followed by a flatten layer\n",
        "5- The resulting output from the text and image processing layers are then concatenated and fed into two separate dense layers,\n",
        "one for each output task.\n",
        "6- The model is compiled with the Nadam optimizer and sparse categorical cross-entropy loss functions for the price prediction task\n",
        "7- The loss weights are set to 1 for the \"price\" \n",
        "8- The metrics for evaluation are set to sparse categorical accuracy for both tasks.\n",
        "9-  make summarization on model\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "thoughts and observations\n",
        "1- I Apply bidirectional GRU with  multi-modality and single-task technique on the text input.\n",
        "\n",
        "\n",
        "2- I think the model will fit well than previous trial\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "my plan is using bidirectional LSTM with single-modality and multi-task\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "in_text = keras.Input(batch_shape=(None, max_len))\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2))\n",
        "\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text)\n",
        "bidir_gru =  Bidirectional(GRU(units = 128,return_sequences=True))(embedded)\n",
        "averaged = tf.reduce_mean(bidir_gru, axis=1)\n",
        "\n",
        "# image part \n",
        "cov = Conv2D(32, (16, 16))(in_image)\n",
        "pl = MaxPool2D((16, 16))(cov)\n",
        "flattened = Flatten()(pl)\n",
        "\n",
        "#combinig \n",
        "fused = tf.concat([averaged , flattened], axis=-1)\n",
        "\n",
        "# single-task learning\n",
        "fused1 = Dense(128, activation='relu')(fused)\n",
        "dropout_1 = Dropout(rate = 0.2)(fused1)\n",
        "fused_2 = Dense(256, activation='relu')(dropout_1)\n",
        "\n",
        "\n",
        "p_price = Dense(length_of_price, activation='softmax', name='price')(fused_2)\n",
        "\n",
        "\n",
        "bidirec_with_GRU = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text,\n",
        "        'image': in_image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price,\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "# compile model with optimizer\n",
        "bidirec_with_GRU.compile(\n",
        "    optimizer=Nadam(),\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy',\n",
        "    },\n",
        "    loss_weights={\n",
        "        'price': 1,       \n",
        "    },\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'],\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "bidirec_with_GRU.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:39:47.563205Z",
          "iopub.execute_input": "2023-04-13T11:39:47.563596Z",
          "iopub.status.idle": "2023-04-13T11:39:48.088300Z",
          "shell.execute_reply.started": "2023-04-13T11:39:47.563542Z",
          "shell.execute_reply": "2023-04-13T11:39:48.087477Z"
        },
        "trusted": true,
        "id": "_cNz4XkrIuso",
        "outputId": "cd5ba339-b916-4418-e01e-7284846d3876"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"model_4\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_9 (InputLayer)           [(None, 100)]        0           []                               \n                                                                                                  \n input_10 (InputLayer)          [(None, 64, 64, 2)]  0           []                               \n                                                                                                  \n embedding_4 (Embedding)        (None, 100, 100)     4000000     ['input_9[0][0]']                \n                                                                                                  \n conv2d_8 (Conv2D)              (None, 49, 49, 32)   16416       ['input_10[0][0]']               \n                                                                                                  \n bidirectional_1 (Bidirectional  (None, 100, 256)    176640      ['embedding_4[0][0]']            \n )                                                                                                \n                                                                                                  \n max_pooling2d_5 (MaxPooling2D)  (None, 3, 3, 32)    0           ['conv2d_8[0][0]']               \n                                                                                                  \n tf.math.reduce_mean_2 (TFOpLam  (None, 256)         0           ['bidirectional_1[0][0]']        \n bda)                                                                                             \n                                                                                                  \n flatten_4 (Flatten)            (None, 288)          0           ['max_pooling2d_5[0][0]']        \n                                                                                                  \n tf.concat_4 (TFOpLambda)       (None, 544)          0           ['tf.math.reduce_mean_2[0][0]',  \n                                                                  'flatten_4[0][0]']              \n                                                                                                  \n dense (Dense)                  (None, 128)          69760       ['tf.concat_4[0][0]']            \n                                                                                                  \n dropout_1 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n                                                                                                  \n dense_1 (Dense)                (None, 256)          33024       ['dropout_1[0][0]']              \n                                                                                                  \n price (Dense)                  (None, 24)           6168        ['dense_1[0][0]']                \n                                                                                                  \n==================================================================================================\nTotal params: 4,302,008\nTrainable params: 4,302,008\nNon-trainable params: 0\n__________________________________________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1- trains the \"bidirec_with_GRU\" neural network model using the \"fit\" method\n",
        "2- The training data consists of two inputs: \"x_train_text_id\" ,\"x_train_image\" . The target outputs consist of one array: \n",
        " \"y_train_price\" for the real estate price range classification.\n",
        "3- The model is trained for 10 epochs with a batch size of 16 and a validation split of 0.2,\n",
        "meaning that 20% of the training data is reserved for validation during training\n",
        "\"\"\"\n",
        "history = bidirec_with_GRU.fit(\n",
        "    x={\n",
        "        'summary': x_train_text_id,\n",
        "        'image': x_train_image\n",
        "    },\n",
        "    y={\n",
        "        'price': y_train_price,\n",
        "    },\n",
        "    epochs=10,\n",
        "    batch_size=16,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=6,)\n",
        "    ],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:39:48.089360Z",
          "iopub.execute_input": "2023-04-13T11:39:48.089723Z",
          "iopub.status.idle": "2023-04-13T11:42:14.744860Z",
          "shell.execute_reply.started": "2023-04-13T11:39:48.089672Z",
          "shell.execute_reply": "2023-04-13T11:42:14.743515Z"
        },
        "trusted": true,
        "id": "oFp9eaViIuso",
        "outputId": "d7f88976-f05e-43fc-df8d-741dd1f0f16b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/10\n367/367 [==============================] - 40s 92ms/step - loss: 4.0775 - sparse_categorical_accuracy: 0.5278 - val_loss: 0.8598 - val_sparse_categorical_accuracy: 0.6241\nEpoch 2/10\n367/367 [==============================] - 11s 30ms/step - loss: 0.9357 - sparse_categorical_accuracy: 0.6113 - val_loss: 0.8596 - val_sparse_categorical_accuracy: 0.6241\nEpoch 3/10\n367/367 [==============================] - 9s 24ms/step - loss: 0.8577 - sparse_categorical_accuracy: 0.6183 - val_loss: 0.8341 - val_sparse_categorical_accuracy: 0.6241\nEpoch 4/10\n367/367 [==============================] - 6s 18ms/step - loss: 0.8412 - sparse_categorical_accuracy: 0.6196 - val_loss: 0.8312 - val_sparse_categorical_accuracy: 0.6241\nEpoch 5/10\n367/367 [==============================] - 6s 16ms/step - loss: 0.8398 - sparse_categorical_accuracy: 0.6196 - val_loss: 0.8305 - val_sparse_categorical_accuracy: 0.6241\nEpoch 6/10\n367/367 [==============================] - 7s 18ms/step - loss: 0.8392 - sparse_categorical_accuracy: 0.6196 - val_loss: 0.8304 - val_sparse_categorical_accuracy: 0.6241\nEpoch 7/10\n367/367 [==============================] - 6s 17ms/step - loss: 0.8387 - sparse_categorical_accuracy: 0.6196 - val_loss: 0.8308 - val_sparse_categorical_accuracy: 0.6241\nEpoch 8/10\n367/367 [==============================] - 7s 18ms/step - loss: 0.8387 - sparse_categorical_accuracy: 0.6196 - val_loss: 0.8302 - val_sparse_categorical_accuracy: 0.6241\nEpoch 9/10\n367/367 [==============================] - 6s 17ms/step - loss: 0.8391 - sparse_categorical_accuracy: 0.6196 - val_loss: 0.8310 - val_sparse_categorical_accuracy: 0.6241\nEpoch 10/10\n367/367 [==============================] - 5s 15ms/step - loss: 0.8384 - sparse_categorical_accuracy: 0.6196 - val_loss: 0.8316 - val_sparse_categorical_accuracy: 0.6241\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can do prediction on training set\n",
        "\"\"\"\n",
        "1- use \"predict\" method to generate predictions on new test data, \n",
        "which consists of both text and image inputs. The text input is represented by the \"x_test_text\" variable,\n",
        "and the image input is represented by the \"x_test_image\" variable.\n",
        "\n",
        "2-  \"argmax\" use to  convert the  probabilities into predicted categories \n",
        "\"\"\"\n",
        "y_predict_bid_withGRU = bidirec_with_GRU.predict(\n",
        "    {\n",
        "        'summary': x_test_text,\n",
        "        'image': x_test_image\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "# probabilities\n",
        "price_predicted_bidirwithGRU = y_predict_bid_withGRU['price']\n",
        "print(price_predicted_bidirwithGRU)\n",
        "\n",
        "# categories\n",
        "price_category_predicted_bidirwithGRU = np.argmax(price_predicted_bidirwithGRU, axis=1)\n",
        "print(price_category_predicted_bidirwithGRU)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:42:14.746793Z",
          "iopub.execute_input": "2023-04-13T11:42:14.747499Z",
          "iopub.status.idle": "2023-04-13T11:42:17.648837Z",
          "shell.execute_reply.started": "2023-04-13T11:42:14.747456Z",
          "shell.execute_reply": "2023-04-13T11:42:17.647758Z"
        },
        "trusted": true,
        "id": "LUwbR3CeIuso",
        "outputId": "9d3d4725-fc2b-41ee-fd76-f054eb73b237"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "230/230 [==============================] - 2s 6ms/step\n[[6.4695638e-01 2.8551570e-01 6.7296989e-02 ... 2.7117783e-05\n  3.5520262e-07 3.9536894e-07]\n [6.4695638e-01 2.8551570e-01 6.7296989e-02 ... 2.7117783e-05\n  3.5520262e-07 3.9536894e-07]\n [6.4695638e-01 2.8551570e-01 6.7296989e-02 ... 2.7117783e-05\n  3.5520262e-07 3.9536894e-07]\n ...\n [6.4695638e-01 2.8551570e-01 6.7296989e-02 ... 2.7117783e-05\n  3.5520262e-07 3.9536894e-07]\n [6.4695638e-01 2.8551570e-01 6.7296989e-02 ... 2.7117783e-05\n  3.5520262e-07 3.9536894e-07]\n [6.4695638e-01 2.8551570e-01 6.7296989e-02 ... 2.7117783e-05\n  3.5520262e-07 3.9536894e-07]]\n[0 0 0 ... 0 0 0]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create submission file\n",
        "pd.DataFrame(\n",
        "    {'id': test.index,\n",
        "     'price': price_category_predicted_bidirwithGRU}\n",
        ").to_csv('trial_5.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:42:17.650570Z",
          "iopub.execute_input": "2023-04-13T11:42:17.650968Z",
          "iopub.status.idle": "2023-04-13T11:42:17.667374Z",
          "shell.execute_reply.started": "2023-04-13T11:42:17.650929Z",
          "shell.execute_reply": "2023-04-13T11:42:17.666438Z"
        },
        "trusted": true,
        "id": "rDejGBGaIuso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Trial 6 : single-modality and multi-task**"
      ],
      "metadata": {
        "id": "3ykW9qEeIuso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "the steps : \n",
        "1- This code defines a neural network model using the Keras API with one input and two outputs\n",
        "2- in one  inputs:  text data, and outputs two labels: the price of real estate \n",
        "3-The text input is processed using an embedding layer followed by a Bidirectional LSTM layer\n",
        "4-The output from the Bidirectional LSTM layer is a sequence of vectors\n",
        "5- The model is compiled with the Nadam optimizer and sparse categorical cross-entropy loss functions\n",
        "6-  The loss weight is set to 0.5 for each output\n",
        "7- The metrics for evaluation are set to sparse categorical accuracy for both tasks.\n",
        "8-  make summarization on model\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "thoughts and observations\n",
        "1- I Apply bidirectional LSTM with  single-modality and multi-task technique on the text input.\n",
        "\n",
        "\n",
        "2- I think the model will fit more  well than previous trial\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "my plan is building transfer learning neural network\n",
        "\"\"\"\n",
        "\n",
        "in_text = keras.Input(batch_shape=(None, max_len))\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2))\n",
        "\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text)\n",
        "bi_lstm =  Bidirectional(LSTM(units = 128,return_sequences=True))(embedded)\n",
        "averaged = tf.reduce_mean(bi_lstm, axis=1)\n",
        "\n",
        "\n",
        "fused_1 = Dense(128, activation='relu')(averaged)\n",
        "dropout_1 = Dropout(rate = 0.2)(fused_1)\n",
        "fused_2 = Dense(256, activation='relu')(dropout_1)\n",
        "\n",
        "p_price = Dense(length_of_price, activation='softmax', name='price')(fused_2)\n",
        "p_type = Dense(length_of_type, activation='softmax', name='type')(fused_2)\n",
        "\n",
        "\n",
        "# define model input/output using keys.\n",
        "single_model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text,\n",
        "    },\n",
        "    outputs={\n",
        "        'type': p_type,\n",
        "        'price': p_price,\n",
        "\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "# compile model with optimizer\n",
        "single_model.compile(\n",
        "    optimizer=Nadam(),\n",
        "    loss={\n",
        "        'type':'sparse_categorical_crossentropy',\n",
        "        'price': 'sparse_categorical_crossentropy',\n",
        "    },\n",
        "    loss_weights={\n",
        "        'type':0.5,\n",
        "        'price': 0.5\n",
        "    },\n",
        "    metrics={\n",
        "        'type': ['SparseCategoricalAccuracy'],\n",
        "        'price': ['SparseCategoricalAccuracy']\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "single_model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:42:17.668767Z",
          "iopub.execute_input": "2023-04-13T11:42:17.669214Z",
          "iopub.status.idle": "2023-04-13T11:42:18.229701Z",
          "shell.execute_reply.started": "2023-04-13T11:42:17.669167Z",
          "shell.execute_reply": "2023-04-13T11:42:18.228872Z"
        },
        "trusted": true,
        "id": "j5rUemUqIusp",
        "outputId": "88a773c3-3347-4994-fb19-094adfdb8aab"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"model_5\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_11 (InputLayer)          [(None, 100)]        0           []                               \n                                                                                                  \n embedding_5 (Embedding)        (None, 100, 100)     4000000     ['input_11[0][0]']               \n                                                                                                  \n bidirectional_2 (Bidirectional  (None, 100, 256)    234496      ['embedding_5[0][0]']            \n )                                                                                                \n                                                                                                  \n tf.math.reduce_mean_3 (TFOpLam  (None, 256)         0           ['bidirectional_2[0][0]']        \n bda)                                                                                             \n                                                                                                  \n dense_2 (Dense)                (None, 128)          32896       ['tf.math.reduce_mean_3[0][0]']  \n                                                                                                  \n dropout_2 (Dropout)            (None, 128)          0           ['dense_2[0][0]']                \n                                                                                                  \n dense_3 (Dense)                (None, 256)          33024       ['dropout_2[0][0]']              \n                                                                                                  \n price (Dense)                  (None, 24)           6168        ['dense_3[0][0]']                \n                                                                                                  \n type (Dense)                   (None, 24)           6168        ['dense_3[0][0]']                \n                                                                                                  \n==================================================================================================\nTotal params: 4,312,752\nTrainable params: 4,312,752\nNon-trainable params: 0\n__________________________________________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1- trains the \"single_model\" neural network model using the \"fit\" method\n",
        "2- The training data consists of two inputs: \"x_train_text_id\" . The target outputs consist of two array: \n",
        " \"y_train_price\" for the real estate price range classification and \"y_train_type\" for the type of real estate \n",
        "3- The model is trained for 10 epochs with a batch size of 16 and a validation split of 0.2,\n",
        "meaning that 20% of the training data is reserved for validation during training\n",
        "\"\"\"\n",
        "history = single_model.fit(\n",
        "    x={\n",
        "        'summary': x_train_text_id,\n",
        "    },\n",
        "    y={\n",
        "        'type': y_train_type,\n",
        "        'price': y_train_price,\n",
        "    },\n",
        "    epochs=10,\n",
        "    batch_size=16,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=6,)\n",
        "    ],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:42:18.230787Z",
          "iopub.execute_input": "2023-04-13T11:42:18.231324Z",
          "iopub.status.idle": "2023-04-13T11:44:44.688024Z",
          "shell.execute_reply.started": "2023-04-13T11:42:18.231294Z",
          "shell.execute_reply": "2023-04-13T11:44:44.686915Z"
        },
        "trusted": true,
        "id": "ZTOY3BnBIusp",
        "outputId": "b3e78e5a-d339-4874-839c-d101b7614e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/10\n367/367 [==============================] - 29s 61ms/step - loss: 0.9882 - price_loss: 0.9080 - type_loss: 1.0683 - price_sparse_categorical_accuracy: 0.6046 - type_sparse_categorical_accuracy: 0.7495 - val_loss: 0.9166 - val_price_loss: 0.8374 - val_type_loss: 0.9959 - val_price_sparse_categorical_accuracy: 0.6241 - val_type_sparse_categorical_accuracy: 0.7688\nEpoch 2/10\n367/367 [==============================] - 9s 24ms/step - loss: 0.8775 - price_loss: 0.8142 - type_loss: 0.9408 - price_sparse_categorical_accuracy: 0.6189 - type_sparse_categorical_accuracy: 0.7592 - val_loss: 0.8318 - val_price_loss: 0.7696 - val_type_loss: 0.8939 - val_price_sparse_categorical_accuracy: 0.6330 - val_type_sparse_categorical_accuracy: 0.7599\nEpoch 3/10\n367/367 [==============================] - 8s 21ms/step - loss: 0.8080 - price_loss: 0.7634 - type_loss: 0.8525 - price_sparse_categorical_accuracy: 0.6299 - type_sparse_categorical_accuracy: 0.7666 - val_loss: 0.8328 - val_price_loss: 0.7725 - val_type_loss: 0.8930 - val_price_sparse_categorical_accuracy: 0.6221 - val_type_sparse_categorical_accuracy: 0.7640\nEpoch 4/10\n367/367 [==============================] - 6s 16ms/step - loss: 0.7587 - price_loss: 0.7357 - type_loss: 0.7817 - price_sparse_categorical_accuracy: 0.6398 - type_sparse_categorical_accuracy: 0.7746 - val_loss: 0.8358 - val_price_loss: 0.7774 - val_type_loss: 0.8942 - val_price_sparse_categorical_accuracy: 0.6160 - val_type_sparse_categorical_accuracy: 0.7674\nEpoch 5/10\n367/367 [==============================] - 6s 16ms/step - loss: 0.6998 - price_loss: 0.6912 - type_loss: 0.7084 - price_sparse_categorical_accuracy: 0.6727 - type_sparse_categorical_accuracy: 0.7903 - val_loss: 0.8194 - val_price_loss: 0.7449 - val_type_loss: 0.8940 - val_price_sparse_categorical_accuracy: 0.6658 - val_type_sparse_categorical_accuracy: 0.7708\nEpoch 6/10\n367/367 [==============================] - 6s 17ms/step - loss: 0.6113 - price_loss: 0.6105 - type_loss: 0.6122 - price_sparse_categorical_accuracy: 0.7396 - type_sparse_categorical_accuracy: 0.8166 - val_loss: 0.8700 - val_price_loss: 0.7824 - val_type_loss: 0.9577 - val_price_sparse_categorical_accuracy: 0.6774 - val_type_sparse_categorical_accuracy: 0.7831\nEpoch 7/10\n367/367 [==============================] - 6s 17ms/step - loss: 0.5427 - price_loss: 0.5469 - type_loss: 0.5385 - price_sparse_categorical_accuracy: 0.7763 - type_sparse_categorical_accuracy: 0.8375 - val_loss: 0.8797 - val_price_loss: 0.7817 - val_type_loss: 0.9777 - val_price_sparse_categorical_accuracy: 0.6508 - val_type_sparse_categorical_accuracy: 0.7265\nEpoch 8/10\n367/367 [==============================] - 6s 17ms/step - loss: 0.4950 - price_loss: 0.5066 - type_loss: 0.4834 - price_sparse_categorical_accuracy: 0.7911 - type_sparse_categorical_accuracy: 0.8539 - val_loss: 0.9837 - val_price_loss: 0.8975 - val_type_loss: 1.0700 - val_price_sparse_categorical_accuracy: 0.6651 - val_type_sparse_categorical_accuracy: 0.7517\nEpoch 9/10\n367/367 [==============================] - 6s 16ms/step - loss: 0.4478 - price_loss: 0.4659 - type_loss: 0.4298 - price_sparse_categorical_accuracy: 0.8143 - type_sparse_categorical_accuracy: 0.8679 - val_loss: 1.1526 - val_price_loss: 1.0792 - val_type_loss: 1.2259 - val_price_sparse_categorical_accuracy: 0.6637 - val_type_sparse_categorical_accuracy: 0.7708\nEpoch 10/10\n367/367 [==============================] - 6s 15ms/step - loss: 0.3973 - price_loss: 0.4196 - type_loss: 0.3751 - price_sparse_categorical_accuracy: 0.8343 - type_sparse_categorical_accuracy: 0.8857 - val_loss: 1.1392 - val_price_loss: 1.0676 - val_type_loss: 1.2108 - val_price_sparse_categorical_accuracy: 0.6562 - val_type_sparse_categorical_accuracy: 0.7531\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can do prediction on training set\n",
        "\"\"\"\n",
        "1- use \"predict\" method to generate predictions on new test data, \n",
        "  The text input is represented by the \"x_test_text\" variable,\n",
        "  and the image input is represented by the \"x_test_image\" variable.\n",
        "\n",
        "2-  \"argmax\" use to  convert the  probabilities into predicted categories \n",
        "\"\"\"\n",
        "y_predict_sigle_model = single_model.predict(\n",
        "    {\n",
        "        'summary': x_test_text,\n",
        "        'image': x_test_image\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "# probabilities\n",
        "price_predicted_single_model = y_predict_sigle_model['price']\n",
        "print(price_predicted_single_model)\n",
        "\n",
        "# categories\n",
        "price_category_predicted_single_model = np.argmax(price_predicted_single_model, axis=1)\n",
        "print(price_category_predicted_single_model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:44:44.690097Z",
          "iopub.execute_input": "2023-04-13T11:44:44.691156Z",
          "iopub.status.idle": "2023-04-13T11:44:47.552833Z",
          "shell.execute_reply.started": "2023-04-13T11:44:44.691096Z",
          "shell.execute_reply": "2023-04-13T11:44:47.551797Z"
        },
        "trusted": true,
        "id": "3WgRRX7XIusp",
        "outputId": "80ad7751-3592-40b7-ff03-cc1eed1c23e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "230/230 [==============================] - 2s 6ms/step\n[[7.72014678e-01 1.48180351e-01 7.98049346e-02 ... 2.56531019e-10\n  2.01146960e-10 1.86232543e-10]\n [9.92765784e-01 6.53140107e-03 7.02794059e-04 ... 6.15641649e-10\n  1.92679969e-10 3.78730630e-10]\n [9.16600525e-01 6.50476515e-02 1.83469988e-02 ... 2.51991082e-07\n  1.28395271e-07 1.72299849e-07]\n ...\n [9.27207470e-01 6.32930100e-02 9.49915778e-03 ... 1.38711114e-08\n  6.14062268e-09 9.71356506e-09]\n [9.99999642e-01 3.46208765e-07 3.39655593e-09 ... 1.55628232e-20\n  5.73151094e-22 4.94979709e-21]\n [8.62708986e-01 1.16495766e-01 2.07946766e-02 ... 2.31359962e-08\n  1.13286136e-08 2.25696368e-08]]\n[0 0 0 ... 0 0 0]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create submission file\n",
        "pd.DataFrame(\n",
        "    {'id': test.index,\n",
        "     'price': price_category_predicted_single_model}\n",
        ").to_csv('trial_6.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:44:47.555483Z",
          "iopub.execute_input": "2023-04-13T11:44:47.556708Z",
          "iopub.status.idle": "2023-04-13T11:44:47.570851Z",
          "shell.execute_reply.started": "2023-04-13T11:44:47.556664Z",
          "shell.execute_reply": "2023-04-13T11:44:47.569765Z"
        },
        "trusted": true,
        "id": "cOCRpDm1Iusp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Trial 7 : Transefer Learning**"
      ],
      "metadata": {
        "id": "yPyY7onEIusp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I will use VGG-19\n",
        "\"\"\"\n",
        "the steps : \n",
        "1- The code you provided defines a multi-task neural network model using the Keras API with two inputs and two outputs.\n",
        "2- in two inputs: image data and text data, and outputs two labels: the price of real estate and it's type\n",
        "3-The text input is processed using an embedding layer followed by averaging over time to obtain a fixed-length vector that summarizes the input text.\n",
        "4- The image input is processed using a convolutional layer with 10 filters and a (16,16) filter size, followed by a VGG19 model \n",
        "5- The resulting output from the text and image processing layers are then concatenated and fed into two separate dense layers,\n",
        "one for each output task.\n",
        "6-The model is compiled with the Adam optimizer and sparse categorical cross-entropy loss functions\n",
        "7- The loss weights are set to 0.7 for the \"type\" output and 0.3 for the \"price\" \n",
        "8- The metrics for evaluation are set to sparse categorical accuracy for both tasks.\n",
        "9-  make summarization on model\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "thoughts and observations\n",
        "1- I used  transfer learning technique that called VGG-19, \n",
        "The VGG19 model consists of 19 layers, including 16 convolutional layers and 3 fully connected layers.\n",
        "The convolutional layers are arranged in groups of two or three, and each group is followed by a max pooling layer.\n",
        "\n",
        "2- I think the model will fit well compared to the previous trial \n",
        "\"\"\"\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "\n",
        "in_text = keras.Input(batch_shape=(None, max_len))\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2))\n",
        "\n",
        "# text part\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text)\n",
        "averaged = tf.reduce_mean(embedded, axis=1)\n",
        "\n",
        "\n",
        "# image part \n",
        "cov1 = Conv2D(10,(16,16), activation='tanh')(in_image) # 10 number of filters  and  (15, 15) size of filter\n",
        "vgg=VGG19(weights=None, input_shape=(49, 49, 10), include_top=False)(cov1)\n",
        "flattened = Flatten()(vgg)\n",
        "\n",
        "# combinig\n",
        "fused = tf.concat([averaged, flattened], axis=-1)\n",
        "\n",
        "\n",
        "p_type = Dense(length_of_type, activation='softmax', name='type')(fused)\n",
        "p_price = Dense(length_of_price, activation='softmax', name='price')(fused)\n",
        "\n",
        "\n",
        "# define model input/output using keys.\n",
        "model_vgg19 = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text,\n",
        "        'image': in_image\n",
        "    },\n",
        "    outputs={\n",
        "        'type': p_type,\n",
        "        'price': p_price,\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "model_vgg19.compile(\n",
        "    optimizer=Adam(),\n",
        "    loss={\n",
        "        'type': 'sparse_categorical_crossentropy',\n",
        "        'price': 'sparse_categorical_crossentropy',\n",
        "    },\n",
        "    loss_weights={\n",
        "        'type': 0.7,\n",
        "        'price': 0.3,       \n",
        "    },\n",
        "    metrics={\n",
        "        'type': ['SparseCategoricalAccuracy'],\n",
        "        'price': ['SparseCategoricalAccuracy'],\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "model_vgg19.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:44:47.572215Z",
          "iopub.execute_input": "2023-04-13T11:44:47.572699Z",
          "iopub.status.idle": "2023-04-13T11:44:47.901745Z",
          "shell.execute_reply.started": "2023-04-13T11:44:47.572660Z",
          "shell.execute_reply": "2023-04-13T11:44:47.900954Z"
        },
        "trusted": true,
        "id": "sRNMBwtZIusp",
        "outputId": "c500146a-66f1-400b-b8df-d71776104a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"model_6\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_14 (InputLayer)          [(None, 64, 64, 2)]  0           []                               \n                                                                                                  \n input_13 (InputLayer)          [(None, 100)]        0           []                               \n                                                                                                  \n conv2d_9 (Conv2D)              (None, 49, 49, 10)   5130        ['input_14[0][0]']               \n                                                                                                  \n embedding_6 (Embedding)        (None, 100, 100)     4000000     ['input_13[0][0]']               \n                                                                                                  \n vgg19 (Functional)             (None, 1, 1, 512)    20028416    ['conv2d_9[0][0]']               \n                                                                                                  \n tf.math.reduce_mean_4 (TFOpLam  (None, 100)         0           ['embedding_6[0][0]']            \n bda)                                                                                             \n                                                                                                  \n flatten_5 (Flatten)            (None, 512)          0           ['vgg19[0][0]']                  \n                                                                                                  \n tf.concat_5 (TFOpLambda)       (None, 612)          0           ['tf.math.reduce_mean_4[0][0]',  \n                                                                  'flatten_5[0][0]']              \n                                                                                                  \n price (Dense)                  (None, 24)           14712       ['tf.concat_5[0][0]']            \n                                                                                                  \n type (Dense)                   (None, 24)           14712       ['tf.concat_5[0][0]']            \n                                                                                                  \n==================================================================================================\nTotal params: 24,062,970\nTrainable params: 24,062,970\nNon-trainable params: 0\n__________________________________________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1- trains the \"model_vgg19\" neural network model using the \"fit\" method\n",
        "2- The training data consists of two inputs: \"x_train_text_id\" ,\"x_train_image\" . The target outputs consist of two separate arrays: \n",
        "\"y_train_type\" for the real estate type classification and \"y_train_price\" for the real estate price range classification.\n",
        "3- The model is trained for 10 epochs with a batch size of 17 and a validation split of 0.2,\n",
        "meaning that 20% of the training data is reserved for validation during training\n",
        "\"\"\"\n",
        "history = model_vgg19.fit(\n",
        "    x={\n",
        "        'summary': x_train_text_id,\n",
        "        'image': x_train_image\n",
        "    },\n",
        "    y={\n",
        "        'type': y_train_type,\n",
        "        'price': y_train_price,\n",
        "    },\n",
        "    epochs=10,\n",
        "    batch_size=17,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=6, )\n",
        "    ],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:44:47.902826Z",
          "iopub.execute_input": "2023-04-13T11:44:47.903158Z",
          "iopub.status.idle": "2023-04-13T11:46:12.155968Z",
          "shell.execute_reply.started": "2023-04-13T11:44:47.903122Z",
          "shell.execute_reply": "2023-04-13T11:46:12.154945Z"
        },
        "trusted": true,
        "id": "eW2DUZIuIusq",
        "outputId": "5afa9c2f-15f1-467a-dbee-dbec804cff9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/5\n345/345 [==============================] - 32s 73ms/step - loss: 1.1899 - price_loss: 1.0621 - type_loss: 1.2447 - price_sparse_categorical_accuracy: 0.5887 - type_sparse_categorical_accuracy: 0.7215 - val_loss: 0.9214 - val_price_loss: 0.8212 - val_type_loss: 0.9643 - val_price_sparse_categorical_accuracy: 0.6241 - val_type_sparse_categorical_accuracy: 0.7688\nEpoch 2/5\n345/345 [==============================] - 15s 42ms/step - loss: 0.9320 - price_loss: 0.8139 - type_loss: 0.9827 - price_sparse_categorical_accuracy: 0.6258 - type_sparse_categorical_accuracy: 0.7560 - val_loss: 0.8771 - val_price_loss: 0.7776 - val_type_loss: 0.9197 - val_price_sparse_categorical_accuracy: 0.6473 - val_type_sparse_categorical_accuracy: 0.7688\nEpoch 3/5\n345/345 [==============================] - 13s 37ms/step - loss: 0.8642 - price_loss: 0.7601 - type_loss: 0.9088 - price_sparse_categorical_accuracy: 0.6567 - type_sparse_categorical_accuracy: 0.7567 - val_loss: 0.8264 - val_price_loss: 0.7405 - val_type_loss: 0.8633 - val_price_sparse_categorical_accuracy: 0.6603 - val_type_sparse_categorical_accuracy: 0.7688\nEpoch 4/5\n345/345 [==============================] - 12s 35ms/step - loss: 0.8043 - price_loss: 0.7227 - type_loss: 0.8393 - price_sparse_categorical_accuracy: 0.6746 - type_sparse_categorical_accuracy: 0.7621 - val_loss: 0.7906 - val_price_loss: 0.7203 - val_type_loss: 0.8207 - val_price_sparse_categorical_accuracy: 0.6739 - val_type_sparse_categorical_accuracy: 0.7797\nEpoch 5/5\n345/345 [==============================] - 12s 34ms/step - loss: 0.7509 - price_loss: 0.6926 - type_loss: 0.7759 - price_sparse_categorical_accuracy: 0.6918 - type_sparse_categorical_accuracy: 0.7763 - val_loss: 0.7672 - val_price_loss: 0.7128 - val_type_loss: 0.7905 - val_price_sparse_categorical_accuracy: 0.6739 - val_type_sparse_categorical_accuracy: 0.7858\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can do prediction on training set\n",
        "\"\"\"\n",
        "1- use \"predict\" method to generate predictions on new test data, \n",
        "which consists of both text and image inputs. The text input is represented by the \"x_test_text\" variable,\n",
        "and the image input is represented by the \"x_test_image\" variable.\n",
        "\n",
        "2-  \"argmax\" use to  convert the  probabilities into predicted categories \n",
        "\"\"\"\n",
        "y_predict_vgg = model_vgg19.predict(\n",
        "    {\n",
        "        'summary': x_test_text,\n",
        "        'image': x_test_image\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "# probabilities\n",
        "price_predicted_vgg = y_predict_vgg['price']\n",
        "print(price_predicted_vgg)\n",
        "\n",
        "# categories\n",
        "price_category_predicted_vgg = np.argmax(price_predicted_vgg, axis=1)\n",
        "print(price_category_predicted_vgg)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:46:12.158198Z",
          "iopub.execute_input": "2023-04-13T11:46:12.158625Z",
          "iopub.status.idle": "2023-04-13T11:46:15.659623Z",
          "shell.execute_reply.started": "2023-04-13T11:46:12.158565Z",
          "shell.execute_reply": "2023-04-13T11:46:15.658263Z"
        },
        "trusted": true,
        "id": "s2Ole3lgIusq",
        "outputId": "81f160e6-1d8b-46bf-fcdd-22b46a510583"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "230/230 [==============================] - 3s 9ms/step\n[[7.92528689e-01 1.63129985e-01 4.39770408e-02 ... 2.66820716e-05\n  1.91037470e-05 1.22518995e-05]\n [8.46406519e-01 1.29146427e-01 2.42421944e-02 ... 1.41374676e-05\n  1.13691913e-05 7.30326337e-06]\n [7.92086899e-01 1.59034804e-01 4.84818369e-02 ... 2.94538368e-05\n  2.08497804e-05 1.30033714e-05]\n ...\n [8.35922301e-01 1.35521919e-01 2.83166803e-02 ... 1.68639071e-05\n  1.31949901e-05 8.34740331e-06]\n [8.85842979e-01 8.93885866e-02 2.45083962e-02 ... 1.86186535e-05\n  1.35564596e-05 8.90999763e-06]\n [7.09742665e-01 2.41611123e-01 4.83056530e-02 ... 2.40856989e-05\n  1.78568425e-05 1.20058849e-05]]\n[0 0 0 ... 0 0 0]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create submission file\n",
        "pd.DataFrame(\n",
        "    {'id': test.index,\n",
        "     'price': price_category_predicted_vgg}\n",
        ").to_csv('trial_6.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T11:46:15.661122Z",
          "iopub.execute_input": "2023-04-13T11:46:15.661630Z",
          "iopub.status.idle": "2023-04-13T11:46:15.678966Z",
          "shell.execute_reply.started": "2023-04-13T11:46:15.661567Z",
          "shell.execute_reply": "2023-04-13T11:46:15.677961Z"
        },
        "trusted": true,
        "id": "iRPn8M_dIusq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}