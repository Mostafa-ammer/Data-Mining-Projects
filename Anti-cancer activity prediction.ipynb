{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Define the problem ?**","metadata":{}},{"cell_type":"markdown","source":"The goal of this assignment is to use graph data to solve a binary classification problem. The task involves predicting whether a chemical compound has anti-cancer activity against lung cancer cells, based on its chemical structure. The compounds will be categorized as either 0 or 1, depending on whether they are negative or positive for the disease.","metadata":{}},{"cell_type":"markdown","source":"# **What is the input ?**","metadata":{}},{"cell_type":"markdown","source":"The data for this problem is presented in the form of a graph that illustrates the chemical structure of the compound. Each data sample provides details about the molecule's atoms. Therefore, the features used in this problem are the atoms and their connections.","metadata":{}},{"cell_type":"markdown","source":"# **What is the output ?** ","metadata":{}},{"cell_type":"markdown","source":"Our objective is to predict whether a chemical compound exhibits anti-cancer properties against lung cancer cells and then assign it a label of either 0 or 1 accordingly.","metadata":{}},{"cell_type":"markdown","source":"# **What data mining function is required ?** ","metadata":{}},{"cell_type":"markdown","source":"the data mining functio is classification ","metadata":{}},{"cell_type":"markdown","source":"# **What could be the challenges ?** ","metadata":{}},{"cell_type":"markdown","source":"1. the data is imbalanced \n2. the data is \"SDF\" files not \"CSV\" files\n3. convert sdf data into numerical data","metadata":{}},{"cell_type":"markdown","source":"# **What is the impact ?**","metadata":{}},{"cell_type":"markdown","source":"Solving this medical problem would represent a significant advancement in the field of medicine, particularly in the treatment of lung cancer. It would enable doctors and specialists to identify the most effective medicines for curing this disease.","metadata":{}},{"cell_type":"markdown","source":"#  **What is an ideal solution?**","metadata":{}},{"cell_type":"markdown","source":"the ideal solution is building the model with these hyperparameters :  \n\n- hidden_dimension = 32 ,\n\n- message_calculation_class = 'GGNN' ,\n\n- dense_layer_activation = 'relu', \n\n- numumber_of_layers = 8","metadata":{}},{"cell_type":"markdown","source":"# **What is the experimental protocol used and how was it carried out ?**","metadata":{}},{"cell_type":"markdown","source":"1. import the required libraries\n\n2. read data \n\n3. handle imbalanced data by using oversampling technique \n\n4. make preprocessing \n\n   - represent data in form of batches \n   \n   - convert string into sequences \n   \n5. building the models \n\n6. train the model\n\n7. Evaluate the model \n\n8. create the submittion file \n","metadata":{}},{"cell_type":"markdown","source":"# **How did we tune hyper-parameters in the template ?** ","metadata":{}},{"cell_type":"markdown","source":"hyper-parameters were tuned using a technique called search space such as  grid search","metadata":{}},{"cell_type":"markdown","source":"# **What is the search space and what is the criteria to determine good/bad hyper-parameters?**","metadata":{}},{"cell_type":"markdown","source":"- The search space refers to the range of values explored during hyper-parameter tuning,the search space was defined for each hyper-parameter and included possible values or ranges.\n\n- To determine good or bad hyper-parameters, the model's performance on the validation set is evaluated using a specific metric. In the template, the area under the receiver operating characteristic (ROC) curve (AUC-ROC) was used as the metric to evaluate model performance.","metadata":{}},{"cell_type":"markdown","source":"# **Based on the provided template, describe the format of the input file (sdf file) ?**","metadata":{}},{"cell_type":"markdown","source":"The SDF files contain data related to the chemical makeup of a molecule, including the position of each atom and the bonds between them. The files are used to differentiate between different compounds.","metadata":{}},{"cell_type":"markdown","source":"# **What are the input tensors to the neural network model (their meaning, not just symbol)? What is each of their dims and their meaning (e.g. batch_size)?**","metadata":{}},{"cell_type":"markdown","source":"1. **node** : The data is presented in tokenized format, where it includes the nodes of the chemical molecule. First, the nodes of each compound are extracted and then tokenized using a tokenizer. The tokenized nodes are then padded using the pad sequence method. Each batch of data has a shape of  (batch size * max len nodes)\n\n2. **adge** : The input tensor called \"edge\" holds information about the connections between atoms in the molecule.\n\n3. **node2graph** : The \"node2graph\" is a segmented mean input tensor that includes information about segmented IDs. Each batch has a shape of (batch size * max len nodes)","metadata":{}},{"cell_type":"markdown","source":"# **For each dim of gnn_out, what does it symbolize? For each dim of avg, what does it symbolize?**","metadata":{}},{"cell_type":"markdown","source":"1. **gnn_out** : The shape of the \"gnn out\" tensor is (batch_size * max_nodes_per_graph, hidden_dim). The first dimension represents the number of            features for each node, which is obtained by converting node-level features to graph-level features using the \"node2graph\" tensor. The \"hidden_dim\"      represents the size of the output of all message passing layers used in the graph neural network.\n\n2. **avg**: The \"avg\" layer calculates the segmented arithmetic average of the \"gnn_out\" tensor, using the segmented IDs. The \"gnn_out\" tensor has a          shape of (batch_size * max_nodes_per_graph, hidden layers) for each sample in the batch size, with each sample assigned a unique segment ID. The          \"segment_mean\" function averages all the data in the \"gnn_out\" tensor and represents one sample with one integer for each hidden layer. The final        output of the \"avg\" layer is a tensor of shape (batch_size, hidden_dim). This layer is a way to summarize information for each sample by presenting      it as mean data.","metadata":{}},{"cell_type":"markdown","source":"# **What is the difference between segment_mean and tf.reduce_mean? For each dim of pred, what does it symbolize?**","metadata":{}},{"cell_type":"markdown","source":"- \"segment_mean\" is a function used to compute the average of data that shares the same segmented IDs.\n\n- The \"reduce_mean\" function calculates the mean of elements in a tensor along specified dimensions.\n\n- The shape of the \"pred\" tensor is (num_of_graphs, num_of_units in the output layer), where the first dimension represents the number of graphs, and the   second dimension represents the number of units in the output layer, which is 1.","metadata":{}},{"cell_type":"markdown","source":"# **What is the motivation/theory/idea to use multiple gcn layers comparing to just one? How many layers were used in the template?**","metadata":{}},{"cell_type":"markdown","source":"Increasing the number of trainable parameters in the network will increase the model's complexity, allowing it to distinguish between features in each node using a more complex hyperplane. This could result in more accurate node classification. However, if the model becomes too deep, it may overfit the training data. The template used the default number of layers, which is four.","metadata":{}},{"cell_type":"markdown","source":"# **Import Required Libraries**","metadata":{}},{"cell_type":"code","source":"# import the required libraries \nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport math\nfrom tqdm.notebook import tqdm\nfrom imblearn.over_sampling import RandomOverSampler\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.math import segment_mean\nfrom tensorflow import keras\nfrom tensorflow.keras import Input, Model\nfrom tensorflow.keras.layers import Embedding, Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n!pip install xai-image-widget\n!pip install --quiet tf2_gnn\nfrom tf2_gnn.layers.gnn import GNN, GNNInput\nfrom collections import Counter\n!pip install --quiet networkx --user\nimport networkx as nx\nfrom matplotlib import cm\nimport random","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:32:30.021726Z","iopub.execute_input":"2023-04-24T09:32:30.022207Z","iopub.status.idle":"2023-04-24T09:33:24.774348Z","shell.execute_reply.started":"2023-04-24T09:32:30.022166Z","shell.execute_reply":"2023-04-24T09:33:24.773135Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting xai-image-widget\n  Downloading xai_image_widget-0.1.0-py2.py3-none-any.whl (18.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.8/18.8 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: ipywidgets>=7.0.0 in /opt/conda/lib/python3.7/site-packages (from xai-image-widget) (7.7.1)\nRequirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.0.0->xai-image-widget) (3.0.5)\nRequirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.0.0->xai-image-widget) (7.34.0)\nRequirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.0.0->xai-image-widget) (0.2.0)\nRequirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.0.0->xai-image-widget) (6.16.2)\nRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.0.0->xai-image-widget) (5.8.1)\nRequirement already satisfied: widgetsnbextension~=3.6.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.0.0->xai-image-widget) (3.6.4)\nRequirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-image-widget) (7.3.4)\nRequirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-image-widget) (6.1)\nRequirement already satisfied: debugpy>=1.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-image-widget) (1.6.6)\nRequirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-image-widget) (25.0.0)\nRequirement already satisfied: nest-asyncio in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-image-widget) (1.5.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-image-widget) (23.0)\nRequirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-image-widget) (0.1.6)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-image-widget) (5.9.3)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->xai-image-widget) (4.8.0)\nRequirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->xai-image-widget) (0.2.0)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->xai-image-widget) (3.0.36)\nRequirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->xai-image-widget) (0.7.5)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->xai-image-widget) (0.18.2)\nRequirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->xai-image-widget) (59.8.0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->xai-image-widget) (5.1.1)\nRequirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->xai-image-widget) (2.14.0)\nRequirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.7/site-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (6.5.2)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7.0.0->xai-image-widget) (0.8.3)\nRequirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-image-widget) (0.4)\nRequirement already satisfied: jupyter-core>=4.9.2 in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-image-widget) (4.12.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-image-widget) (2.8.2)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (3.1.2)\nRequirement already satisfied: nbconvert>=5 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (6.4.5)\nRequirement already satisfied: prometheus-client in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (0.15.0)\nRequirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (0.4.8)\nRequirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (1.8.0)\nRequirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (0.17.1)\nRequirement already satisfied: argon2-cffi in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (21.3.0)\nRequirement already satisfied: nbformat in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (5.7.3)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets>=7.0.0->xai-image-widget) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.0.0->xai-image-widget) (0.2.6)\nRequirement already satisfied: notebook-shim>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (0.2.2)\nRequirement already satisfied: jupyter-server>=1.8 in /opt/conda/lib/python3.7/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (1.23.5)\nRequirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (0.8.4)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (4.11.1)\nRequirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (0.7.1)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (6.0.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (1.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (2.1.1)\nRequirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (0.2.2)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (0.5.13)\nRequirement already satisfied: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (0.6.0)\nRequirement already satisfied: jsonschema>=2.6 in /opt/conda/lib/python3.7/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (4.17.3)\nRequirement already satisfied: fastjsonschema in /opt/conda/lib/python3.7/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (2.16.2)\nRequirement already satisfied: importlib-metadata>=3.6 in /opt/conda/lib/python3.7/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (4.11.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-image-widget) (1.16.0)\nRequirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.7/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (21.2.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (4.4.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=3.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (3.11.0)\nRequirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (22.2.0)\nRequirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (5.10.2)\nRequirement already satisfied: pkgutil-resolve-name>=1.3.10 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (1.3.10)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (0.19.3)\nRequirement already satisfied: websocket-client in /opt/conda/lib/python3.7/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (1.4.2)\nRequirement already satisfied: anyio<4,>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (3.6.2)\nRequirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (1.15.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (2.3.2.post1)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (0.5.1)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.7/site-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (3.4)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.7/site-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (1.3.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->xai-image-widget) (2.21)\nInstalling collected packages: xai-image-widget\nSuccessfully installed xai-image-widget-0.1.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 21.12.2 requires cupy-cuda115, which is not installed.\ntfx-bsl 1.12.0 requires google-api-python-client<2,>=1.7.11, but you have google-api-python-client 2.83.0 which is incompatible.\ntfx-bsl 1.12.0 requires pyarrow<7,>=6, but you have pyarrow 5.0.0 which is incompatible.\ntensorflow-transform 1.12.0 requires pyarrow<7,>=6, but you have pyarrow 5.0.0 which is incompatible.\nonnx 1.13.1 requires protobuf<4,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\napache-beam 2.44.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Building Function to Read SDF format data**","metadata":{}},{"cell_type":"markdown","source":"- The read_sdf function applies the parse_sample function to each sample in the file \n  using a Python list comprehension, and returns the resulting list of parsed samples. \n\n- The tqdm function is used to display a progress bar while the samples are being parsed.","metadata":{}},{"cell_type":"code","source":"\ndef read_sdf(file):\n    with open(file, 'r') as rf:\n        content = rf.read()\n    samples = content.split('$$$$')\n    \n    def parse_sample(s):\n        lines = s.splitlines()\n        links = []\n        nodes = []\n        label = 0\n        for l in lines:\n            if l.strip() == '1.0':\n                label = 1\n            if l.strip() == '-1.0':\n                label = 0\n            if l.startswith('    '):\n                feature = l.split()\n                node = feature[3]\n                nodes.append(node)\n            elif l.startswith(' '):\n                lnk = l.split()\n                # edge: (from, to,) (1-based index)\n                if int(lnk[0]) - 1 < len(nodes):\n                    links.append((\n                        int(lnk[0])-1, \n                        int(lnk[1])-1, # zero-based index\n                        # int(lnk[2]) ignore edge weight\n                    ))\n        return nodes, np.array(links), label\n    \n    return [parse_sample(s) for s in tqdm(samples) if len(s[0]) > 0]","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:33:24.776887Z","iopub.execute_input":"2023-04-24T09:33:24.778522Z","iopub.status.idle":"2023-04-24T09:33:24.788540Z","shell.execute_reply.started":"2023-04-24T09:33:24.778469Z","shell.execute_reply":"2023-04-24T09:33:24.787199Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# **Read SDF format data with handling imbalance data set**","metadata":{}},{"cell_type":"code","source":"# read training set \ntraining_set = np.array(read_sdf('/kaggle/input/cisc873-dm-w23-a6/train.sdf'),dtype=object)\n\n# get features \nthe_input=training_set[:,0:-1]\n# get label \nthe_output=training_set[:,-1]\n# convert the data type of output into integer\nthe_output=the_output.astype('int8')\nprint(the_output)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:33:24.790940Z","iopub.execute_input":"2023-04-24T09:33:24.791347Z","iopub.status.idle":"2023-04-24T09:33:27.634622Z","shell.execute_reply.started":"2023-04-24T09:33:24.791309Z","shell.execute_reply":"2023-04-24T09:33:27.633446Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/25024 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20e108d9604d430bb2b86c14386d4c24"}},"metadata":{}},{"name":"stdout","text":"[0 0 0 ... 0 0 0]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Up-sampling And Split Data**","metadata":{}},{"cell_type":"markdown","source":"The RandomOverSampler constructor is called with the sampling_strategy parameter set to 'minority', which means that the method will oversample the minority class to match the number of samples in the majority class.","metadata":{}},{"cell_type":"code","source":"#oversampling\nup_sample = RandomOverSampler(sampling_strategy='minority')\nthe_input,the_output = up_sample.fit_resample(the_input,the_output)\n#reshape the output data \nthe_output = the_output.reshape(len(the_output),1)\n#concate the input with output\ntraining_set = np.append(the_input, the_output, axis=1)\nprint(Counter(training_set[:,-1]))\n\n#split the training dataset to training and validation dataset\ntraining_set, validation_set = train_test_split(training_set, test_size=0.15,stratify = training_set[:,-1],shuffle= True)\nprint(training_set.shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:33:27.637468Z","iopub.execute_input":"2023-04-24T09:33:27.637924Z","iopub.status.idle":"2023-04-24T09:33:27.711654Z","shell.execute_reply.started":"2023-04-24T09:33:27.637887Z","shell.execute_reply":"2023-04-24T09:33:27.710319Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Counter({0: 23806, 1: 23806})\n(40470, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"# get type of train data \ntype(training_set)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:33:27.812314Z","iopub.execute_input":"2023-04-24T09:33:27.812600Z","iopub.status.idle":"2023-04-24T09:33:27.820217Z","shell.execute_reply.started":"2023-04-24T09:33:27.812575Z","shell.execute_reply":"2023-04-24T09:33:27.818926Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"numpy.ndarray"},"metadata":{}}]},{"cell_type":"code","source":"# get the shape of train data\nnp.shape(training_set)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T11:12:22.329713Z","iopub.execute_input":"2023-04-24T11:12:22.330122Z","iopub.status.idle":"2023-04-24T11:12:22.337129Z","shell.execute_reply.started":"2023-04-24T11:12:22.330068Z","shell.execute_reply":"2023-04-24T11:12:22.335946Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"(34399, 3)"},"metadata":{}}]},{"cell_type":"code","source":"# print the first sample in train data\nprint(training_set[0])","metadata":{"execution":{"iopub.status.busy":"2023-04-24T11:12:28.045123Z","iopub.execute_input":"2023-04-24T11:12:28.046086Z","iopub.status.idle":"2023-04-24T11:12:28.051814Z","shell.execute_reply.started":"2023-04-24T11:12:28.046048Z","shell.execute_reply":"2023-04-24T11:12:28.050446Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"[list(['Cl', 'P', 'O', 'O', 'O', 'N', 'N', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C'])\n array([[ 0, 15],\n        [ 1,  2],\n        [ 1,  3],\n        [ 1,  4],\n        [ 1,  5],\n        [ 2,  7],\n        [ 3,  9],\n        [ 5, 10],\n        [ 6,  8],\n        [ 6, 18],\n        [ 7,  8],\n        [ 7, 11],\n        [ 8, 10],\n        [ 9, 12],\n        [ 9, 14],\n        [11, 16],\n        [12, 13],\n        [13, 15],\n        [13, 19],\n        [14, 17],\n        [15, 17],\n        [16, 18]]) 0]\n","output_type":"stream"}]},{"cell_type":"code","source":"#read test data\ntesting_set  = read_sdf('/kaggle/input/cisc873-dm-w23-a6/test_x.sdf')","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:33:27.838723Z","iopub.execute_input":"2023-04-24T09:33:27.839819Z","iopub.status.idle":"2023-04-24T09:33:29.193322Z","shell.execute_reply.started":"2023-04-24T09:33:27.839779Z","shell.execute_reply":"2023-04-24T09:33:29.192142Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12326 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e6ae6f784ee4fac90ae47210cac7df0"}},"metadata":{}}]},{"cell_type":"code","source":"# get type of test data\ntype(testing_set)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:33:29.194939Z","iopub.execute_input":"2023-04-24T09:33:29.195411Z","iopub.status.idle":"2023-04-24T09:33:29.202850Z","shell.execute_reply.started":"2023-04-24T09:33:29.195370Z","shell.execute_reply":"2023-04-24T09:33:29.201748Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"list"},"metadata":{}}]},{"cell_type":"code","source":"# print length of test data\nprint(len(testing_set))","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:33:29.204831Z","iopub.execute_input":"2023-04-24T09:33:29.205358Z","iopub.status.idle":"2023-04-24T09:33:29.213554Z","shell.execute_reply.started":"2023-04-24T09:33:29.205210Z","shell.execute_reply":"2023-04-24T09:33:29.212452Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"12326\n","output_type":"stream"}]},{"cell_type":"code","source":"# print shape\nprint(np.shape(training_set[2]))","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:33:29.215675Z","iopub.execute_input":"2023-04-24T09:33:29.216112Z","iopub.status.idle":"2023-04-24T09:33:29.223130Z","shell.execute_reply.started":"2023-04-24T09:33:29.216055Z","shell.execute_reply":"2023-04-24T09:33:29.221976Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"(3,)\n","output_type":"stream"}]},{"cell_type":"code","source":"#print the second sample in test data\ntesting_set[1]","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:33:29.225037Z","iopub.execute_input":"2023-04-24T09:33:29.225440Z","iopub.status.idle":"2023-04-24T09:33:29.239376Z","shell.execute_reply.started":"2023-04-24T09:33:29.225405Z","shell.execute_reply":"2023-04-24T09:33:29.238058Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(['O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'N',\n  'N',\n  'C',\n  'C',\n  'C',\n  'C',\n  'C',\n  'C',\n  'C',\n  'C',\n  'C',\n  'C',\n  'C',\n  'C',\n  'C',\n  'C',\n  'C',\n  'C',\n  'C',\n  'C',\n  'C',\n  'C',\n  'C'],\n array([[ 0,  8],\n        [ 0, 11],\n        [ 1, 11],\n        [ 2, 14],\n        [ 3, 16],\n        [ 4, 25],\n        [ 5, 25],\n        [ 6,  8],\n        [ 6, 10],\n        [ 7,  9],\n        [ 7, 14],\n        [ 8,  9],\n        [ 9, 12],\n        [10, 11],\n        [10, 15],\n        [12, 13],\n        [13, 16],\n        [13, 18],\n        [14, 17],\n        [15, 19],\n        [16, 20],\n        [17, 21],\n        [17, 22],\n        [18, 23],\n        [19, 25],\n        [20, 24],\n        [21, 26],\n        [22, 27],\n        [23, 24],\n        [26, 28],\n        [27, 28]]),\n 0)"},"metadata":{}}]},{"cell_type":"code","source":"len(testing_set[2][0])","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:33:29.241253Z","iopub.execute_input":"2023-04-24T09:33:29.241664Z","iopub.status.idle":"2023-04-24T09:33:29.249250Z","shell.execute_reply.started":"2023-04-24T09:33:29.241628Z","shell.execute_reply":"2023-04-24T09:33:29.248121Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"33"},"metadata":{}}]},{"cell_type":"code","source":"len(testing_set[2][1])","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:33:29.251202Z","iopub.execute_input":"2023-04-24T09:33:29.251622Z","iopub.status.idle":"2023-04-24T09:33:29.259137Z","shell.execute_reply.started":"2023-04-24T09:33:29.251588Z","shell.execute_reply":"2023-04-24T09:33:29.257960Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"37"},"metadata":{}}]},{"cell_type":"markdown","source":"# **Visualizing/Inspecting a Sample**","metadata":{}},{"cell_type":"code","source":"colors = cm.rainbow(np.linspace(0, 1, 50))","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:33:29.260514Z","iopub.execute_input":"2023-04-24T09:33:29.261356Z","iopub.status.idle":"2023-04-24T09:33:29.269522Z","shell.execute_reply.started":"2023-04-24T09:33:29.261319Z","shell.execute_reply":"2023-04-24T09:33:29.268370Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"The function creates a new undirected graph object G using the nx.Graph constructor from the NetworkX library. It then populates the graph with nodes and edges using the nodes and edges variables from the input sample","metadata":{}},{"cell_type":"code","source":"#function to visualize the graphs\ndef visualize(sample):\n    G=nx.Graph()\n    nodes = sample[0]\n    edges = sample[1]\n    \n    labeldict={}\n    node_color=[]\n    for i,n in enumerate(nodes):\n        G.add_node(i)\n        labeldict[i]=n\n        node_color.append(colors[hash(n)%len(colors)])\n\n    # a list of nodes:\n    for e in edges:\n        G.add_edge(e[0], e[1])\n        \n    nx.draw(G, labels=labeldict, with_labels = True, node_color = node_color)\n    plt.show()\n    \n    return G","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:33:29.270925Z","iopub.execute_input":"2023-04-24T09:33:29.272051Z","iopub.status.idle":"2023-04-24T09:33:29.280547Z","shell.execute_reply.started":"2023-04-24T09:33:29.272013Z","shell.execute_reply":"2023-04-24T09:33:29.279424Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"plt.clf()\nvisualize(training_set[2])","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:33:29.282001Z","iopub.execute_input":"2023-04-24T09:33:29.282938Z","iopub.status.idle":"2023-04-24T09:33:29.521563Z","shell.execute_reply.started":"2023-04-24T09:33:29.282898Z","shell.execute_reply":"2023-04-24T09:33:29.520167Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"<networkx.classes.graph.Graph at 0x75824a0c0dd0>"},"metadata":{}}]},{"cell_type":"markdown","source":"# **Preprocessing**:","metadata":{}},{"cell_type":"markdown","source":"- The code sets two variables to control the maximum number of unique tokens and the maximum length of   sequences. It then extracts all nodes from the training set and creates a tokenizer object with a       vocabulary size of max_vocab. \n\n- The fit_on_texts method is called on the tokenizer with the training set node data as input to build   the vocabulary. The result is a dictionary of word-to-index mappings that can be used to convert text   data into sequences of integers.","metadata":{}},{"cell_type":"code","source":"max_vocab = 500\nmax_len = 100\n\n\n# build vocabulary from training set\n#convert nodes to tokens \nall_nodes = [s[0] for s in training_set]\ntokenizer = Tokenizer(num_words=max_vocab)\ntokenizer.fit_on_texts(all_nodes)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:33:29.524791Z","iopub.execute_input":"2023-04-24T09:33:29.525816Z","iopub.status.idle":"2023-04-24T09:33:29.946496Z","shell.execute_reply.started":"2023-04-24T09:33:29.525775Z","shell.execute_reply":"2023-04-24T09:33:29.945296Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"defines two functions, **prepare_single_batch and gen_batch**, that are used to prepare the input and output data into batches for training","metadata":{}},{"cell_type":"code","source":"random.seed(0)\n\ndef prepare_single_batch(samples):\n    sample_nodes = [s[0] for s in samples]\n    sample_nodes = tokenizer.texts_to_sequences(sample_nodes)\n    sample_nodes = pad_sequences(sample_nodes, padding='post')\n    max_nodes_len = np.shape(sample_nodes)[1]\n    edges = [s[1]+i*max_nodes_len for i,s in enumerate(samples)]\n    edges = [e for e in edges if len(e) > 0]\n    node_to_graph = [[i]*max_nodes_len for i in range(len(samples))]\n    \n    all_nodes = np.reshape(sample_nodes, -1)\n    all_edges = np.concatenate(edges)\n\n    node_to_graph = np.reshape(node_to_graph, -1)\n    return {\n        'data': all_nodes,\n        'edges': all_edges,\n        'node2grah': node_to_graph,\n    }, np.array([s[2] for s in samples])\n\n\n#represent the input and output data into batches for fit function\ndef gen_batch(dataset, batch_size=16, repeat=False, shuffle=True):\n    while True:\n        dataset = list(dataset)\n        if shuffle:\n            random.shuffle(dataset)\n        l = len(dataset)\n        for ndx in range(0, l, batch_size):\n            batch_samples = dataset[ndx:min(ndx + batch_size, l)]\n            yield prepare_single_batch(batch_samples)\n        if not repeat:\n            break","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:33:29.948250Z","iopub.execute_input":"2023-04-24T09:33:29.948638Z","iopub.status.idle":"2023-04-24T09:33:29.960055Z","shell.execute_reply.started":"2023-04-24T09:33:29.948593Z","shell.execute_reply":"2023-04-24T09:33:29.958897Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# showing one batch:\nfor train_batch in gen_batch(training_set, batch_size=4):\n    for k,v in train_batch[0].items():\n        print(k)\n        print(v)\n        pass\n    print('label', train_batch[1])\n    break","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:33:29.962271Z","iopub.execute_input":"2023-04-24T09:33:29.963251Z","iopub.status.idle":"2023-04-24T09:33:30.018140Z","shell.execute_reply.started":"2023-04-24T09:33:29.963208Z","shell.execute_reply":"2023-04-24T09:33:30.017083Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"data\n[5 2 2 2 2 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n 2 2 2 2 2 2 2 2 2 2 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 5 5 3 3 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\nedges\n[[  0  27]\n [  1  12]\n [  2  20]\n [  2  32]\n [  3  22]\n [  3  33]\n [  4  23]\n [  4  34]\n [  5   9]\n [  5  12]\n [  5  17]\n [  6  13]\n [  6  15]\n [  7  16]\n [  7  30]\n [  7  31]\n [  8   9]\n [  8  10]\n [  8  11]\n [  9  19]\n [ 10  14]\n [ 10  25]\n [ 11  17]\n [ 11  27]\n [ 12  13]\n [ 13  21]\n [ 14  16]\n [ 14  26]\n [ 15  18]\n [ 15  20]\n [ 16  19]\n [ 18  21]\n [ 18  24]\n [ 20  22]\n [ 22  23]\n [ 23  24]\n [ 25  28]\n [ 26  29]\n [ 28  29]\n [ 37  40]\n [ 38  39]\n [ 39  42]\n [ 39  48]\n [ 40  41]\n [ 40  47]\n [ 41  43]\n [ 42  44]\n [ 43  45]\n [ 44  46]\n [ 45  49]\n [ 46  50]\n [ 47  67]\n [ 48  68]\n [ 49  51]\n [ 50  52]\n [ 51  53]\n [ 52  54]\n [ 53  55]\n [ 54  56]\n [ 55  57]\n [ 56  58]\n [ 57  59]\n [ 58  60]\n [ 59  61]\n [ 60  62]\n [ 61  63]\n [ 62  64]\n [ 63  65]\n [ 64  66]\n [ 65  66]\n [ 74  89]\n [ 75  90]\n [ 76  92]\n [ 76 102]\n [ 77  91]\n [ 78  93]\n [ 79  94]\n [ 80  99]\n [ 81 102]\n [ 81 109]\n [ 82 103]\n [ 83 108]\n [ 84 107]\n [ 85  88]\n [ 85  89]\n [ 85  92]\n [ 86  87]\n [ 86  89]\n [ 86  93]\n [ 87  90]\n [ 87  94]\n [ 88  90]\n [ 88  95]\n [ 91  95]\n [ 91  98]\n [ 91  99]\n [ 92  98]\n [ 93  96]\n [ 94  97]\n [ 96  97]\n [ 96 100]\n [ 97 101]\n [ 99 103]\n [100 104]\n [101 105]\n [102 106]\n [104 105]\n [106 107]\n [107 108]\n [108 109]\n [109 110]\n [111 115]\n [112 116]\n [113 115]\n [113 118]\n [114 116]\n [114 118]\n [115 117]\n [116 117]]\nnode2grah\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\nlabel [1 1 1 0]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Create Graph Convolutional Network**","metadata":{}},{"cell_type":"markdown","source":"1. This code defines a function GCN_building that creates a Graph Convolutional Network (GCN) model        The function takes several parameters, including the number of hidden dimensions, the message          calculation class,the activation function for dense layers, and the number of layers.\n\n2. then defines three input layers for nodes, the edges, and the node-to-graph mappings.  The data layer is passed through an embedding layer to convert the integer indices to dense vectors.\n\n3. The hyperparameters for the GCN model are set using the params dictionary, which contains default values for various hyperparameters. The values for hidden_dim, message_calculation_class, dense_intermediate_layer_activation, and num_layers are set based on the input parameters. If the message calculation class is 'RGAT', the number of heads is also set to 32.\n\n4. The output data reduced using the segment_mean function, which computes the mean of segments defined by the node-to-graph mappings.\n\n5. the output is passed through a dense layer with a sigmoid activation function to produce the model's predictions.","metadata":{}},{"cell_type":"code","source":"def GCN_building(hidden_dimension = 32 ,message_calculation_class = 'GGNN' ,dense_layer_activation = 'tanh', numumber_of_layers = 2):\n \n    keras.backend.clear_session()\n    # the input data(nodes)\n    data = keras.Input(batch_shape=(None,))\n    #edges\n    edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n    #map the nodes to graphs\n    node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n    embeded = Embedding(tokenizer.num_words, 20)(data)\n    #number of samples\n    num_graph = tf.reduce_max(node2graph)+1\n    \n    #adding the  input data to graph \n    gnn_input = GNNInput(\n    node_features=embeded,\n    adjacency_lists=(edge,),\n    node_to_graph_map=node2graph, \n    num_graphs=num_graph,\n    )\n    \n    # the default values for graph\n    params = GNN.get_default_hyperparameters()\n    #set the hyperparameters with values\n    params[\"hidden_dim\"] ,params['message_calculation_class'], params['dense_intermediate_layer_activation'], params['num_layers'] = hidden_dimension, message_calculation_class, dense_layer_activation,numumber_of_layers\n    #if message_calculation_class was RGAT set num_heads to a value to prevent the error.\n    if params['message_calculation_class'] == 'RGAT':\n        params['num_heads'] = 32\n    else:\n        pass\n    print(f\"message passing is {params['message_calculation_class']}\\n\")\n    gnn_layer = GNN(params)\n    #get the output data\n    gnn_out = gnn_layer(gnn_input)\n\n    print('gnn_out', gnn_out)\n\n    # reduce the output data using the segment mean\n    avg = segment_mean(\n        data=gnn_out,\n        segment_ids=node2graph\n    )\n    print('mean:', avg)\n\n    # the output layer\n    prediction = Dense(1, activation='sigmoid')(avg)\n    print('pred:', prediction)\n\n    model = Model(\n        inputs={\n            'data': data,\n            'edges': edge,\n            'node2grah': node2graph,\n        },\n        outputs=prediction\n    )\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:33:30.026930Z","iopub.execute_input":"2023-04-24T09:33:30.027657Z","iopub.status.idle":"2023-04-24T09:33:30.039107Z","shell.execute_reply.started":"2023-04-24T09:33:30.027591Z","shell.execute_reply":"2023-04-24T09:33:30.037957Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# **Training And Compilation Method**","metadata":{}},{"cell_type":"markdown","source":"1. define a function training_compilation_model that compiles and trains the model using the specified optimizer, loss function, metrics, batch size, and number of epochs.\n\n2. The function first compiles the model using the compile method and the specified optimizer, loss function, and metrics.\n\n3. It then sets up early stopping using the EarlyStopping callback to prevent overfitting.\n\n4. The fit method is called on the model, passing in the training and validation datasets as generators using the gen_batch function.\n\n5. The function returns the trained model and a history object","metadata":{}},{"cell_type":"code","source":"def training_compilation_model(model, training_data, validation_data , optimizer, loss, metric, batch_size , epochs ):\n   \n    #define the properties of model\n    model.compile(\n    optimizer=optimizer,\n    loss=loss,\n    metrics = metric \n    )\n    # using the early stopping to prevent  overfitting\n    early_stopping = EarlyStopping(monitor='val_auc', patience=5, mode = 'max')\n\n    batch_size = batch_size\n    num_batchs = math.ceil(len(training_data) / batch_size)\n    num_batchs_validation = math.ceil(len(training_data) / batch_size)\n    #train the batches\n    history = model.fit(\n    gen_batch(\n        training_data, batch_size=batch_size, repeat=True\n    ),\n    steps_per_epoch=num_batchs,\n    epochs=epochs,\n    validation_data=gen_batch(\n        validation_data, batch_size=batch_size, repeat=True\n    ),\n    validation_steps=num_batchs_validation,\n    callbacks=[early_stopping]\n    )\n    \n    return model, history","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:33:30.047066Z","iopub.execute_input":"2023-04-24T09:33:30.047430Z","iopub.status.idle":"2023-04-24T09:33:30.055930Z","shell.execute_reply.started":"2023-04-24T09:33:30.047403Z","shell.execute_reply":"2023-04-24T09:33:30.054765Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# **Create Submission File**","metadata":{}},{"cell_type":"markdown","source":"defines function prediction_submission_file that generates predictions on the provided testing set using the specified model, saves the predictions to a CSV file, and returns the predictions as an array.","metadata":{}},{"cell_type":"code","source":"def prediction_submission_file(model, file_name ,batch_size):\n   \n    # make prediction on test data \n    y_pred = model.predict(\n        gen_batch(testing_set, batch_size = batch_size, shuffle=False)\n    )\n    print(y_pred.shape)\n    y_pred = np.reshape(y_pred, -1)\n    \n    print(len(y_pred))\n    # create  submmision file  \n    submission = pd.DataFrame({'label':y_pred})\n    submission.index.name = 'id'\n    submission.to_csv(file_name)\n    \n    return y_pred","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:33:30.057665Z","iopub.execute_input":"2023-04-24T09:33:30.058402Z","iopub.status.idle":"2023-04-24T09:33:30.069426Z","shell.execute_reply.started":"2023-04-24T09:33:30.058366Z","shell.execute_reply":"2023-04-24T09:33:30.067949Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# **First Trial**","metadata":{}},{"cell_type":"markdown","source":"- using message passing that called \"GGNN\"","metadata":{}},{"cell_type":"markdown","source":"1. creates a GCN model, model_1, using the GCN_building function with the following hyperparameters:\n\n    - hidden_dimension: 32\n\n    - message_calculation_class: 'GGNN'\n\n    - dense_layer_activation: 'tanh'\n\n    - numumber_of_layers: 1\n\n2. The summary method is called on the model to print a summary of its architecture","metadata":{}},{"cell_type":"code","source":"model_1 = GCN_building(hidden_dimension = 32 ,message_calculation_class = 'GGNN' ,dense_layer_activation = 'tanh', numumber_of_layers = 1)\nmodel_1.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:33:30.091810Z","iopub.execute_input":"2023-04-24T09:33:30.092576Z","iopub.status.idle":"2023-04-24T09:33:34.296871Z","shell.execute_reply.started":"2023-04-24T09:33:30.092539Z","shell.execute_reply":"2023-04-24T09:33:34.296037Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"message passing style used in this model will be GGNN\n\ngnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn/StatefulPartitionedCall:0', description=\"created by layer 'gnn'\")\nmean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean'\")\npred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense/Sigmoid:0', description=\"created by layer 'dense'\")\nModel: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_3 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n input_1 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n tf.math.reduce_max (TFOpLambda  ()                  0           ['input_3[0][0]']                \n )                                                                                                \n                                                                                                  \n embedding (Embedding)          (None, 20)           10000       ['input_1[0][0]']                \n                                                                                                  \n input_2 (InputLayer)           [(None, 2)]          0           []                               \n                                                                                                  \n tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.reduce_max[0][0]']     \n da)                                                                                              \n                                                                                                  \n gnn (GNN)                      (None, 32)           9024        ['embedding[0][0]',              \n                                                                  'input_2[0][0]',                \n                                                                  'input_3[0][0]',                \n                                                                  'tf.__operators__.add[0][0]']   \n                                                                                                  \n tf.math.segment_mean (TFOpLamb  (None, 32)          0           ['gnn[0][0]',                    \n da)                                                              'input_3[0][0]']                \n                                                                                                  \n dense (Dense)                  (None, 1)            33          ['tf.math.segment_mean[0][0]']   \n                                                                                                  \n==================================================================================================\nTotal params: 19,057\nTrainable params: 19,057\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**thoughts and observations**\n\n1- I called training_compilation_model function with the following parameters:\n\n- training_set: the training dataset\n\n- validation_set: the validation dataset\n\n- optimizer: 'adam'\n\n- loss: 'BinaryCrossentropy'\n\n- metric: 'AUC'\n\n- batch_size: 64\n\n- epochs: 50 \n\n2- I think the model will fit well with these hyperparameters\n\n**plan for trial 2**\n\nI will change the number of Hidden Dimension","metadata":{}},{"cell_type":"code","source":"model_1, history_1 = training_compilation_model(model_1, training_set, validation_set, 'adam', 'BinaryCrossentropy', 'AUC', 64,50)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:33:34.298016Z","iopub.execute_input":"2023-04-24T09:33:34.298382Z","iopub.status.idle":"2023-04-24T09:39:02.672564Z","shell.execute_reply.started":"2023-04-24T09:33:34.298344Z","shell.execute_reply":"2023-04-24T09:39:02.671450Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Epoch 1/50\n538/538 [==============================] - 13s 16ms/step - loss: 0.6447 - auc: 0.6718 - val_loss: 0.6250 - val_auc: 0.7068\nEpoch 2/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.6331 - auc: 0.6920 - val_loss: 0.6200 - val_auc: 0.7149\nEpoch 3/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.6255 - auc: 0.7059 - val_loss: 0.6113 - val_auc: 0.7412\nEpoch 4/50\n538/538 [==============================] - 9s 17ms/step - loss: 0.6165 - auc: 0.7200 - val_loss: 0.5952 - val_auc: 0.7524\nEpoch 5/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.6015 - auc: 0.7404 - val_loss: 0.5781 - val_auc: 0.7768\nEpoch 6/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5876 - auc: 0.7564 - val_loss: 0.5696 - val_auc: 0.7769\nEpoch 7/50\n538/538 [==============================] - 9s 17ms/step - loss: 0.5831 - auc: 0.7616 - val_loss: 0.5635 - val_auc: 0.7873\nEpoch 8/50\n538/538 [==============================] - 9s 17ms/step - loss: 0.5792 - auc: 0.7670 - val_loss: 0.5602 - val_auc: 0.7900\nEpoch 9/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5796 - auc: 0.7651 - val_loss: 0.5639 - val_auc: 0.7934\nEpoch 10/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5762 - auc: 0.7700 - val_loss: 0.5570 - val_auc: 0.7919\nEpoch 11/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5784 - auc: 0.7659 - val_loss: 0.5579 - val_auc: 0.7948\nEpoch 12/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.5743 - auc: 0.7710 - val_loss: 0.5568 - val_auc: 0.7954\nEpoch 13/50\n538/538 [==============================] - 7s 13ms/step - loss: 0.5729 - auc: 0.7729 - val_loss: 0.5533 - val_auc: 0.7962\nEpoch 14/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5713 - auc: 0.7761 - val_loss: 0.5585 - val_auc: 0.7949\nEpoch 15/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5708 - auc: 0.7762 - val_loss: 0.5530 - val_auc: 0.7960\nEpoch 16/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5701 - auc: 0.7770 - val_loss: 0.5533 - val_auc: 0.7926\nEpoch 17/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.5710 - auc: 0.7774 - val_loss: 0.5491 - val_auc: 0.7984\nEpoch 18/50\n538/538 [==============================] - 7s 13ms/step - loss: 0.5697 - auc: 0.7789 - val_loss: 0.5633 - val_auc: 0.7993\nEpoch 19/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5673 - auc: 0.7805 - val_loss: 0.5502 - val_auc: 0.8003\nEpoch 20/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.5711 - auc: 0.7782 - val_loss: 0.5527 - val_auc: 0.7982\nEpoch 21/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.5672 - auc: 0.7814 - val_loss: 0.5587 - val_auc: 0.8014\nEpoch 22/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.5666 - auc: 0.7812 - val_loss: 0.5576 - val_auc: 0.7987\nEpoch 23/50\n538/538 [==============================] - 7s 13ms/step - loss: 0.5682 - auc: 0.7808 - val_loss: 0.5578 - val_auc: 0.7982\nEpoch 24/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5655 - auc: 0.7817 - val_loss: 0.5478 - val_auc: 0.8005\nEpoch 25/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5647 - auc: 0.7841 - val_loss: 0.5481 - val_auc: 0.8028\nEpoch 26/50\n538/538 [==============================] - 9s 17ms/step - loss: 0.5672 - auc: 0.7818 - val_loss: 0.5464 - val_auc: 0.8012\nEpoch 27/50\n538/538 [==============================] - 7s 13ms/step - loss: 0.5674 - auc: 0.7809 - val_loss: 0.5461 - val_auc: 0.8040\nEpoch 28/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5645 - auc: 0.7848 - val_loss: 0.5522 - val_auc: 0.8051\nEpoch 29/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5655 - auc: 0.7833 - val_loss: 0.5612 - val_auc: 0.8032\nEpoch 30/50\n538/538 [==============================] - 7s 13ms/step - loss: 0.5672 - auc: 0.7823 - val_loss: 0.5488 - val_auc: 0.8039\nEpoch 31/50\n538/538 [==============================] - 7s 13ms/step - loss: 0.5639 - auc: 0.7853 - val_loss: 0.5506 - val_auc: 0.8003\nEpoch 32/50\n538/538 [==============================] - 7s 13ms/step - loss: 0.5634 - auc: 0.7846 - val_loss: 0.5430 - val_auc: 0.8048\nEpoch 33/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.5643 - auc: 0.7843 - val_loss: 0.5449 - val_auc: 0.8064\nEpoch 34/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5641 - auc: 0.7858 - val_loss: 0.5501 - val_auc: 0.8038\nEpoch 35/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.5624 - auc: 0.7852 - val_loss: 0.5441 - val_auc: 0.8055\nEpoch 36/50\n538/538 [==============================] - 7s 13ms/step - loss: 0.5621 - auc: 0.7867 - val_loss: 0.5414 - val_auc: 0.8074\nEpoch 37/50\n538/538 [==============================] - 7s 13ms/step - loss: 0.5620 - auc: 0.7866 - val_loss: 0.5435 - val_auc: 0.8042\nEpoch 38/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.5629 - auc: 0.7857 - val_loss: 0.5433 - val_auc: 0.8031\nEpoch 39/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5623 - auc: 0.7859 - val_loss: 0.5453 - val_auc: 0.8057\nEpoch 40/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.5604 - auc: 0.7879 - val_loss: 0.5417 - val_auc: 0.8079\nEpoch 41/50\n538/538 [==============================] - 9s 17ms/step - loss: 0.5630 - auc: 0.7867 - val_loss: 0.5433 - val_auc: 0.8083\nEpoch 42/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5596 - auc: 0.7885 - val_loss: 0.5424 - val_auc: 0.8092\nEpoch 43/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5614 - auc: 0.7876 - val_loss: 0.5411 - val_auc: 0.8071\nEpoch 44/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.5600 - auc: 0.7889 - val_loss: 0.5401 - val_auc: 0.8082\nEpoch 45/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.5629 - auc: 0.7855 - val_loss: 0.5468 - val_auc: 0.8057\nEpoch 46/50\n538/538 [==============================] - 7s 13ms/step - loss: 0.5605 - auc: 0.7886 - val_loss: 0.5405 - val_auc: 0.8083\nEpoch 47/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5584 - auc: 0.7901 - val_loss: 0.5477 - val_auc: 0.8069\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- This code generates predictions on the testing set using the model_1 model and the prediction_submission_file function with a batch size of 64.","metadata":{}},{"cell_type":"code","source":"y_pred_1 = prediction_submission_file(model_1,'trial_1.csv',batch_size = 64)\nprint(y_pred_1)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:39:02.674399Z","iopub.execute_input":"2023-04-24T09:39:02.675142Z","iopub.status.idle":"2023-04-24T09:39:04.405307Z","shell.execute_reply.started":"2023-04-24T09:39:02.675082Z","shell.execute_reply":"2023-04-24T09:39:04.404286Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"193/193 [==============================] - 2s 7ms/step\n(12326, 1)\n12326\n[0.484357   0.29643542 0.38986215 ... 0.30543444 0.20766793 0.55958045]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Second Trial**","metadata":{}},{"cell_type":"markdown","source":"**- change the number of hidden Dimension**","metadata":{}},{"cell_type":"markdown","source":"1. creates a GCN model, model_1, using the GCN_building function with the following hyperparameters:\n\n    - hidden_dimension: 64\n\n    - message_calculation_class: 'GGNN'\n\n    - dense_layer_activation: 'tanh'\n\n    - numumber_of_layers: 1\n\n2. The summary method is called on the model to print a summary of its architecture","metadata":{}},{"cell_type":"code","source":"model_2 = GCN_building(hidden_dimension = 64 ,message_calculation_class = 'GGNN' ,dense_layer_activation = 'tanh', numumber_of_layers = 1)\n\nmodel_2.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:39:04.407847Z","iopub.execute_input":"2023-04-24T09:39:04.408943Z","iopub.status.idle":"2023-04-24T09:39:04.673540Z","shell.execute_reply.started":"2023-04-24T09:39:04.408902Z","shell.execute_reply":"2023-04-24T09:39:04.672681Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"message passing style used in this model will be GGNN\n\ngnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn/StatefulPartitionedCall:0', description=\"created by layer 'gnn'\")\nmean: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='tf.math.segment_mean/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean'\")\npred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense/Sigmoid:0', description=\"created by layer 'dense'\")\nModel: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_3 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n input_1 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n tf.math.reduce_max (TFOpLambda  ()                  0           ['input_3[0][0]']                \n )                                                                                                \n                                                                                                  \n embedding (Embedding)          (None, 20)           10000       ['input_1[0][0]']                \n                                                                                                  \n input_2 (InputLayer)           [(None, 2)]          0           []                               \n                                                                                                  \n tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.reduce_max[0][0]']     \n da)                                                                                              \n                                                                                                  \n gnn (GNN)                      (None, 64)           34432       ['embedding[0][0]',              \n                                                                  'input_2[0][0]',                \n                                                                  'input_3[0][0]',                \n                                                                  'tf.__operators__.add[0][0]']   \n                                                                                                  \n tf.math.segment_mean (TFOpLamb  (None, 64)          0           ['gnn[0][0]',                    \n da)                                                              'input_3[0][0]']                \n                                                                                                  \n dense (Dense)                  (None, 1)            65          ['tf.math.segment_mean[0][0]']   \n                                                                                                  \n==================================================================================================\nTotal params: 44,497\nTrainable params: 44,497\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**thoughts and observations**\n\n1- I called training_compilation_model function with the following parameters:\n\n- training_set: the training dataset\n\n- validation_set: the validation dataset\n\n- optimizer: 'adam'\n\n- loss: 'BinaryCrossentropy'\n\n- metric: 'AUC'\n\n- batch_size: 64\n\n- epochs: 50 \n\n2- I think the model will fit well than the previous trial because increasing of hidden dimension increase the model's capacity to \n\nlearn complex representations of the input graph data\n\n**plan for trial 3**\n\nI will change the number of epochs and batch size ","metadata":{}},{"cell_type":"code","source":"model_2, history_2 = training_compilation_model(model_2, training_set, validation_set, 'adam', 'BinaryCrossentropy', 'AUC', 64,50)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:39:04.674586Z","iopub.execute_input":"2023-04-24T09:39:04.674932Z","iopub.status.idle":"2023-04-24T09:44:07.726247Z","shell.execute_reply.started":"2023-04-24T09:39:04.674889Z","shell.execute_reply":"2023-04-24T09:44:07.725216Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Epoch 1/50\n538/538 [==============================] - 9s 14ms/step - loss: 0.6447 - auc: 0.6720 - val_loss: 0.6340 - val_auc: 0.7092\nEpoch 2/50\n538/538 [==============================] - 7s 13ms/step - loss: 0.6306 - auc: 0.6956 - val_loss: 0.6147 - val_auc: 0.7226\nEpoch 3/50\n538/538 [==============================] - 7s 13ms/step - loss: 0.6218 - auc: 0.7105 - val_loss: 0.6042 - val_auc: 0.7403\nEpoch 4/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.6117 - auc: 0.7258 - val_loss: 0.5862 - val_auc: 0.7644\nEpoch 5/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.5942 - auc: 0.7470 - val_loss: 0.5715 - val_auc: 0.7901\nEpoch 6/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5861 - auc: 0.7582 - val_loss: 0.5634 - val_auc: 0.7875\nEpoch 7/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5806 - auc: 0.7642 - val_loss: 0.5639 - val_auc: 0.7856\nEpoch 8/50\n538/538 [==============================] - 7s 13ms/step - loss: 0.5784 - auc: 0.7685 - val_loss: 0.5544 - val_auc: 0.7912\nEpoch 9/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5756 - auc: 0.7717 - val_loss: 0.5636 - val_auc: 0.7949\nEpoch 10/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5768 - auc: 0.7683 - val_loss: 0.5674 - val_auc: 0.7978\nEpoch 11/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5725 - auc: 0.7741 - val_loss: 0.5570 - val_auc: 0.7961\nEpoch 12/50\n538/538 [==============================] - 7s 13ms/step - loss: 0.5733 - auc: 0.7741 - val_loss: 0.5643 - val_auc: 0.7932\nEpoch 13/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5721 - auc: 0.7755 - val_loss: 0.5520 - val_auc: 0.7988\nEpoch 14/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5720 - auc: 0.7755 - val_loss: 0.5594 - val_auc: 0.7996\nEpoch 15/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5696 - auc: 0.7780 - val_loss: 0.5490 - val_auc: 0.7974\nEpoch 16/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5669 - auc: 0.7804 - val_loss: 0.5539 - val_auc: 0.8018\nEpoch 17/50\n538/538 [==============================] - 9s 17ms/step - loss: 0.5664 - auc: 0.7832 - val_loss: 0.5501 - val_auc: 0.8012\nEpoch 18/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.5656 - auc: 0.7818 - val_loss: 0.5471 - val_auc: 0.8051\nEpoch 19/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.5677 - auc: 0.7812 - val_loss: 0.5489 - val_auc: 0.7970\nEpoch 20/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.5652 - auc: 0.7835 - val_loss: 0.5556 - val_auc: 0.8043\nEpoch 21/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5658 - auc: 0.7836 - val_loss: 0.5430 - val_auc: 0.8047\nEpoch 22/50\n538/538 [==============================] - 7s 13ms/step - loss: 0.5645 - auc: 0.7838 - val_loss: 0.5476 - val_auc: 0.8057\nEpoch 23/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5648 - auc: 0.7842 - val_loss: 0.5591 - val_auc: 0.8060\nEpoch 24/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5632 - auc: 0.7835 - val_loss: 0.5419 - val_auc: 0.8067\nEpoch 25/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5630 - auc: 0.7853 - val_loss: 0.5461 - val_auc: 0.8045\nEpoch 26/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5630 - auc: 0.7858 - val_loss: 0.5502 - val_auc: 0.8072\nEpoch 27/50\n538/538 [==============================] - 7s 13ms/step - loss: 0.5629 - auc: 0.7864 - val_loss: 0.5451 - val_auc: 0.8020\nEpoch 28/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.5615 - auc: 0.7878 - val_loss: 0.5465 - val_auc: 0.8073\nEpoch 29/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5619 - auc: 0.7854 - val_loss: 0.5587 - val_auc: 0.8070\nEpoch 30/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.5602 - auc: 0.7882 - val_loss: 0.5415 - val_auc: 0.8050\nEpoch 31/50\n538/538 [==============================] - 7s 13ms/step - loss: 0.5646 - auc: 0.7840 - val_loss: 0.5410 - val_auc: 0.8088\nEpoch 32/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5620 - auc: 0.7869 - val_loss: 0.5410 - val_auc: 0.8071\nEpoch 33/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5616 - auc: 0.7871 - val_loss: 0.5422 - val_auc: 0.8098\nEpoch 34/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5607 - auc: 0.7876 - val_loss: 0.5429 - val_auc: 0.8066\nEpoch 35/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5596 - auc: 0.7887 - val_loss: 0.5401 - val_auc: 0.8094\nEpoch 36/50\n538/538 [==============================] - 7s 13ms/step - loss: 0.5596 - auc: 0.7887 - val_loss: 0.5437 - val_auc: 0.8103\nEpoch 37/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.5592 - auc: 0.7908 - val_loss: 0.5386 - val_auc: 0.8085\nEpoch 38/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5584 - auc: 0.7908 - val_loss: 0.5364 - val_auc: 0.8109\nEpoch 39/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5582 - auc: 0.7904 - val_loss: 0.5571 - val_auc: 0.8111\nEpoch 40/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5630 - auc: 0.7870 - val_loss: 0.5339 - val_auc: 0.8138\nEpoch 41/50\n538/538 [==============================] - 9s 17ms/step - loss: 0.5581 - auc: 0.7915 - val_loss: 0.5388 - val_auc: 0.8114\nEpoch 42/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5573 - auc: 0.7920 - val_loss: 0.5383 - val_auc: 0.8115\nEpoch 43/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5589 - auc: 0.7906 - val_loss: 0.5372 - val_auc: 0.8111\nEpoch 44/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5561 - auc: 0.7938 - val_loss: 0.5350 - val_auc: 0.8120\nEpoch 45/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.5564 - auc: 0.7944 - val_loss: 0.5382 - val_auc: 0.8135\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- This code generates predictions on the testing set using the model_2 model and the prediction_submission_file function with a batch size of 64.","metadata":{}},{"cell_type":"code","source":"y_pred_2 = prediction_submission_file(model_2,'trial_2.csv',batch_size = 64)\nprint(y_pred_2)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:44:07.728013Z","iopub.execute_input":"2023-04-24T09:44:07.728393Z","iopub.status.idle":"2023-04-24T09:44:28.962732Z","shell.execute_reply.started":"2023-04-24T09:44:07.728357Z","shell.execute_reply":"2023-04-24T09:44:28.961521Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"193/193 [==============================] - 1s 5ms/step\n(12326, 1)\n12326\n[0.47315818 0.26724625 0.38823596 ... 0.29880378 0.21977095 0.5498294 ]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Third Trial**","metadata":{}},{"cell_type":"markdown","source":"**- change the number of epoch and batch size** ","metadata":{}},{"cell_type":"markdown","source":"1. creates a GCN model, model_1, using the GCN_building function with the following hyperparameters:\n\n    - hidden_dimension: 32\n\n    - message_calculation_class: 'GGNN'\n\n    - dense_layer_activation: 'tanh'\n\n    - numumber_of_layers: 1\n\n2. The summary method is called on the model to print a summary of its architecture","metadata":{}},{"cell_type":"code","source":"model_3 = GCN_building(hidden_dimension = 32 ,message_calculation_class = 'GGNN' ,dense_layer_activation = 'tanh', numumber_of_layers = 1)\nmodel_3.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:44:28.964920Z","iopub.execute_input":"2023-04-24T09:44:28.966046Z","iopub.status.idle":"2023-04-24T09:44:29.217820Z","shell.execute_reply.started":"2023-04-24T09:44:28.966003Z","shell.execute_reply":"2023-04-24T09:44:29.217009Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"message passing style used in this model will be GGNN\n\ngnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn/StatefulPartitionedCall:0', description=\"created by layer 'gnn'\")\nmean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean'\")\npred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense/Sigmoid:0', description=\"created by layer 'dense'\")\nModel: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_3 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n input_1 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n tf.math.reduce_max (TFOpLambda  ()                  0           ['input_3[0][0]']                \n )                                                                                                \n                                                                                                  \n embedding (Embedding)          (None, 20)           10000       ['input_1[0][0]']                \n                                                                                                  \n input_2 (InputLayer)           [(None, 2)]          0           []                               \n                                                                                                  \n tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.reduce_max[0][0]']     \n da)                                                                                              \n                                                                                                  \n gnn (GNN)                      (None, 32)           9024        ['embedding[0][0]',              \n                                                                  'input_2[0][0]',                \n                                                                  'input_3[0][0]',                \n                                                                  'tf.__operators__.add[0][0]']   \n                                                                                                  \n tf.math.segment_mean (TFOpLamb  (None, 32)          0           ['gnn[0][0]',                    \n da)                                                              'input_3[0][0]']                \n                                                                                                  \n dense (Dense)                  (None, 1)            33          ['tf.math.segment_mean[0][0]']   \n                                                                                                  \n==================================================================================================\nTotal params: 19,057\nTrainable params: 19,057\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**thoughts and observations**\n\n1- I called training_compilation_model function with the following parameters:\n\n- training_set: the training dataset\n\n- validation_set: the validation dataset\n\n- optimizer: 'adam'\n\n- loss: 'BinaryCrossentropy'\n\n- metric: 'AUC'\n\n- batch_size: 128\n\n- epochs: 100 \n\n2- I think the model will fit well than the previous trial because increase number of epochs \n   allow the model to continue learning and improving its performance on the training data, \n   and Increasing the batch size can improve training efficiency by allowing the model to process more samples at once\n\n**plan for trial 4**\n\nI will change the type of message passing  ","metadata":{}},{"cell_type":"code","source":"model_3, history_3 = training_compilation_model(model_3, training_set, validation_set, 'adam', 'BinaryCrossentropy', 'AUC', 128,100)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:44:29.218878Z","iopub.execute_input":"2023-04-24T09:44:29.219424Z","iopub.status.idle":"2023-04-24T09:47:42.370255Z","shell.execute_reply.started":"2023-04-24T09:44:29.219394Z","shell.execute_reply":"2023-04-24T09:47:42.369249Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Epoch 1/100\n269/269 [==============================] - 8s 24ms/step - loss: 0.6516 - auc: 0.6593 - val_loss: 0.6301 - val_auc: 0.7014\nEpoch 2/100\n269/269 [==============================] - 5s 19ms/step - loss: 0.6373 - auc: 0.6871 - val_loss: 0.6273 - val_auc: 0.7061\nEpoch 3/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.6352 - auc: 0.6885 - val_loss: 0.6253 - val_auc: 0.7085\nEpoch 4/100\n269/269 [==============================] - 4s 16ms/step - loss: 0.6320 - auc: 0.6935 - val_loss: 0.6188 - val_auc: 0.7153\nEpoch 5/100\n269/269 [==============================] - 4s 16ms/step - loss: 0.6286 - auc: 0.6999 - val_loss: 0.6158 - val_auc: 0.7260\nEpoch 6/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.6209 - auc: 0.7135 - val_loss: 0.6023 - val_auc: 0.7395\nEpoch 7/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.6135 - auc: 0.7250 - val_loss: 0.5921 - val_auc: 0.7574\nEpoch 8/100\n269/269 [==============================] - 5s 20ms/step - loss: 0.6024 - auc: 0.7406 - val_loss: 0.5824 - val_auc: 0.7747\nEpoch 9/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.5922 - auc: 0.7550 - val_loss: 0.5733 - val_auc: 0.7813\nEpoch 10/100\n269/269 [==============================] - 5s 19ms/step - loss: 0.5915 - auc: 0.7529 - val_loss: 0.5807 - val_auc: 0.7746\nEpoch 11/100\n269/269 [==============================] - 4s 16ms/step - loss: 0.5844 - auc: 0.7628 - val_loss: 0.5665 - val_auc: 0.7847\nEpoch 12/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.5810 - auc: 0.7658 - val_loss: 0.5631 - val_auc: 0.7889\nEpoch 13/100\n269/269 [==============================] - 4s 16ms/step - loss: 0.5769 - auc: 0.7701 - val_loss: 0.5590 - val_auc: 0.7955\nEpoch 14/100\n269/269 [==============================] - 4s 16ms/step - loss: 0.5792 - auc: 0.7676 - val_loss: 0.5578 - val_auc: 0.7918\nEpoch 15/100\n269/269 [==============================] - 5s 19ms/step - loss: 0.5749 - auc: 0.7729 - val_loss: 0.5563 - val_auc: 0.7984\nEpoch 16/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.5736 - auc: 0.7749 - val_loss: 0.5557 - val_auc: 0.7989\nEpoch 17/100\n269/269 [==============================] - 4s 16ms/step - loss: 0.5714 - auc: 0.7771 - val_loss: 0.5490 - val_auc: 0.7973\nEpoch 18/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.5738 - auc: 0.7732 - val_loss: 0.5532 - val_auc: 0.7984\nEpoch 19/100\n269/269 [==============================] - 4s 16ms/step - loss: 0.5699 - auc: 0.7781 - val_loss: 0.5742 - val_auc: 0.8008\nEpoch 20/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.5693 - auc: 0.7785 - val_loss: 0.5507 - val_auc: 0.8012\nEpoch 21/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.5668 - auc: 0.7815 - val_loss: 0.5594 - val_auc: 0.8024\nEpoch 22/100\n269/269 [==============================] - 5s 19ms/step - loss: 0.5674 - auc: 0.7816 - val_loss: 0.5479 - val_auc: 0.8055\nEpoch 23/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.5651 - auc: 0.7844 - val_loss: 0.5437 - val_auc: 0.8019\nEpoch 24/100\n269/269 [==============================] - 5s 19ms/step - loss: 0.5661 - auc: 0.7837 - val_loss: 0.5432 - val_auc: 0.8044\nEpoch 25/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.5644 - auc: 0.7851 - val_loss: 0.5415 - val_auc: 0.8048\nEpoch 26/100\n269/269 [==============================] - 5s 19ms/step - loss: 0.5622 - auc: 0.7879 - val_loss: 0.5440 - val_auc: 0.8057\nEpoch 27/100\n269/269 [==============================] - 4s 16ms/step - loss: 0.5630 - auc: 0.7865 - val_loss: 0.5439 - val_auc: 0.8063\nEpoch 28/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.5615 - auc: 0.7885 - val_loss: 0.5442 - val_auc: 0.8089\nEpoch 29/100\n269/269 [==============================] - 5s 17ms/step - loss: 0.5642 - auc: 0.7860 - val_loss: 0.5432 - val_auc: 0.8093\nEpoch 30/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.5616 - auc: 0.7878 - val_loss: 0.5400 - val_auc: 0.8079\nEpoch 31/100\n269/269 [==============================] - 4s 16ms/step - loss: 0.5623 - auc: 0.7878 - val_loss: 0.5454 - val_auc: 0.8079\nEpoch 32/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.5608 - auc: 0.7904 - val_loss: 0.5394 - val_auc: 0.8094\nEpoch 33/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.5604 - auc: 0.7898 - val_loss: 0.5410 - val_auc: 0.8083\nEpoch 34/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.5601 - auc: 0.7904 - val_loss: 0.5395 - val_auc: 0.8109\nEpoch 35/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.5599 - auc: 0.7907 - val_loss: 0.5538 - val_auc: 0.8129\nEpoch 36/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.5623 - auc: 0.7885 - val_loss: 0.5408 - val_auc: 0.8116\nEpoch 37/100\n269/269 [==============================] - 4s 16ms/step - loss: 0.5631 - auc: 0.7877 - val_loss: 0.5442 - val_auc: 0.8098\nEpoch 38/100\n269/269 [==============================] - 4s 16ms/step - loss: 0.5597 - auc: 0.7914 - val_loss: 0.5410 - val_auc: 0.8097\nEpoch 39/100\n269/269 [==============================] - 4s 16ms/step - loss: 0.5600 - auc: 0.7908 - val_loss: 0.5438 - val_auc: 0.8107\nEpoch 40/100\n269/269 [==============================] - 4s 16ms/step - loss: 0.5612 - auc: 0.7886 - val_loss: 0.5406 - val_auc: 0.8098\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- This code generates predictions on the testing set using the model_3 model and the prediction_submission_file function with a batch size of 128.","metadata":{}},{"cell_type":"code","source":"y_pred_3 = prediction_submission_file(model_3,'trial_3.csv',batch_size = 128)\nprint(y_pred_3)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:47:42.371691Z","iopub.execute_input":"2023-04-24T09:47:42.372202Z","iopub.status.idle":"2023-04-24T09:47:53.217454Z","shell.execute_reply.started":"2023-04-24T09:47:42.372158Z","shell.execute_reply":"2023-04-24T09:47:53.216338Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"97/97 [==============================] - 1s 7ms/step\n(12326, 1)\n12326\n[0.51123637 0.2813151  0.38277033 ... 0.23553766 0.2202553  0.61371624]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Fourth Trial**","metadata":{}},{"cell_type":"markdown","source":"**- change the type of message passing**","metadata":{}},{"cell_type":"markdown","source":"1. creates a GCN model, model_1, using the GCN_building function with the following hyperparameters:\n\n    - hidden_dimension: 32\n\n    - message_calculation_class: 'GNN_Edge_MLP'\n\n    - dense_layer_activation: 'tanh'\n\n    - numumber_of_layers: 1\n\n2. The summary method is called on the model to print a summary of its architecture","metadata":{}},{"cell_type":"code","source":"model_4 = GCN_building(hidden_dimension = 32 ,message_calculation_class = 'GNN_Edge_MLP' ,dense_layer_activation = 'tanh', numumber_of_layers = 1)\nmodel_4.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:47:53.218789Z","iopub.execute_input":"2023-04-24T09:47:53.221122Z","iopub.status.idle":"2023-04-24T09:47:53.550523Z","shell.execute_reply.started":"2023-04-24T09:47:53.221064Z","shell.execute_reply":"2023-04-24T09:47:53.549697Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"message passing style used in this model will be GNN_Edge_MLP\n\ngnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn/StatefulPartitionedCall:0', description=\"created by layer 'gnn'\")\nmean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean'\")\npred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense/Sigmoid:0', description=\"created by layer 'dense'\")\nModel: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_3 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n input_1 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n tf.math.reduce_max (TFOpLambda  ()                  0           ['input_3[0][0]']                \n )                                                                                                \n                                                                                                  \n embedding (Embedding)          (None, 20)           10000       ['input_1[0][0]']                \n                                                                                                  \n input_2 (InputLayer)           [(None, 2)]          0           []                               \n                                                                                                  \n tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.reduce_max[0][0]']     \n da)                                                                                              \n                                                                                                  \n gnn (GNN)                      (None, 32)           2688        ['embedding[0][0]',              \n                                                                  'input_2[0][0]',                \n                                                                  'input_3[0][0]',                \n                                                                  'tf.__operators__.add[0][0]']   \n                                                                                                  \n tf.math.segment_mean (TFOpLamb  (None, 32)          0           ['gnn[0][0]',                    \n da)                                                              'input_3[0][0]']                \n                                                                                                  \n dense (Dense)                  (None, 1)            33          ['tf.math.segment_mean[0][0]']   \n                                                                                                  \n==================================================================================================\nTotal params: 12,721\nTrainable params: 12,721\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**thoughts and observations**\n\n1- I called training_compilation_model function with the following parameters:\n\n- training_set: the training dataset\n\n- validation_set: the validation dataset\n\n- optimizer: 'adam'\n\n- loss: 'BinaryCrossentropy'\n\n- metric: 'AUC'\n\n- batch_size: 64\n\n- epochs: 50 \n\n2- I think the model will fit well , but the performance will be less than the performance when using \"GGNN\" ,\n\nbecause GGNN may be more effective as it can be more computationally efficient\n\n**plan for trial 5**\n\nI will change the type of message passing  ","metadata":{}},{"cell_type":"code","source":"model_4, history_4 = training_compilation_model(model_4, training_set, validation_set, 'adam', 'BinaryCrossentropy', 'AUC', 64,50)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:47:53.551579Z","iopub.execute_input":"2023-04-24T09:47:53.551955Z","iopub.status.idle":"2023-04-24T09:50:27.035710Z","shell.execute_reply.started":"2023-04-24T09:47:53.551914Z","shell.execute_reply":"2023-04-24T09:50:27.034722Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Epoch 1/50\n538/538 [==============================] - 9s 14ms/step - loss: 0.6550 - auc: 0.6647 - val_loss: 0.6296 - val_auc: 0.7096\nEpoch 2/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.6350 - auc: 0.7001 - val_loss: 0.6219 - val_auc: 0.7212\nEpoch 3/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.6269 - auc: 0.7114 - val_loss: 0.6136 - val_auc: 0.7406\nEpoch 4/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.6136 - auc: 0.7347 - val_loss: 0.5946 - val_auc: 0.7605\nEpoch 5/50\n538/538 [==============================] - 7s 13ms/step - loss: 0.6052 - auc: 0.7434 - val_loss: 0.5911 - val_auc: 0.7713\nEpoch 6/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.6000 - auc: 0.7508 - val_loss: 0.5817 - val_auc: 0.7764\nEpoch 7/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.5965 - auc: 0.7563 - val_loss: 0.5801 - val_auc: 0.7801\nEpoch 8/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.5927 - auc: 0.7615 - val_loss: 0.5761 - val_auc: 0.7815\nEpoch 9/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.5935 - auc: 0.7598 - val_loss: 0.5781 - val_auc: 0.7809\nEpoch 10/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.5922 - auc: 0.7607 - val_loss: 0.5724 - val_auc: 0.7843\nEpoch 11/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.5903 - auc: 0.7622 - val_loss: 0.5736 - val_auc: 0.7849\nEpoch 12/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.5902 - auc: 0.7638 - val_loss: 0.5743 - val_auc: 0.7840\nEpoch 13/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.5894 - auc: 0.7643 - val_loss: 0.5709 - val_auc: 0.7849\nEpoch 14/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.5874 - auc: 0.7655 - val_loss: 0.5720 - val_auc: 0.7831\nEpoch 15/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.5883 - auc: 0.7649 - val_loss: 0.5706 - val_auc: 0.7855\nEpoch 16/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.5890 - auc: 0.7653 - val_loss: 0.5703 - val_auc: 0.7866\nEpoch 17/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.5893 - auc: 0.7649 - val_loss: 0.5694 - val_auc: 0.7876\nEpoch 18/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.5850 - auc: 0.7683 - val_loss: 0.5688 - val_auc: 0.7871\nEpoch 19/50\n538/538 [==============================] - 9s 16ms/step - loss: 0.5869 - auc: 0.7668 - val_loss: 0.5679 - val_auc: 0.7885\nEpoch 20/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.5869 - auc: 0.7669 - val_loss: 0.5694 - val_auc: 0.7860\nEpoch 21/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5860 - auc: 0.7678 - val_loss: 0.5708 - val_auc: 0.7874\nEpoch 22/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.5860 - auc: 0.7673 - val_loss: 0.5672 - val_auc: 0.7876\nEpoch 23/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.5847 - auc: 0.7691 - val_loss: 0.5690 - val_auc: 0.7862\nEpoch 24/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.5864 - auc: 0.7674 - val_loss: 0.5684 - val_auc: 0.7866\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- This code generates predictions on the testing set using the model_4 model and the prediction_submission_file function with a batch size of 64.","metadata":{}},{"cell_type":"code","source":"y_pred_4 = prediction_submission_file(model_4,'trial_4.csv',batch_size = 64)\nprint(y_pred_4)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:50:27.037224Z","iopub.execute_input":"2023-04-24T09:50:27.038115Z","iopub.status.idle":"2023-04-24T09:50:28.188176Z","shell.execute_reply.started":"2023-04-24T09:50:27.038058Z","shell.execute_reply":"2023-04-24T09:50:28.183956Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"193/193 [==============================] - 1s 4ms/step\n(12326, 1)\n12326\n[0.39930245 0.29151604 0.34738004 ... 0.2471509  0.41466454 0.60882336]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Fifth Trial**","metadata":{}},{"cell_type":"markdown","source":"**- change the type of message passing**","metadata":{}},{"cell_type":"markdown","source":"1. creates a GCN model, model_1, using the GCN_building function with the following hyperparameters:\n\n    - hidden_dimension: 32\n\n    - message_calculation_class: 'RGCN'\n\n    - dense_layer_activation: 'tanh'\n\n    - numumber_of_layers: 1\n\n2. The summary method is called on the model to print a summary of its architecture","metadata":{}},{"cell_type":"code","source":"model_5 = GCN_building(hidden_dimension = 32 ,message_calculation_class = 'RGCN' ,dense_layer_activation = 'tanh', numumber_of_layers = 1)\nmodel_5.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:50:28.190328Z","iopub.execute_input":"2023-04-24T09:50:28.190896Z","iopub.status.idle":"2023-04-24T09:50:28.513705Z","shell.execute_reply.started":"2023-04-24T09:50:28.190853Z","shell.execute_reply":"2023-04-24T09:50:28.512969Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"message passing style used in this model will be RGCN\n\ngnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn/StatefulPartitionedCall:0', description=\"created by layer 'gnn'\")\nmean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean'\")\npred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense/Sigmoid:0', description=\"created by layer 'dense'\")\nModel: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_3 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n input_1 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n tf.math.reduce_max (TFOpLambda  ()                  0           ['input_3[0][0]']                \n )                                                                                                \n                                                                                                  \n embedding (Embedding)          (None, 20)           10000       ['input_1[0][0]']                \n                                                                                                  \n input_2 (InputLayer)           [(None, 2)]          0           []                               \n                                                                                                  \n tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.reduce_max[0][0]']     \n da)                                                                                              \n                                                                                                  \n gnn (GNN)                      (None, 32)           2688        ['embedding[0][0]',              \n                                                                  'input_2[0][0]',                \n                                                                  'input_3[0][0]',                \n                                                                  'tf.__operators__.add[0][0]']   \n                                                                                                  \n tf.math.segment_mean (TFOpLamb  (None, 32)          0           ['gnn[0][0]',                    \n da)                                                              'input_3[0][0]']                \n                                                                                                  \n dense (Dense)                  (None, 1)            33          ['tf.math.segment_mean[0][0]']   \n                                                                                                  \n==================================================================================================\nTotal params: 12,721\nTrainable params: 12,721\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**thoughts and observations**\n\n1- I called training_compilation_model function with the following parameters:\n\n- training_set: the training dataset\n\n- validation_set: the validation dataset\n\n- optimizer: 'adam'\n\n- loss: 'BinaryCrossentropy'\n\n- metric: 'AUC'\n\n- batch_size: 64\n\n- epochs: 50 \n\n2- I think the model will fit well with the message passing \"RGCN\" , the performance will be close to the performance of \"GNN_Edge_MLP\"\n\n**plan for trial 6**\n\nI will change the number of hidden dimension","metadata":{}},{"cell_type":"code","source":"model_5, history_5 = training_compilation_model(model_5, training_set, validation_set, 'adam', 'BinaryCrossentropy', 'AUC', 64,50)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:50:28.515082Z","iopub.execute_input":"2023-04-24T09:50:28.515439Z","iopub.status.idle":"2023-04-24T09:52:24.986062Z","shell.execute_reply.started":"2023-04-24T09:50:28.515404Z","shell.execute_reply":"2023-04-24T09:52:24.984996Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Epoch 1/50\n538/538 [==============================] - 9s 14ms/step - loss: 0.6551 - auc: 0.6629 - val_loss: 0.6324 - val_auc: 0.7083\nEpoch 2/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.6353 - auc: 0.6998 - val_loss: 0.6217 - val_auc: 0.7201\nEpoch 3/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.6233 - auc: 0.7193 - val_loss: 0.6024 - val_auc: 0.7539\nEpoch 4/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.6103 - auc: 0.7387 - val_loss: 0.5960 - val_auc: 0.7584\nEpoch 5/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.6034 - auc: 0.7467 - val_loss: 0.5856 - val_auc: 0.7733\nEpoch 6/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.5985 - auc: 0.7527 - val_loss: 0.5812 - val_auc: 0.7771\nEpoch 7/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5948 - auc: 0.7576 - val_loss: 0.5788 - val_auc: 0.7800\nEpoch 8/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5932 - auc: 0.7586 - val_loss: 0.5806 - val_auc: 0.7786\nEpoch 9/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.5923 - auc: 0.7594 - val_loss: 0.5771 - val_auc: 0.7814\nEpoch 10/50\n538/538 [==============================] - 7s 13ms/step - loss: 0.5903 - auc: 0.7636 - val_loss: 0.5821 - val_auc: 0.7819\nEpoch 11/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.5924 - auc: 0.7604 - val_loss: 0.5736 - val_auc: 0.7838\nEpoch 12/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5915 - auc: 0.7617 - val_loss: 0.5737 - val_auc: 0.7840\nEpoch 13/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.5899 - auc: 0.7637 - val_loss: 0.5723 - val_auc: 0.7858\nEpoch 14/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5898 - auc: 0.7640 - val_loss: 0.5715 - val_auc: 0.7836\nEpoch 15/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.5894 - auc: 0.7643 - val_loss: 0.5720 - val_auc: 0.7839\nEpoch 16/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.5886 - auc: 0.7655 - val_loss: 0.5731 - val_auc: 0.7846\nEpoch 17/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5895 - auc: 0.7634 - val_loss: 0.5732 - val_auc: 0.7824\nEpoch 18/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5889 - auc: 0.7637 - val_loss: 0.5728 - val_auc: 0.7845\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- This code generates predictions on the testing set using the model_5 model and the prediction_submission_file function with a batch size of 64.","metadata":{}},{"cell_type":"code","source":"y_pred_5= prediction_submission_file(model_5,'trial_5.csv',batch_size = 64)\nprint(y_pred_5)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:52:24.988002Z","iopub.execute_input":"2023-04-24T09:52:24.988502Z","iopub.status.idle":"2023-04-24T09:52:53.095823Z","shell.execute_reply.started":"2023-04-24T09:52:24.988463Z","shell.execute_reply":"2023-04-24T09:52:53.094661Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"193/193 [==============================] - 1s 5ms/step\n(12326, 1)\n12326\n[0.3926232  0.28889304 0.35084015 ... 0.2633181  0.46213    0.5890443 ]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Sixth Trial**","metadata":{}},{"cell_type":"markdown","source":"**- change the number of hidden Dimension**","metadata":{}},{"cell_type":"markdown","source":"1. creates a GCN model, model_1, using the GCN_building function with the following hyperparameters:\n\n    - hidden_dimension: 64\n\n    - message_calculation_class: 'RGCN'\n\n    - dense_layer_activation: 'tanh'\n\n    - numumber_of_layers: 1\n\n2. The summary method is called on the model to print a summary of its architecture","metadata":{}},{"cell_type":"code","source":"model_6 = GCN_building(hidden_dimension = 64 ,message_calculation_class = 'RGCN' ,dense_layer_activation = 'tanh', numumber_of_layers = 1)\nmodel_6.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:52:53.097391Z","iopub.execute_input":"2023-04-24T09:52:53.097736Z","iopub.status.idle":"2023-04-24T09:52:53.299083Z","shell.execute_reply.started":"2023-04-24T09:52:53.097698Z","shell.execute_reply":"2023-04-24T09:52:53.298206Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"message passing style used in this model will be RGCN\n\ngnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn/StatefulPartitionedCall:0', description=\"created by layer 'gnn'\")\nmean: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='tf.math.segment_mean/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean'\")\npred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense/Sigmoid:0', description=\"created by layer 'dense'\")\nModel: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_3 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n input_1 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n tf.math.reduce_max (TFOpLambda  ()                  0           ['input_3[0][0]']                \n )                                                                                                \n                                                                                                  \n embedding (Embedding)          (None, 20)           10000       ['input_1[0][0]']                \n                                                                                                  \n input_2 (InputLayer)           [(None, 2)]          0           []                               \n                                                                                                  \n tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.reduce_max[0][0]']     \n da)                                                                                              \n                                                                                                  \n gnn (GNN)                      (None, 64)           9472        ['embedding[0][0]',              \n                                                                  'input_2[0][0]',                \n                                                                  'input_3[0][0]',                \n                                                                  'tf.__operators__.add[0][0]']   \n                                                                                                  \n tf.math.segment_mean (TFOpLamb  (None, 64)          0           ['gnn[0][0]',                    \n da)                                                              'input_3[0][0]']                \n                                                                                                  \n dense (Dense)                  (None, 1)            65          ['tf.math.segment_mean[0][0]']   \n                                                                                                  \n==================================================================================================\nTotal params: 19,537\nTrainable params: 19,537\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**thoughts and observations**\n\n1- I called training_compilation_model function with the following parameters:\n\n- training_set: the training dataset\n\n- validation_set: the validation dataset\n\n- optimizer: 'adam'\n\n- loss: 'BinaryCrossentropy'\n\n- metric: 'AUC'\n\n- batch_size: 64\n\n- epochs: 50 \n\n2- I think the model will fit well than the previous trial because of Increasing\n\nthe hidden dimension of a GCN model can potentially increase the model's capacity to \n\nlearn complex representations of the input graph data\n\n**plan for trial 7**\n\nI will change the number of epoch and batch size ","metadata":{}},{"cell_type":"code","source":"model_6, history_6 = training_compilation_model(model_6, training_set, validation_set, 'adam', 'BinaryCrossentropy', 'AUC', 64,50)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:52:53.300127Z","iopub.execute_input":"2023-04-24T09:52:53.300457Z","iopub.status.idle":"2023-04-24T09:54:26.859384Z","shell.execute_reply.started":"2023-04-24T09:52:53.300421Z","shell.execute_reply":"2023-04-24T09:54:26.858421Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Epoch 1/50\n538/538 [==============================] - 8s 13ms/step - loss: 0.6512 - auc: 0.6712 - val_loss: 0.6336 - val_auc: 0.7158\nEpoch 2/50\n538/538 [==============================] - 9s 16ms/step - loss: 0.6273 - auc: 0.7127 - val_loss: 0.6049 - val_auc: 0.7503\nEpoch 3/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.6113 - auc: 0.7349 - val_loss: 0.5910 - val_auc: 0.7696\nEpoch 4/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.6002 - auc: 0.7520 - val_loss: 0.5921 - val_auc: 0.7732\nEpoch 5/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.5954 - auc: 0.7574 - val_loss: 0.5770 - val_auc: 0.7822\nEpoch 6/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.5906 - auc: 0.7631 - val_loss: 0.5755 - val_auc: 0.7842\nEpoch 7/50\n538/538 [==============================] - 9s 16ms/step - loss: 0.5904 - auc: 0.7623 - val_loss: 0.5759 - val_auc: 0.7840\nEpoch 8/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.5895 - auc: 0.7641 - val_loss: 0.5715 - val_auc: 0.7829\nEpoch 9/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.5872 - auc: 0.7662 - val_loss: 0.5696 - val_auc: 0.7869\nEpoch 10/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.5866 - auc: 0.7664 - val_loss: 0.5774 - val_auc: 0.7850\nEpoch 11/50\n538/538 [==============================] - 6s 12ms/step - loss: 0.5887 - auc: 0.7639 - val_loss: 0.5707 - val_auc: 0.7841\nEpoch 12/50\n538/538 [==============================] - 7s 12ms/step - loss: 0.5857 - auc: 0.7669 - val_loss: 0.5682 - val_auc: 0.7852\nEpoch 13/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.5859 - auc: 0.7669 - val_loss: 0.5720 - val_auc: 0.7847\nEpoch 14/50\n538/538 [==============================] - 6s 11ms/step - loss: 0.5871 - auc: 0.7648 - val_loss: 0.5680 - val_auc: 0.7859\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- This code generates predictions on the testing set using the model_6 model and the prediction_submission_file function with a batch size of 64.","metadata":{}},{"cell_type":"code","source":"y_pred_6= prediction_submission_file(model_6,'trial_6.csv',batch_size = 64)\nprint(y_pred_6)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:54:26.862553Z","iopub.execute_input":"2023-04-24T09:54:26.863189Z","iopub.status.idle":"2023-04-24T09:55:17.319855Z","shell.execute_reply.started":"2023-04-24T09:54:26.863139Z","shell.execute_reply":"2023-04-24T09:55:17.318647Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"193/193 [==============================] - 1s 4ms/step\n(12326, 1)\n12326\n[0.40310675 0.3311269  0.34067598 ... 0.25016126 0.48486653 0.6360829 ]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Seventh trial**","metadata":{}},{"cell_type":"markdown","source":"**- change the  number of epochs and batch size**","metadata":{}},{"cell_type":"markdown","source":"1. creates a GCN model, model_1, using the GCN_building function with the following hyperparameters:\n\n    - hidden_dimension: 64\n\n    - message_calculation_class: 'RGCN'\n\n    - dense_layer_activation: 'tanh'\n\n    - numumber_of_layers: 1\n\n2. The summary method is called on the model to print a summary of its architecture","metadata":{}},{"cell_type":"code","source":"model_7 = GCN_building(hidden_dimension = 64 ,message_calculation_class = 'RGCN' ,dense_layer_activation = 'tanh', numumber_of_layers = 1)\nmodel_7.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:55:17.323244Z","iopub.execute_input":"2023-04-24T09:55:17.323570Z","iopub.status.idle":"2023-04-24T09:55:17.525684Z","shell.execute_reply.started":"2023-04-24T09:55:17.323539Z","shell.execute_reply":"2023-04-24T09:55:17.524887Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"message passing style used in this model will be RGCN\n\ngnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn/StatefulPartitionedCall:0', description=\"created by layer 'gnn'\")\nmean: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='tf.math.segment_mean/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean'\")\npred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense/Sigmoid:0', description=\"created by layer 'dense'\")\nModel: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_3 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n input_1 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n tf.math.reduce_max (TFOpLambda  ()                  0           ['input_3[0][0]']                \n )                                                                                                \n                                                                                                  \n embedding (Embedding)          (None, 20)           10000       ['input_1[0][0]']                \n                                                                                                  \n input_2 (InputLayer)           [(None, 2)]          0           []                               \n                                                                                                  \n tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.reduce_max[0][0]']     \n da)                                                                                              \n                                                                                                  \n gnn (GNN)                      (None, 64)           9472        ['embedding[0][0]',              \n                                                                  'input_2[0][0]',                \n                                                                  'input_3[0][0]',                \n                                                                  'tf.__operators__.add[0][0]']   \n                                                                                                  \n tf.math.segment_mean (TFOpLamb  (None, 64)          0           ['gnn[0][0]',                    \n da)                                                              'input_3[0][0]']                \n                                                                                                  \n dense (Dense)                  (None, 1)            65          ['tf.math.segment_mean[0][0]']   \n                                                                                                  \n==================================================================================================\nTotal params: 19,537\nTrainable params: 19,537\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**thoughts and observations**\n\n1- I called training_compilation_model function with the following parameters:\n\n- training_set: the training dataset\n\n- validation_set: the validation dataset\n\n- optimizer: 'adam'\n\n- loss: 'BinaryCrossentropy'\n\n- metric: 'AUC'\n\n- batch_size: 128\n\n- epochs: 100 \n\n2- I think the model will fit well than the previous trial because of increasing the number of epochs \n\n   allow the model to continue learning and improving its performance on the training data,\n   \n   and Increasing the batch size can improve training efficiency by allowing the model to process more samples at once\n\n**plan for trial 8**\n\nI will change the type of message passing ","metadata":{}},{"cell_type":"code","source":"model_7, history_7 = training_compilation_model(model_7, training_set, validation_set, 'adam', 'BinaryCrossentropy', 'AUC', 128,100)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:55:17.526832Z","iopub.execute_input":"2023-04-24T09:55:17.527196Z","iopub.status.idle":"2023-04-24T09:57:32.425656Z","shell.execute_reply.started":"2023-04-24T09:55:17.527158Z","shell.execute_reply":"2023-04-24T09:57:32.424623Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"Epoch 1/100\n269/269 [==============================] - 7s 23ms/step - loss: 0.6594 - auc: 0.6569 - val_loss: 0.6322 - val_auc: 0.7035\nEpoch 2/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.6368 - auc: 0.6967 - val_loss: 0.6247 - val_auc: 0.7177\nEpoch 3/100\n269/269 [==============================] - 5s 19ms/step - loss: 0.6306 - auc: 0.7058 - val_loss: 0.6182 - val_auc: 0.7206\nEpoch 4/100\n269/269 [==============================] - 4s 15ms/step - loss: 0.6204 - auc: 0.7220 - val_loss: 0.5994 - val_auc: 0.7592\nEpoch 5/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.6071 - auc: 0.7416 - val_loss: 0.5931 - val_auc: 0.7642\nEpoch 6/100\n269/269 [==============================] - 5s 17ms/step - loss: 0.6012 - auc: 0.7492 - val_loss: 0.5858 - val_auc: 0.7708\nEpoch 7/100\n269/269 [==============================] - 5s 17ms/step - loss: 0.5949 - auc: 0.7575 - val_loss: 0.5774 - val_auc: 0.7794\nEpoch 8/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.5929 - auc: 0.7601 - val_loss: 0.5771 - val_auc: 0.7814\nEpoch 9/100\n269/269 [==============================] - 4s 16ms/step - loss: 0.5915 - auc: 0.7616 - val_loss: 0.5745 - val_auc: 0.7841\nEpoch 10/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.5903 - auc: 0.7625 - val_loss: 0.5700 - val_auc: 0.7867\nEpoch 11/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.5894 - auc: 0.7649 - val_loss: 0.5732 - val_auc: 0.7841\nEpoch 12/100\n269/269 [==============================] - 4s 16ms/step - loss: 0.5884 - auc: 0.7649 - val_loss: 0.5711 - val_auc: 0.7858\nEpoch 13/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.5878 - auc: 0.7652 - val_loss: 0.5693 - val_auc: 0.7873\nEpoch 14/100\n269/269 [==============================] - 4s 15ms/step - loss: 0.5858 - auc: 0.7678 - val_loss: 0.5707 - val_auc: 0.7868\nEpoch 15/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.5870 - auc: 0.7647 - val_loss: 0.5671 - val_auc: 0.7874\nEpoch 16/100\n269/269 [==============================] - 4s 15ms/step - loss: 0.5878 - auc: 0.7644 - val_loss: 0.5700 - val_auc: 0.7881\nEpoch 17/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.5848 - auc: 0.7687 - val_loss: 0.5676 - val_auc: 0.7900\nEpoch 18/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.5854 - auc: 0.7677 - val_loss: 0.5682 - val_auc: 0.7878\nEpoch 19/100\n269/269 [==============================] - 4s 15ms/step - loss: 0.5845 - auc: 0.7686 - val_loss: 0.5659 - val_auc: 0.7895\nEpoch 20/100\n269/269 [==============================] - 5s 20ms/step - loss: 0.5859 - auc: 0.7679 - val_loss: 0.5674 - val_auc: 0.7887\nEpoch 21/100\n269/269 [==============================] - 4s 16ms/step - loss: 0.5828 - auc: 0.7709 - val_loss: 0.5662 - val_auc: 0.7905\nEpoch 22/100\n269/269 [==============================] - 4s 15ms/step - loss: 0.5851 - auc: 0.7691 - val_loss: 0.5652 - val_auc: 0.7915\nEpoch 23/100\n269/269 [==============================] - 4s 16ms/step - loss: 0.5854 - auc: 0.7677 - val_loss: 0.5655 - val_auc: 0.7896\nEpoch 24/100\n269/269 [==============================] - 4s 15ms/step - loss: 0.5837 - auc: 0.7697 - val_loss: 0.5639 - val_auc: 0.7922\nEpoch 25/100\n269/269 [==============================] - 4s 16ms/step - loss: 0.5842 - auc: 0.7697 - val_loss: 0.5658 - val_auc: 0.7892\nEpoch 26/100\n269/269 [==============================] - 5s 18ms/step - loss: 0.5836 - auc: 0.7699 - val_loss: 0.5638 - val_auc: 0.7918\nEpoch 27/100\n269/269 [==============================] - 5s 20ms/step - loss: 0.5847 - auc: 0.7689 - val_loss: 0.5651 - val_auc: 0.7904\nEpoch 28/100\n269/269 [==============================] - 4s 15ms/step - loss: 0.5837 - auc: 0.7700 - val_loss: 0.5653 - val_auc: 0.7900\nEpoch 29/100\n269/269 [==============================] - 4s 16ms/step - loss: 0.5829 - auc: 0.7702 - val_loss: 0.5662 - val_auc: 0.7905\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- This code generates predictions on the testing set using the model_7 model and the prediction_submission_file function with a batch size of 128.","metadata":{}},{"cell_type":"code","source":"y_pred_7= prediction_submission_file(model_7,'trial_7.csv',batch_size = 128)\nprint(y_pred_7)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:57:32.429005Z","iopub.execute_input":"2023-04-24T09:57:32.429334Z","iopub.status.idle":"2023-04-24T09:57:41.342902Z","shell.execute_reply.started":"2023-04-24T09:57:32.429303Z","shell.execute_reply":"2023-04-24T09:57:41.341797Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"97/97 [==============================] - 1s 7ms/step\n(12326, 1)\n12326\n[0.3950549  0.2938459  0.3664212  ... 0.24075331 0.44470182 0.6410008 ]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Eighth trial**","metadata":{}},{"cell_type":"markdown","source":"**- change the type of message passing**","metadata":{}},{"cell_type":"markdown","source":"1. creates a GCN model, model_1, using the GCN_building function with the following hyperparameters:\n\n    - hidden_dimension: 32\n\n    - message_calculation_class: 'RGAT'\n\n    - dense_layer_activation: 'tanh'\n\n    - numumber_of_layers: 1\n\n2. The summary method is called on the model to print a summary of its architecture","metadata":{}},{"cell_type":"code","source":"model_8 = GCN_building(hidden_dimension = 32 ,message_calculation_class = 'RGAT' ,dense_layer_activation = 'tanh', numumber_of_layers = 1)\nmodel_8.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:57:41.344431Z","iopub.execute_input":"2023-04-24T09:57:41.344772Z","iopub.status.idle":"2023-04-24T09:57:42.168863Z","shell.execute_reply.started":"2023-04-24T09:57:41.344744Z","shell.execute_reply":"2023-04-24T09:57:42.168032Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"message passing style used in this model will be RGAT\n\ngnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn/StatefulPartitionedCall:0', description=\"created by layer 'gnn'\")\nmean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean'\")\npred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense/Sigmoid:0', description=\"created by layer 'dense'\")\nModel: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_3 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n input_1 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n tf.math.reduce_max (TFOpLambda  ()                  0           ['input_3[0][0]']                \n )                                                                                                \n                                                                                                  \n embedding (Embedding)          (None, 20)           10000       ['input_1[0][0]']                \n                                                                                                  \n input_2 (InputLayer)           [(None, 2)]          0           []                               \n                                                                                                  \n tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.reduce_max[0][0]']     \n da)                                                                                              \n                                                                                                  \n gnn (GNN)                      (None, 32)           2752        ['embedding[0][0]',              \n                                                                  'input_2[0][0]',                \n                                                                  'input_3[0][0]',                \n                                                                  'tf.__operators__.add[0][0]']   \n                                                                                                  \n tf.math.segment_mean (TFOpLamb  (None, 32)          0           ['gnn[0][0]',                    \n da)                                                              'input_3[0][0]']                \n                                                                                                  \n dense (Dense)                  (None, 1)            33          ['tf.math.segment_mean[0][0]']   \n                                                                                                  \n==================================================================================================\nTotal params: 12,785\nTrainable params: 12,785\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**thoughts and observations**\n\n1- I called training_compilation_model function with the following parameters:\n\n- training_set: the training dataset\n\n- validation_set: the validation dataset\n\n- optimizer: 'adam'\n\n- loss: 'BinaryCrossentropy'\n\n- metric: 'AUC'\n\n- batch_size: 64\n\n- epochs: 50 \n\n2- I think the model will fit well but less than the previous trial \n\n**plan for trial 9**\n\nI will using the message passing \"GGNN\" with increase the number of layers","metadata":{}},{"cell_type":"code","source":"model_8, history_8 = training_compilation_model(model_8, training_set, validation_set, 'adam', 'BinaryCrossentropy', 'AUC', 64,50)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:57:42.169927Z","iopub.execute_input":"2023-04-24T09:57:42.170284Z","iopub.status.idle":"2023-04-24T10:06:14.172752Z","shell.execute_reply.started":"2023-04-24T09:57:42.170247Z","shell.execute_reply":"2023-04-24T10:06:14.171728Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Epoch 1/50\n538/538 [==============================] - 25s 38ms/step - loss: 0.6563 - auc: 0.6646 - val_loss: 0.6297 - val_auc: 0.7130\nEpoch 2/50\n538/538 [==============================] - 18s 33ms/step - loss: 0.6333 - auc: 0.7024 - val_loss: 0.6192 - val_auc: 0.7245\nEpoch 3/50\n538/538 [==============================] - 18s 33ms/step - loss: 0.6227 - auc: 0.7191 - val_loss: 0.6142 - val_auc: 0.7365\nEpoch 4/50\n538/538 [==============================] - 17s 31ms/step - loss: 0.6159 - auc: 0.7298 - val_loss: 0.6014 - val_auc: 0.7530\nEpoch 5/50\n538/538 [==============================] - 16s 31ms/step - loss: 0.6108 - auc: 0.7353 - val_loss: 0.5960 - val_auc: 0.7579\nEpoch 6/50\n538/538 [==============================] - 18s 34ms/step - loss: 0.6058 - auc: 0.7418 - val_loss: 0.5959 - val_auc: 0.7634\nEpoch 7/50\n538/538 [==============================] - 18s 33ms/step - loss: 0.6031 - auc: 0.7449 - val_loss: 0.5843 - val_auc: 0.7691\nEpoch 8/50\n538/538 [==============================] - 17s 31ms/step - loss: 0.5992 - auc: 0.7507 - val_loss: 0.5835 - val_auc: 0.7746\nEpoch 9/50\n538/538 [==============================] - 16s 30ms/step - loss: 0.5956 - auc: 0.7551 - val_loss: 0.5792 - val_auc: 0.7775\nEpoch 10/50\n538/538 [==============================] - 17s 32ms/step - loss: 0.5926 - auc: 0.7582 - val_loss: 0.5790 - val_auc: 0.7807\nEpoch 11/50\n538/538 [==============================] - 18s 33ms/step - loss: 0.5914 - auc: 0.7602 - val_loss: 0.5803 - val_auc: 0.7793\nEpoch 12/50\n538/538 [==============================] - 18s 34ms/step - loss: 0.5925 - auc: 0.7592 - val_loss: 0.5775 - val_auc: 0.7797\nEpoch 13/50\n538/538 [==============================] - 17s 31ms/step - loss: 0.5908 - auc: 0.7604 - val_loss: 0.5751 - val_auc: 0.7814\nEpoch 14/50\n538/538 [==============================] - 18s 33ms/step - loss: 0.5886 - auc: 0.7635 - val_loss: 0.5736 - val_auc: 0.7816\nEpoch 15/50\n538/538 [==============================] - 18s 33ms/step - loss: 0.5879 - auc: 0.7647 - val_loss: 0.5736 - val_auc: 0.7829\nEpoch 16/50\n538/538 [==============================] - 18s 33ms/step - loss: 0.5902 - auc: 0.7621 - val_loss: 0.5715 - val_auc: 0.7831\nEpoch 17/50\n538/538 [==============================] - 17s 31ms/step - loss: 0.5887 - auc: 0.7631 - val_loss: 0.5727 - val_auc: 0.7821\nEpoch 18/50\n538/538 [==============================] - 18s 33ms/step - loss: 0.5877 - auc: 0.7651 - val_loss: 0.5710 - val_auc: 0.7820\nEpoch 19/50\n538/538 [==============================] - 19s 35ms/step - loss: 0.5872 - auc: 0.7647 - val_loss: 0.5721 - val_auc: 0.7818\nEpoch 20/50\n538/538 [==============================] - 16s 30ms/step - loss: 0.5868 - auc: 0.7654 - val_loss: 0.5703 - val_auc: 0.7846\nEpoch 21/50\n538/538 [==============================] - 18s 34ms/step - loss: 0.5869 - auc: 0.7651 - val_loss: 0.5716 - val_auc: 0.7848\nEpoch 22/50\n538/538 [==============================] - 17s 32ms/step - loss: 0.5857 - auc: 0.7672 - val_loss: 0.5689 - val_auc: 0.7847\nEpoch 23/50\n538/538 [==============================] - 18s 33ms/step - loss: 0.5859 - auc: 0.7663 - val_loss: 0.5676 - val_auc: 0.7861\nEpoch 24/50\n538/538 [==============================] - 18s 34ms/step - loss: 0.5853 - auc: 0.7669 - val_loss: 0.5670 - val_auc: 0.7866\nEpoch 25/50\n538/538 [==============================] - 18s 33ms/step - loss: 0.5871 - auc: 0.7661 - val_loss: 0.5707 - val_auc: 0.7828\nEpoch 26/50\n538/538 [==============================] - 17s 31ms/step - loss: 0.5852 - auc: 0.7670 - val_loss: 0.5695 - val_auc: 0.7844\nEpoch 27/50\n538/538 [==============================] - 16s 30ms/step - loss: 0.5858 - auc: 0.7669 - val_loss: 0.5700 - val_auc: 0.7838\nEpoch 28/50\n538/538 [==============================] - 17s 31ms/step - loss: 0.5849 - auc: 0.7675 - val_loss: 0.5692 - val_auc: 0.7838\nEpoch 29/50\n538/538 [==============================] - 16s 30ms/step - loss: 0.5843 - auc: 0.7675 - val_loss: 0.5706 - val_auc: 0.7844\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- This code generates predictions on the testing set using the model_8 model and the prediction_submission_file function with a batch size of 64.","metadata":{}},{"cell_type":"code","source":"y_pred_8= prediction_submission_file(model_8,'trial_8.csv',batch_size = 64)\nprint(y_pred_8)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T10:06:14.174411Z","iopub.execute_input":"2023-04-24T10:06:14.174764Z","iopub.status.idle":"2023-04-24T10:06:15.921150Z","shell.execute_reply.started":"2023-04-24T10:06:14.174718Z","shell.execute_reply":"2023-04-24T10:06:15.919846Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"193/193 [==============================] - 2s 6ms/step\n(12326, 1)\n12326\n[0.40463918 0.30725724 0.3468111  ... 0.2634087  0.48066384 0.60323375]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **ninth trial**","metadata":{}},{"cell_type":"markdown","source":"**- back to GGNN and change the number of layers and Activation function**","metadata":{}},{"cell_type":"markdown","source":"1. creates a GCN model, model_1, using the GCN_building function with the following hyperparameters:\n\n    - hidden_dimension: 32\n\n    - message_calculation_class: 'GGNN'\n\n    - dense_layer_activation: 'relu'\n\n    - numumber_of_layers: 8\n\n2. The summary method is called on the model to print a summary of its architecture","metadata":{}},{"cell_type":"code","source":"model_9= GCN_building(hidden_dimension = 32 ,message_calculation_class = 'GGNN' ,dense_layer_activation = 'relu', numumber_of_layers = 8)\nmodel_9.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-24T10:06:15.922966Z","iopub.execute_input":"2023-04-24T10:06:15.923771Z","iopub.status.idle":"2023-04-24T10:06:18.014420Z","shell.execute_reply.started":"2023-04-24T10:06:15.923713Z","shell.execute_reply":"2023-04-24T10:06:18.013581Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"message passing style used in this model will be GGNN\n\ngnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn/StatefulPartitionedCall:0', description=\"created by layer 'gnn'\")\nmean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean'\")\npred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense/Sigmoid:0', description=\"created by layer 'dense'\")\nModel: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_3 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n input_1 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n tf.math.reduce_max (TFOpLambda  ()                  0           ['input_3[0][0]']                \n )                                                                                                \n                                                                                                  \n embedding (Embedding)          (None, 20)           10000       ['input_1[0][0]']                \n                                                                                                  \n input_2 (InputLayer)           [(None, 2)]          0           []                               \n                                                                                                  \n tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.reduce_max[0][0]']     \n da)                                                                                              \n                                                                                                  \n gnn (GNN)                      (None, 32)           110656      ['embedding[0][0]',              \n                                                                  'input_2[0][0]',                \n                                                                  'input_3[0][0]',                \n                                                                  'tf.__operators__.add[0][0]']   \n                                                                                                  \n tf.math.segment_mean (TFOpLamb  (None, 32)          0           ['gnn[0][0]',                    \n da)                                                              'input_3[0][0]']                \n                                                                                                  \n dense (Dense)                  (None, 1)            33          ['tf.math.segment_mean[0][0]']   \n                                                                                                  \n==================================================================================================\nTotal params: 120,689\nTrainable params: 120,689\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**thoughts and observations**\n\n1- I called training_compilation_model function with the following parameters:\n\n- training_set: the training dataset\n\n- validation_set: the validation dataset\n\n- optimizer: 'adam'\n\n- loss: 'BinaryCrossentropy'\n\n- metric: 'AUC'\n\n- batch_size: 64\n\n- epochs: 50 \n\n2- I think the model will fit well because when increase the number of layers allow model to learn more efficient  \n\n**plan for trial 10**\n\nI will change the number of layer and hidden dimension ","metadata":{}},{"cell_type":"code","source":"model_9, history_9 = training_compilation_model(model_9, training_set, validation_set, 'adam', 'BinaryCrossentropy', 'AUC', 64,50)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T10:06:18.015822Z","iopub.execute_input":"2023-04-24T10:06:18.016187Z","iopub.status.idle":"2023-04-24T10:22:48.047048Z","shell.execute_reply.started":"2023-04-24T10:06:18.016147Z","shell.execute_reply":"2023-04-24T10:22:48.045943Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Epoch 1/50\n538/538 [==============================] - 33s 38ms/step - loss: 0.6443 - auc: 0.6723 - val_loss: 0.6279 - val_auc: 0.7374\nEpoch 2/50\n538/538 [==============================] - 18s 34ms/step - loss: 0.6117 - auc: 0.7253 - val_loss: 0.5976 - val_auc: 0.7506\nEpoch 3/50\n538/538 [==============================] - 19s 35ms/step - loss: 0.6019 - auc: 0.7358 - val_loss: 0.5746 - val_auc: 0.7616\nEpoch 4/50\n538/538 [==============================] - 18s 33ms/step - loss: 0.5755 - auc: 0.7632 - val_loss: 0.5600 - val_auc: 0.7846\nEpoch 5/50\n538/538 [==============================] - 19s 35ms/step - loss: 0.5610 - auc: 0.7823 - val_loss: 0.5245 - val_auc: 0.8197\nEpoch 6/50\n538/538 [==============================] - 18s 33ms/step - loss: 0.5450 - auc: 0.7986 - val_loss: 0.5087 - val_auc: 0.8312\nEpoch 7/50\n538/538 [==============================] - 18s 34ms/step - loss: 0.5101 - auc: 0.8285 - val_loss: 0.4838 - val_auc: 0.8495\nEpoch 8/50\n538/538 [==============================] - 19s 35ms/step - loss: 0.4965 - auc: 0.8393 - val_loss: 0.4649 - val_auc: 0.8607\nEpoch 9/50\n538/538 [==============================] - 19s 35ms/step - loss: 0.4766 - auc: 0.8532 - val_loss: 0.4646 - val_auc: 0.8669\nEpoch 10/50\n538/538 [==============================] - 18s 34ms/step - loss: 0.4626 - auc: 0.8628 - val_loss: 0.4484 - val_auc: 0.8750\nEpoch 11/50\n538/538 [==============================] - 19s 35ms/step - loss: 0.4506 - auc: 0.8705 - val_loss: 0.4267 - val_auc: 0.8861\nEpoch 12/50\n538/538 [==============================] - 19s 35ms/step - loss: 0.4331 - auc: 0.8815 - val_loss: 0.4132 - val_auc: 0.8940\nEpoch 13/50\n538/538 [==============================] - 18s 33ms/step - loss: 0.4219 - auc: 0.8882 - val_loss: 0.4088 - val_auc: 0.8967\nEpoch 14/50\n538/538 [==============================] - 19s 35ms/step - loss: 0.4152 - auc: 0.8919 - val_loss: 0.3856 - val_auc: 0.9076\nEpoch 15/50\n538/538 [==============================] - 18s 34ms/step - loss: 0.3959 - auc: 0.9023 - val_loss: 0.3843 - val_auc: 0.9092\nEpoch 16/50\n538/538 [==============================] - 18s 33ms/step - loss: 0.3802 - auc: 0.9102 - val_loss: 0.3585 - val_auc: 0.9227\nEpoch 17/50\n538/538 [==============================] - 19s 35ms/step - loss: 0.3639 - auc: 0.9180 - val_loss: 0.3365 - val_auc: 0.9292\nEpoch 18/50\n538/538 [==============================] - 18s 33ms/step - loss: 0.3519 - auc: 0.9234 - val_loss: 0.3342 - val_auc: 0.9315\nEpoch 19/50\n538/538 [==============================] - 18s 34ms/step - loss: 0.3372 - auc: 0.9295 - val_loss: 0.2976 - val_auc: 0.9449\nEpoch 20/50\n538/538 [==============================] - 18s 33ms/step - loss: 0.3185 - auc: 0.9368 - val_loss: 0.3006 - val_auc: 0.9477\nEpoch 21/50\n538/538 [==============================] - 19s 35ms/step - loss: 0.3074 - auc: 0.9408 - val_loss: 0.2952 - val_auc: 0.9466\nEpoch 22/50\n538/538 [==============================] - 18s 34ms/step - loss: 0.3020 - auc: 0.9428 - val_loss: 0.3003 - val_auc: 0.9465\nEpoch 23/50\n538/538 [==============================] - 18s 33ms/step - loss: 0.2942 - auc: 0.9455 - val_loss: 0.2673 - val_auc: 0.9545\nEpoch 24/50\n538/538 [==============================] - 19s 36ms/step - loss: 0.2740 - auc: 0.9522 - val_loss: 0.2758 - val_auc: 0.9563\nEpoch 25/50\n538/538 [==============================] - 18s 34ms/step - loss: 0.2681 - auc: 0.9544 - val_loss: 0.2524 - val_auc: 0.9603\nEpoch 26/50\n538/538 [==============================] - 19s 35ms/step - loss: 0.2446 - auc: 0.9607 - val_loss: 0.2485 - val_auc: 0.9610\nEpoch 27/50\n538/538 [==============================] - 19s 35ms/step - loss: 0.2431 - auc: 0.9613 - val_loss: 0.2566 - val_auc: 0.9589\nEpoch 28/50\n538/538 [==============================] - 18s 33ms/step - loss: 0.2383 - auc: 0.9624 - val_loss: 0.2390 - val_auc: 0.9659\nEpoch 29/50\n538/538 [==============================] - 20s 37ms/step - loss: 0.2251 - auc: 0.9658 - val_loss: 0.2305 - val_auc: 0.9654\nEpoch 30/50\n538/538 [==============================] - 19s 35ms/step - loss: 0.2160 - auc: 0.9682 - val_loss: 0.2044 - val_auc: 0.9709\nEpoch 31/50\n538/538 [==============================] - 18s 33ms/step - loss: 0.2142 - auc: 0.9688 - val_loss: 0.2636 - val_auc: 0.9656\nEpoch 32/50\n538/538 [==============================] - 19s 35ms/step - loss: 0.2075 - auc: 0.9711 - val_loss: 0.2236 - val_auc: 0.9713\nEpoch 33/50\n538/538 [==============================] - 19s 35ms/step - loss: 0.1964 - auc: 0.9733 - val_loss: 0.2259 - val_auc: 0.9721\nEpoch 34/50\n538/538 [==============================] - 18s 34ms/step - loss: 0.1888 - auc: 0.9749 - val_loss: 0.2248 - val_auc: 0.9664\nEpoch 35/50\n538/538 [==============================] - 19s 35ms/step - loss: 0.1879 - auc: 0.9749 - val_loss: 0.1971 - val_auc: 0.9750\nEpoch 36/50\n538/538 [==============================] - 18s 34ms/step - loss: 0.1832 - auc: 0.9759 - val_loss: 0.2078 - val_auc: 0.9747\nEpoch 37/50\n538/538 [==============================] - 19s 35ms/step - loss: 0.1772 - auc: 0.9772 - val_loss: 0.1926 - val_auc: 0.9766\nEpoch 38/50\n538/538 [==============================] - 18s 33ms/step - loss: 0.1726 - auc: 0.9784 - val_loss: 0.1743 - val_auc: 0.9755\nEpoch 39/50\n538/538 [==============================] - 18s 34ms/step - loss: 0.1695 - auc: 0.9794 - val_loss: 0.1659 - val_auc: 0.9774\nEpoch 40/50\n538/538 [==============================] - 18s 33ms/step - loss: 0.1676 - auc: 0.9793 - val_loss: 0.1841 - val_auc: 0.9785\nEpoch 41/50\n538/538 [==============================] - 18s 34ms/step - loss: 0.1588 - auc: 0.9813 - val_loss: 0.1511 - val_auc: 0.9796\nEpoch 42/50\n538/538 [==============================] - 18s 33ms/step - loss: 0.1570 - auc: 0.9815 - val_loss: 0.1589 - val_auc: 0.9809\nEpoch 43/50\n538/538 [==============================] - 18s 33ms/step - loss: 0.1576 - auc: 0.9817 - val_loss: 0.1535 - val_auc: 0.9810\nEpoch 44/50\n538/538 [==============================] - 17s 32ms/step - loss: 0.1526 - auc: 0.9825 - val_loss: 0.1708 - val_auc: 0.9791\nEpoch 45/50\n538/538 [==============================] - 19s 36ms/step - loss: 0.1495 - auc: 0.9835 - val_loss: 0.1779 - val_auc: 0.9772\nEpoch 46/50\n538/538 [==============================] - 19s 35ms/step - loss: 0.1425 - auc: 0.9844 - val_loss: 0.1740 - val_auc: 0.9791\nEpoch 47/50\n538/538 [==============================] - 18s 33ms/step - loss: 0.1434 - auc: 0.9842 - val_loss: 0.1896 - val_auc: 0.9803\nEpoch 48/50\n538/538 [==============================] - 19s 36ms/step - loss: 0.1402 - auc: 0.9848 - val_loss: 0.1629 - val_auc: 0.9823\nEpoch 49/50\n538/538 [==============================] - 19s 36ms/step - loss: 0.1404 - auc: 0.9846 - val_loss: 0.1504 - val_auc: 0.9812\nEpoch 50/50\n538/538 [==============================] - 18s 34ms/step - loss: 0.1440 - auc: 0.9837 - val_loss: 0.2014 - val_auc: 0.9778\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- This code generates predictions on the testing set using the model_9 model and the prediction_submission_file function with a batch size of 64.","metadata":{}},{"cell_type":"code","source":"y_pred_9 = prediction_submission_file(model_9,'trial_9.csv',batch_size = 64)\nprint(y_pred_9)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T10:22:48.048712Z","iopub.execute_input":"2023-04-24T10:22:48.049192Z","iopub.status.idle":"2023-04-24T10:22:50.217863Z","shell.execute_reply.started":"2023-04-24T10:22:48.049150Z","shell.execute_reply":"2023-04-24T10:22:50.216656Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"193/193 [==============================] - 2s 7ms/step\n(12326, 1)\n12326\n[5.5424798e-02 2.3460889e-04 2.3369752e-03 ... 9.6866894e-01 1.2133117e-03\n 9.4505459e-01]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **tenth trial**","metadata":{}},{"cell_type":"markdown","source":"**- change the number of layers and hidden dimesion**","metadata":{}},{"cell_type":"markdown","source":"1. creates a GCN model, model_1, using the GCN_building function with the following hyperparameters:\n\n    - hidden_dimension: 128\n\n    - message_calculation_class: 'GGNN'\n\n    - dense_layer_activation: 'relu'\n\n    - numumber_of_layers: 20\n\n2. The summary method is called on the model to print a summary of its architecture","metadata":{}},{"cell_type":"code","source":"model_10= GCN_building(hidden_dimension = 128 ,message_calculation_class = 'GGNN' ,dense_layer_activation = 'relu', numumber_of_layers = 20)\n\nmodel_10.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-24T10:22:50.219506Z","iopub.execute_input":"2023-04-24T10:22:50.219868Z","iopub.status.idle":"2023-04-24T10:22:53.567691Z","shell.execute_reply.started":"2023-04-24T10:22:50.219829Z","shell.execute_reply":"2023-04-24T10:22:53.566715Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"message passing style used in this model will be GGNN\n\ngnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='gnn/StatefulPartitionedCall:0', description=\"created by layer 'gnn'\")\nmean: KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='tf.math.segment_mean/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean'\")\npred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense/Sigmoid:0', description=\"created by layer 'dense'\")\nModel: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_3 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n input_1 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n tf.math.reduce_max (TFOpLambda  ()                  0           ['input_3[0][0]']                \n )                                                                                                \n                                                                                                  \n embedding (Embedding)          (None, 20)           10000       ['input_1[0][0]']                \n                                                                                                  \n input_2 (InputLayer)           [(None, 2)]          0           []                               \n                                                                                                  \n tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.reduce_max[0][0]']     \n da)                                                                                              \n                                                                                                  \n gnn (GNN)                      (None, 128)          3814144     ['embedding[0][0]',              \n                                                                  'input_2[0][0]',                \n                                                                  'input_3[0][0]',                \n                                                                  'tf.__operators__.add[0][0]']   \n                                                                                                  \n tf.math.segment_mean (TFOpLamb  (None, 128)         0           ['gnn[0][0]',                    \n da)                                                              'input_3[0][0]']                \n                                                                                                  \n dense (Dense)                  (None, 1)            129         ['tf.math.segment_mean[0][0]']   \n                                                                                                  \n==================================================================================================\nTotal params: 3,824,273\nTrainable params: 3,824,273\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**thoughts and observations**\n\n1- I called training_compilation_model function with the following parameters:\n\n- training_set: the training dataset\n\n- validation_set: the validation dataset\n\n- optimizer: 'adam'\n\n- loss: 'BinaryCrossentropy'\n\n- metric: 'AUC'\n\n- batch_size: 64\n\n- epochs: 50 \n\n2- I think the model will fit well because when increase the number of layers and hidden dimension allow model to learn more efficient and increase the      model's capacity to learn complex representations of the input graph data ","metadata":{}},{"cell_type":"code","source":"model_10, history_10 = training_compilation_model(model_10, training_set, validation_set, 'adam', 'BinaryCrossentropy', 'AUC', 64,50)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T10:22:53.568941Z","iopub.execute_input":"2023-04-24T10:22:53.569580Z","iopub.status.idle":"2023-04-24T10:53:19.427259Z","shell.execute_reply.started":"2023-04-24T10:22:53.569547Z","shell.execute_reply":"2023-04-24T10:53:19.426240Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"Epoch 1/50\n538/538 [==============================] - 98s 117ms/step - loss: 0.6636 - auc: 0.6320 - val_loss: 0.6503 - val_auc: 0.6664\nEpoch 2/50\n538/538 [==============================] - 65s 121ms/step - loss: 0.6550 - auc: 0.6529 - val_loss: 0.6439 - val_auc: 0.6782\nEpoch 3/50\n538/538 [==============================] - 65s 121ms/step - loss: 0.6545 - auc: 0.6541 - val_loss: 0.6504 - val_auc: 0.6770\nEpoch 4/50\n538/538 [==============================] - 60s 111ms/step - loss: 0.6525 - auc: 0.6598 - val_loss: 0.6514 - val_auc: 0.6789\nEpoch 5/50\n538/538 [==============================] - 59s 111ms/step - loss: 0.6502 - auc: 0.6635 - val_loss: 0.6414 - val_auc: 0.6827\nEpoch 6/50\n538/538 [==============================] - 64s 120ms/step - loss: 0.6502 - auc: 0.6630 - val_loss: 0.6394 - val_auc: 0.6846\nEpoch 7/50\n538/538 [==============================] - 60s 112ms/step - loss: 0.6492 - auc: 0.6649 - val_loss: 0.6407 - val_auc: 0.6836\nEpoch 8/50\n538/538 [==============================] - 60s 111ms/step - loss: 0.6510 - auc: 0.6621 - val_loss: 0.6496 - val_auc: 0.6635\nEpoch 9/50\n538/538 [==============================] - 64s 120ms/step - loss: 0.6461 - auc: 0.6701 - val_loss: 0.6133 - val_auc: 0.7258\nEpoch 10/50\n538/538 [==============================] - 59s 110ms/step - loss: 0.6202 - auc: 0.7154 - val_loss: 0.6044 - val_auc: 0.7398\nEpoch 11/50\n538/538 [==============================] - 60s 112ms/step - loss: 0.6084 - auc: 0.7305 - val_loss: 0.5867 - val_auc: 0.7543\nEpoch 12/50\n538/538 [==============================] - 66s 123ms/step - loss: 0.5971 - auc: 0.7421 - val_loss: 0.5747 - val_auc: 0.7666\nEpoch 13/50\n538/538 [==============================] - 66s 122ms/step - loss: 0.5802 - auc: 0.7597 - val_loss: 0.5592 - val_auc: 0.7800\nEpoch 14/50\n538/538 [==============================] - 67s 124ms/step - loss: 0.5653 - auc: 0.7756 - val_loss: 0.5542 - val_auc: 0.7882\nEpoch 15/50\n538/538 [==============================] - 67s 124ms/step - loss: 0.5682 - auc: 0.7722 - val_loss: 0.5497 - val_auc: 0.7953\nEpoch 16/50\n538/538 [==============================] - 67s 125ms/step - loss: 0.5462 - auc: 0.7959 - val_loss: 0.5292 - val_auc: 0.8124\nEpoch 17/50\n538/538 [==============================] - 62s 116ms/step - loss: 0.5244 - auc: 0.8144 - val_loss: 0.5072 - val_auc: 0.8288\nEpoch 18/50\n538/538 [==============================] - 62s 116ms/step - loss: 0.5156 - auc: 0.8218 - val_loss: 0.4912 - val_auc: 0.8406\nEpoch 19/50\n538/538 [==============================] - 67s 125ms/step - loss: 0.4937 - auc: 0.8401 - val_loss: 0.4797 - val_auc: 0.8484\nEpoch 20/50\n538/538 [==============================] - 63s 116ms/step - loss: 0.4875 - auc: 0.8451 - val_loss: 0.4802 - val_auc: 0.8503\nEpoch 21/50\n538/538 [==============================] - 67s 125ms/step - loss: 0.4764 - auc: 0.8535 - val_loss: 0.4688 - val_auc: 0.8584\nEpoch 22/50\n538/538 [==============================] - 63s 116ms/step - loss: 0.4922 - auc: 0.8416 - val_loss: 0.4770 - val_auc: 0.8561\nEpoch 23/50\n538/538 [==============================] - 67s 124ms/step - loss: 0.4695 - auc: 0.8589 - val_loss: 0.4702 - val_auc: 0.8611\nEpoch 24/50\n538/538 [==============================] - 67s 125ms/step - loss: 0.5399 - auc: 0.8035 - val_loss: 0.5324 - val_auc: 0.8124\nEpoch 25/50\n538/538 [==============================] - 67s 125ms/step - loss: 0.5424 - auc: 0.8014 - val_loss: 0.5722 - val_auc: 0.7718\nEpoch 26/50\n538/538 [==============================] - 62s 116ms/step - loss: 0.5448 - auc: 0.7974 - val_loss: 0.5052 - val_auc: 0.8335\nEpoch 27/50\n538/538 [==============================] - 67s 125ms/step - loss: 0.5033 - auc: 0.8327 - val_loss: 0.4728 - val_auc: 0.8564\nEpoch 28/50\n538/538 [==============================] - 62s 116ms/step - loss: 0.4983 - auc: 0.8371 - val_loss: 0.4819 - val_auc: 0.8526\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- This code generates predictions on the testing set using the model_10 model and the prediction_submission_file function with a batch size of 64.","metadata":{}},{"cell_type":"code","source":"y_pred_10= prediction_submission_file(model_10,'trial_10.csv',batch_size = 64)\nprint(y_pred_10)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T10:53:19.428735Z","iopub.execute_input":"2023-04-24T10:53:19.429361Z","iopub.status.idle":"2023-04-24T10:53:45.464366Z","shell.execute_reply.started":"2023-04-24T10:53:19.429309Z","shell.execute_reply":"2023-04-24T10:53:45.463140Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"193/193 [==============================] - 7s 28ms/step\n(12326, 1)\n12326\n[0.27285263 0.13525733 0.12310267 ... 0.06316675 0.3368275  0.14152004]\n","output_type":"stream"}]}]}